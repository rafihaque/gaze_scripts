Epoch (train): [0][0/74490]	Time 1.986 (1.986)	Data 1.288 (1.288)	Loss 17.6998 (17.6998)
Epoch (train): [0][1000/74490]	Time 0.083 (0.122)	Data 0.000 (0.046)	Loss 31.9574 (30.6864)
Epoch (train): [0][2000/74490]	Time 0.090 (0.121)	Data 0.000 (0.045)	Loss 22.6640 (30.3700)
Epoch (train): [0][3000/74490]	Time 0.076 (0.121)	Data 0.001 (0.044)	Loss 12.1449 (29.2319)
Epoch (train): [0][4000/74490]	Time 0.084 (0.120)	Data 0.000 (0.044)	Loss 20.7989 (27.5574)
Epoch (train): [0][5000/74490]	Time 0.080 (0.121)	Data 0.000 (0.044)	Loss 19.3753 (25.2540)
Epoch (train): [0][6000/74490]	Time 0.084 (0.121)	Data 0.000 (0.044)	Loss 7.3919 (23.4739)
Epoch (train): [0][7000/74490]	Time 0.089 (0.121)	Data 0.000 (0.044)	Loss 21.8045 (22.1770)
Epoch (train): [0][8000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 19.4650 (21.1376)
Epoch (train): [0][9000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 27.8295 (20.3612)
Epoch (train): [0][10000/74490]	Time 0.085 (0.121)	Data 0.000 (0.045)	Loss 18.1899 (19.6977)
Epoch (train): [0][11000/74490]	Time 0.083 (0.121)	Data 0.000 (0.045)	Loss 11.6471 (19.0981)
Epoch (train): [0][12000/74490]	Time 0.090 (0.121)	Data 0.000 (0.045)	Loss 11.4695 (18.6134)
Epoch (train): [0][13000/74490]	Time 0.076 (0.121)	Data 0.000 (0.045)	Loss 14.8521 (18.1762)
Epoch (train): [0][14000/74490]	Time 0.080 (0.121)	Data 0.000 (0.045)	Loss 6.7990 (17.7948)
Epoch (train): [0][15000/74490]	Time 0.084 (0.121)	Data 0.000 (0.045)	Loss 7.1835 (17.4781)
Epoch (train): [0][16000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 8.9725 (17.1831)
Epoch (train): [0][17000/74490]	Time 0.085 (0.121)	Data 0.000 (0.045)	Loss 11.9297 (16.9264)
Epoch (train): [0][18000/74490]	Time 0.079 (0.121)	Data 0.000 (0.045)	Loss 14.0742 (16.6896)
Epoch (train): [0][19000/74490]	Time 0.077 (0.121)	Data 0.000 (0.045)	Loss 9.7632 (16.4744)
Epoch (train): [0][20000/74490]	Time 0.087 (0.121)	Data 0.000 (0.045)	Loss 12.4675 (16.2772)
Epoch (train): [0][21000/74490]	Time 0.089 (0.121)	Data 0.000 (0.045)	Loss 13.5318 (16.0939)
Epoch (train): [0][22000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 19.4371 (15.9321)
Epoch (train): [0][23000/74490]	Time 0.095 (0.121)	Data 0.000 (0.045)	Loss 10.0183 (15.7868)
Epoch (train): [0][24000/74490]	Time 0.086 (0.122)	Data 0.003 (0.045)	Loss 17.0535 (15.6346)
Epoch (train): [0][25000/74490]	Time 0.086 (0.122)	Data 0.002 (0.045)	Loss 5.2958 (15.4957)
Epoch (train): [0][26000/74490]	Time 0.072 (0.122)	Data 0.000 (0.045)	Loss 8.2184 (15.3667)
Epoch (train): [0][27000/74490]	Time 0.081 (0.122)	Data 0.000 (0.045)	Loss 10.4329 (15.2538)
Epoch (train): [0][28000/74490]	Time 0.077 (0.122)	Data 0.001 (0.045)	Loss 12.2500 (15.1532)
Epoch (train): [0][29000/74490]	Time 0.096 (0.122)	Data 0.002 (0.045)	Loss 7.0237 (15.0609)
Epoch (train): [0][30000/74490]	Time 0.081 (0.123)	Data 0.001 (0.046)	Loss 10.6201 (14.9647)
Epoch (train): [0][31000/74490]	Time 0.083 (0.123)	Data 0.001 (0.046)	Loss 10.0719 (14.8769)
Epoch (train): [0][32000/74490]	Time 0.082 (0.123)	Data 0.000 (0.047)	Loss 7.3069 (14.7911)
Epoch (train): [0][33000/74490]	Time 0.081 (0.124)	Data 0.000 (0.047)	Loss 6.2986 (14.7064)
Epoch (train): [0][34000/74490]	Time 0.099 (0.124)	Data 0.000 (0.047)	Loss 7.7048 (14.6358)
Epoch (train): [0][35000/74490]	Time 0.085 (0.125)	Data 0.000 (0.048)	Loss 8.6893 (14.5684)
Epoch (train): [0][36000/74490]	Time 0.077 (0.125)	Data 0.000 (0.048)	Loss 17.9132 (14.4982)
Epoch (train): [0][37000/74490]	Time 0.079 (0.125)	Data 0.000 (0.048)	Loss 5.9215 (14.4306)
Epoch (train): [0][38000/74490]	Time 0.086 (0.126)	Data 0.000 (0.048)	Loss 6.9176 (14.3595)
Epoch (train): [0][39000/74490]	Time 0.087 (0.126)	Data 0.000 (0.049)	Loss 15.0232 (14.3004)
Epoch (train): [0][40000/74490]	Time 0.077 (0.126)	Data 0.001 (0.049)	Loss 16.7143 (14.2500)
Epoch (train): [0][41000/74490]	Time 0.071 (0.126)	Data 0.000 (0.049)	Loss 8.3035 (14.1945)
Epoch (train): [0][42000/74490]	Time 0.082 (0.126)	Data 0.000 (0.049)	Loss 17.7448 (14.1395)
Epoch (train): [0][43000/74490]	Time 0.091 (0.127)	Data 0.000 (0.049)	Loss 17.7781 (14.0902)
Epoch (train): [0][44000/74490]	Time 0.081 (0.127)	Data 0.000 (0.049)	Loss 12.7499 (14.0384)
Epoch (train): [0][45000/74490]	Time 0.088 (0.127)	Data 0.000 (0.049)	Loss 9.9648 (13.9899)
Epoch (train): [0][46000/74490]	Time 0.083 (0.127)	Data 0.000 (0.049)	Loss 18.3363 (13.9456)
Epoch (train): [0][47000/74490]	Time 0.077 (0.127)	Data 0.000 (0.049)	Loss 10.1903 (13.9033)
Epoch (train): [0][48000/74490]	Time 0.101 (0.127)	Data 0.000 (0.050)	Loss 13.5348 (13.8628)
Epoch (train): [0][49000/74490]	Time 0.083 (0.127)	Data 0.000 (0.050)	Loss 14.4800 (13.8256)
Epoch (train): [0][50000/74490]	Time 0.076 (0.127)	Data 0.000 (0.050)	Loss 14.2707 (13.7928)
Epoch (train): [0][51000/74490]	Time 0.095 (0.127)	Data 0.000 (0.050)	Loss 18.2562 (13.7599)
Epoch (train): [0][52000/74490]	Time 0.085 (0.128)	Data 0.000 (0.050)	Loss 9.3083 (13.7272)
Epoch (train): [0][53000/74490]	Time 0.088 (0.128)	Data 0.000 (0.050)	Loss 11.2948 (13.6962)
Epoch (train): [0][54000/74490]	Time 0.083 (0.128)	Data 0.003 (0.050)	Loss 10.0118 (13.6615)
Epoch (train): [0][55000/74490]	Time 0.085 (0.128)	Data 0.000 (0.050)	Loss 15.7170 (13.6260)
Epoch (train): [0][56000/74490]	Time 0.079 (0.128)	Data 0.000 (0.050)	Loss 25.4339 (13.5956)
Epoch (train): [0][57000/74490]	Time 0.085 (0.128)	Data 0.000 (0.050)	Loss 16.3099 (13.5693)
Epoch (train): [0][58000/74490]	Time 0.081 (0.128)	Data 0.000 (0.050)	Loss 9.8447 (13.5398)
Epoch (train): [0][59000/74490]	Time 0.086 (0.128)	Data 0.000 (0.051)	Loss 6.8152 (13.5096)
Epoch (train): [0][60000/74490]	Time 0.087 (0.128)	Data 0.000 (0.051)	Loss 10.0001 (13.4804)
Epoch (train): [0][61000/74490]	Time 0.083 (0.128)	Data 0.000 (0.051)	Loss 12.6149 (13.4574)
Epoch (train): [0][62000/74490]	Time 0.085 (0.129)	Data 0.000 (0.051)	Loss 6.5452 (13.4292)
Epoch (train): [0][63000/74490]	Time 0.096 (0.129)	Data 0.000 (0.051)	Loss 9.9987 (13.4024)
Epoch (train): [0][64000/74490]	Time 0.080 (0.129)	Data 0.000 (0.051)	Loss 8.0524 (13.3769)
Epoch (train): [0][65000/74490]	Time 0.091 (0.129)	Data 0.000 (0.051)	Loss 5.2985 (13.3556)
Epoch (train): [0][66000/74490]	Time 0.081 (0.129)	Data 0.000 (0.051)	Loss 9.5915 (13.3350)
Epoch (train): [0][67000/74490]	Time 0.090 (0.129)	Data 0.000 (0.051)	Loss 30.1812 (13.3113)
Epoch (train): [0][68000/74490]	Time 0.088 (0.129)	Data 0.000 (0.051)	Loss 13.3134 (13.2879)
Epoch (train): [0][69000/74490]	Time 0.088 (0.129)	Data 0.004 (0.051)	Loss 10.8081 (13.2693)
Epoch (train): [0][70000/74490]	Time 0.080 (0.129)	Data 0.001 (0.051)	Loss 17.5205 (13.2474)
Epoch (train): [0][71000/74490]	Time 0.089 (0.129)	Data 0.000 (0.051)	Loss 6.4525 (13.2220)
Epoch (train): [0][72000/74490]	Time 0.087 (0.129)	Data 0.000 (0.051)	Loss 10.5482 (13.2011)
Epoch (train): [0][73000/74490]	Time 0.074 (0.129)	Data 0.000 (0.051)	Loss 7.6953 (13.1769)
Epoch (train): [0][74000/74490]	Time 0.083 (0.129)	Data 0.000 (0.051)	Loss 6.7546 (13.1555)
Epoch (train): [1][510/74490]	Time 0.153 (0.136)	Data 0.115 (0.062)	Loss 6.8178 (11.3408)
Epoch (train): [1][1510/74490]	Time 0.088 (0.134)	Data 0.000 (0.061)	Loss 7.3645 (11.3710)
Epoch (train): [1][2510/74490]	Time 0.091 (0.134)	Data 0.000 (0.059)	Loss 6.9416 (11.3758)
Epoch (train): [1][3510/74490]	Time 0.085 (0.133)	Data 0.016 (0.057)	Loss 10.3922 (11.3664)
Epoch (train): [1][4510/74490]	Time 0.080 (0.134)	Data 0.000 (0.057)	Loss 11.8671 (11.3738)
Epoch (train): [1][5510/74490]	Time 0.193 (0.134)	Data 0.153 (0.057)	Loss 10.4879 (11.3726)
Epoch (train): [1][6510/74490]	Time 0.465 (0.134)	Data 0.427 (0.057)	Loss 7.4263 (11.3392)
Epoch (train): [1][7510/74490]	Time 0.358 (0.134)	Data 0.319 (0.057)	Loss 10.4291 (11.3089)
Epoch (train): [1][8510/74490]	Time 0.087 (0.134)	Data 0.000 (0.057)	Loss 22.2782 (11.2648)
Epoch (train): [1][9510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 14.7364 (11.2473)
Epoch (train): [1][10510/74490]	Time 0.087 (0.134)	Data 0.000 (0.057)	Loss 8.0828 (11.2093)
Epoch (train): [1][11510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 7.9917 (11.1742)
Epoch (train): [1][12510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 11.6104 (11.1274)
Epoch (train): [1][13510/74490]	Time 0.089 (0.134)	Data 0.000 (0.057)	Loss 9.3070 (11.0977)
Epoch (train): [1][14510/74490]	Time 0.093 (0.134)	Data 0.001 (0.057)	Loss 6.4588 (11.0670)
Epoch (train): [1][15510/74490]	Time 0.975 (0.134)	Data 0.938 (0.057)	Loss 6.4880 (11.0487)
Epoch (train): [1][16510/74490]	Time 0.446 (0.134)	Data 0.412 (0.057)	Loss 7.0927 (11.0211)
Epoch (train): [1][17510/74490]	Time 0.090 (0.134)	Data 0.000 (0.057)	Loss 6.7033 (11.0025)
Epoch (train): [1][18510/74490]	Time 0.176 (0.134)	Data 0.135 (0.057)	Loss 15.7798 (10.9760)
Epoch (train): [1][19510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 8.9392 (10.9553)
Epoch (train): [1][20510/74490]	Time 0.091 (0.134)	Data 0.000 (0.057)	Loss 7.0225 (10.9354)
Epoch (train): [1][21510/74490]	Time 0.083 (0.134)	Data 0.000 (0.057)	Loss 7.9176 (10.9121)
Epoch (train): [1][22510/74490]	Time 0.083 (0.133)	Data 0.000 (0.057)	Loss 17.3537 (10.8823)
Epoch (train): [1][23510/74490]	Time 0.430 (0.133)	Data 0.388 (0.056)	Loss 5.0644 (10.8495)
Epoch (train): [1][24510/74490]	Time 0.082 (0.133)	Data 0.000 (0.056)	Loss 6.9442 (10.8238)
Epoch (train): [1][25510/74490]	Time 0.453 (0.133)	Data 0.415 (0.056)	Loss 8.6824 (10.8097)
Epoch (train): [1][26510/74490]	Time 0.078 (0.133)	Data 0.000 (0.056)	Loss 7.9667 (10.7926)
Epoch (train): [1][27510/74490]	Time 0.080 (0.133)	Data 0.000 (0.056)	Loss 15.3064 (10.7743)
Epoch (train): [1][28510/74490]	Time 0.062 (0.133)	Data 0.000 (0.056)	Loss 12.9763 (10.7440)
Epoch (train): [1][29510/74490]	Time 0.080 (0.133)	Data 0.000 (0.056)	Loss 16.0642 (10.7167)
Epoch (train): [1][30510/74490]	Time 0.087 (0.134)	Data 0.000 (0.057)	Loss 11.5243 (10.6999)
Epoch (train): [1][31510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 7.4952 (10.6800)
Epoch (train): [1][32510/74490]	Time 0.068 (0.134)	Data 0.000 (0.057)	Loss 7.7612 (10.6542)
Epoch (train): [1][33510/74490]	Time 0.090 (0.134)	Data 0.000 (0.056)	Loss 15.2555 (10.6355)
Epoch (train): [1][34510/74490]	Time 0.083 (0.134)	Data 0.000 (0.056)	Loss 11.7699 (10.6092)
Epoch (train): [1][35510/74490]	Time 0.503 (0.134)	Data 0.464 (0.057)	Loss 11.0966 (10.5877)
Epoch (train): [1][36510/74490]	Time 0.082 (0.134)	Data 0.000 (0.057)	Loss 2.9445 (10.5639)
Epoch (train): [1][37510/74490]	Time 0.090 (0.134)	Data 0.000 (0.057)	Loss 15.6480 (10.5433)
Epoch (train): [1][38510/74490]	Time 0.093 (0.134)	Data 0.000 (0.057)	Loss 8.7091 (10.5205)
Epoch (train): [1][39510/74490]	Time 0.091 (0.134)	Data 0.000 (0.057)	Loss 9.9193 (10.5005)
Epoch (train): [1][40510/74490]	Time 0.096 (0.134)	Data 0.000 (0.057)	Loss 5.3574 (10.4784)
Epoch (train): [1][41510/74490]	Time 0.096 (0.134)	Data 0.001 (0.057)	Loss 10.7326 (10.4535)
Epoch (train): [1][42510/74490]	Time 0.083 (0.134)	Data 0.000 (0.057)	Loss 6.3389 (10.4308)
Epoch (train): [1][43510/74490]	Time 0.084 (0.134)	Data 0.000 (0.057)	Loss 11.6080 (10.4096)
Epoch (train): [1][44510/74490]	Time 0.398 (0.134)	Data 0.358 (0.057)	Loss 7.9409 (10.3801)
Epoch (train): [1][45510/74490]	Time 0.601 (0.134)	Data 0.561 (0.057)	Loss 10.3134 (10.3561)
Epoch (train): [1][46510/74490]	Time 0.088 (0.134)	Data 0.000 (0.057)	Loss 10.8804 (10.3300)
Epoch (train): [1][47510/74490]	Time 0.100 (0.134)	Data 0.000 (0.057)	Loss 3.4223 (10.3063)
Epoch (train): [1][48510/74490]	Time 0.083 (0.134)	Data 0.000 (0.057)	Loss 14.8553 (10.2825)
Epoch (train): [1][49510/74490]	Time 0.473 (0.134)	Data 0.434 (0.057)	Loss 6.4213 (10.2669)
Epoch (train): [1][50510/74490]	Time 0.083 (0.134)	Data 0.047 (0.057)	Loss 10.7460 (10.2476)
Epoch (train): [1][51510/74490]	Time 0.086 (0.134)	Data 0.002 (0.057)	Loss 16.5232 (10.2266)
Epoch (train): [1][52510/74490]	Time 0.080 (0.134)	Data 0.000 (0.057)	Loss 5.7677 (10.2032)
Epoch (train): [1][53510/74490]	Time 0.088 (0.134)	Data 0.000 (0.057)	Loss 5.3444 (10.1806)
Epoch (train): [1][54510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 4.8256 (10.1607)
Epoch (train): [1][55510/74490]	Time 0.354 (0.134)	Data 0.316 (0.057)	Loss 3.0684 (10.1369)
Epoch (train): [1][56510/74490]	Time 0.434 (0.134)	Data 0.398 (0.057)	Loss 16.5449 (10.1149)
Epoch (train): [1][57510/74490]	Time 0.081 (0.134)	Data 0.000 (0.057)	Loss 10.9093 (10.0917)
Epoch (train): [1][58510/74490]	Time 0.082 (0.134)	Data 0.000 (0.057)	Loss 11.7888 (10.0685)
Epoch (train): [1][59510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 15.0366 (10.0447)
Epoch (train): [1][60510/74490]	Time 0.080 (0.134)	Data 0.000 (0.057)	Loss 12.3119 (10.0204)
Epoch (train): [1][61510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 8.6902 (10.0015)
Epoch (train): [1][62510/74490]	Time 0.081 (0.134)	Data 0.046 (0.057)	Loss 9.5692 (9.9761)
Epoch (train): [1][63510/74490]	Time 0.442 (0.134)	Data 0.409 (0.057)	Loss 7.8585 (9.9573)
Epoch (train): [1][64510/74490]	Time 0.762 (0.134)	Data 0.717 (0.057)	Loss 8.8236 (9.9348)
Epoch (train): [1][65510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 6.9724 (9.9140)
Epoch (train): [1][66510/74490]	Time 0.070 (0.135)	Data 0.000 (0.057)	Loss 3.5284 (9.8920)
Epoch (train): [1][67510/74490]	Time 0.189 (0.135)	Data 0.151 (0.057)	Loss 10.4315 (9.8701)
Epoch (train): [1][68510/74490]	Time 0.085 (0.135)	Data 0.000 (0.058)	Loss 10.9078 (9.8499)
Epoch (train): [1][69510/74490]	Time 0.089 (0.135)	Data 0.000 (0.058)	Loss 10.8112 (9.8291)
Epoch (train): [1][70510/74490]	Time 0.085 (0.135)	Data 0.001 (0.058)	Loss 3.4866 (9.8061)
Epoch (train): [1][71510/74490]	Time 0.086 (0.135)	Data 0.001 (0.057)	Loss 5.2696 (9.7842)
Epoch (train): [1][72510/74490]	Time 0.144 (0.135)	Data 0.102 (0.057)	Loss 5.2275 (9.7635)
Epoch (train): [1][73510/74490]	Time 0.093 (0.135)	Data 0.000 (0.057)	Loss 3.8314 (9.7427)
Epoch (train): [2][20/74490]	Time 0.086 (0.183)	Data 0.000 (0.110)	Loss 5.3445 (7.6000)
Epoch (train): [2][1020/74490]	Time 0.088 (0.123)	Data 0.001 (0.048)	Loss 9.6148 (8.4718)
Epoch (train): [2][2020/74490]	Time 0.134 (0.122)	Data 0.095 (0.047)	Loss 8.4224 (8.2229)
Epoch (train): [2][3020/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 8.3889 (8.1566)
Epoch (train): [2][4020/74490]	Time 0.087 (0.125)	Data 0.000 (0.050)	Loss 7.5816 (8.1479)
Epoch (train): [2][5020/74490]	Time 0.089 (0.125)	Data 0.000 (0.049)	Loss 2.5164 (8.0679)
Epoch (train): [2][6020/74490]	Time 0.086 (0.125)	Data 0.000 (0.048)	Loss 6.0430 (8.0270)
Epoch (train): [2][7020/74490]	Time 0.081 (0.125)	Data 0.000 (0.048)	Loss 18.0337 (8.0041)
Epoch (train): [2][8020/74490]	Time 0.086 (0.124)	Data 0.000 (0.048)	Loss 9.3425 (7.9928)
Epoch (train): [2][9020/74490]	Time 0.084 (0.124)	Data 0.000 (0.047)	Loss 5.0453 (7.9499)
Epoch (train): [2][10020/74490]	Time 0.087 (0.124)	Data 0.000 (0.048)	Loss 5.7769 (7.9245)
Epoch (train): [2][11020/74490]	Time 0.081 (0.124)	Data 0.000 (0.048)	Loss 8.4927 (7.9007)
Epoch (train): [2][12020/74490]	Time 0.087 (0.124)	Data 0.000 (0.048)	Loss 7.7962 (7.8668)
Epoch (train): [2][13020/74490]	Time 0.082 (0.124)	Data 0.001 (0.048)	Loss 7.3560 (7.8583)
Epoch (train): [2][14020/74490]	Time 0.071 (0.124)	Data 0.000 (0.048)	Loss 7.0146 (7.8357)
Epoch (train): [2][15020/74490]	Time 0.090 (0.127)	Data 0.000 (0.051)	Loss 10.3050 (7.8410)
Epoch (train): [2][16020/74490]	Time 0.081 (0.132)	Data 0.002 (0.056)	Loss 9.6316 (7.8306)
Epoch (train): [2][17020/74490]	Time 0.419 (0.136)	Data 0.382 (0.060)	Loss 6.7792 (7.8071)
Epoch (train): [2][18020/74490]	Time 0.083 (0.135)	Data 0.000 (0.060)	Loss 14.7467 (7.7872)
Epoch (train): [2][19020/74490]	Time 0.083 (0.135)	Data 0.000 (0.059)	Loss 6.3844 (7.7677)
Epoch (train): [2][20020/74490]	Time 0.085 (0.134)	Data 0.002 (0.059)	Loss 7.2179 (7.7461)
Epoch (train): [2][21020/74490]	Time 0.085 (0.134)	Data 0.000 (0.058)	Loss 5.4201 (7.7383)
Epoch (train): [2][22020/74490]	Time 0.089 (0.134)	Data 0.000 (0.058)	Loss 7.2127 (7.7167)
Epoch (train): [2][23020/74490]	Time 0.081 (0.133)	Data 0.000 (0.057)	Loss 6.6621 (7.7053)
Epoch (train): [2][24020/74490]	Time 0.091 (0.133)	Data 0.000 (0.057)	Loss 6.1351 (7.6791)
Epoch (train): [2][25020/74490]	Time 0.087 (0.133)	Data 0.000 (0.057)	Loss 3.8080 (7.6630)
Epoch (train): [2][26020/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 5.4890 (7.6446)
Epoch (train): [2][27020/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 6.9364 (7.6262)
Epoch (train): [2][28020/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 7.0464 (7.6138)
Epoch (train): [2][29020/74490]	Time 0.095 (0.132)	Data 0.000 (0.056)	Loss 5.0963 (7.5984)
Epoch (train): [2][30020/74490]	Time 0.094 (0.131)	Data 0.000 (0.056)	Loss 9.0306 (7.5801)
Epoch (train): [2][31020/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 8.8352 (7.5631)
Epoch (train): [2][32020/74490]	Time 0.091 (0.131)	Data 0.000 (0.055)	Loss 5.3754 (7.5475)
Epoch (train): [2][33020/74490]	Time 0.092 (0.131)	Data 0.000 (0.055)	Loss 7.7227 (7.5315)
Epoch (train): [2][34020/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 6.9746 (7.5113)
Epoch (train): [2][35020/74490]	Time 0.081 (0.130)	Data 0.000 (0.055)	Loss 8.6030 (7.4918)
Epoch (train): [2][36020/74490]	Time 0.085 (0.130)	Data 0.000 (0.055)	Loss 5.3164 (7.4722)
Epoch (train): [2][37020/74490]	Time 0.080 (0.130)	Data 0.000 (0.055)	Loss 5.8172 (7.4556)
Epoch (train): [2][38020/74490]	Time 0.080 (0.130)	Data 0.000 (0.054)	Loss 7.7395 (7.4461)
Epoch (train): [2][39020/74490]	Time 0.087 (0.130)	Data 0.000 (0.054)	Loss 6.2895 (7.4304)
Epoch (train): [2][40020/74490]	Time 0.086 (0.130)	Data 0.001 (0.054)	Loss 3.9941 (7.4181)
Epoch (train): [2][41020/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 7.2777 (7.4031)
Epoch (train): [2][42020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.6666 (7.3917)
Epoch (train): [2][43020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 8.6003 (7.3724)
Epoch (train): [2][44020/74490]	Time 0.090 (0.130)	Data 0.001 (0.054)	Loss 10.3311 (7.3612)
Epoch (train): [2][45020/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 4.7739 (7.3441)
Epoch (train): [2][46020/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 13.6195 (7.3290)
Epoch (train): [2][47020/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 10.5647 (7.3148)
Epoch (train): [2][48020/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 5.7526 (7.2994)
Epoch (train): [2][49020/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 10.8026 (7.2862)
Epoch (train): [2][50020/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 5.1514 (7.2725)
Epoch (train): [2][51020/74490]	Time 0.088 (0.129)	Data 0.000 (0.054)	Loss 4.8362 (7.2582)
Epoch (train): [2][52020/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 4.8728 (7.2444)
Epoch (train): [2][53020/74490]	Time 0.076 (0.130)	Data 0.000 (0.054)	Loss 9.3993 (7.2301)
Epoch (train): [2][54020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 7.0362 (7.2160)
Epoch (train): [2][55020/74490]	Time 0.086 (0.130)	Data 0.003 (0.054)	Loss 4.5707 (7.2005)
Epoch (train): [2][56020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 7.6540 (7.1869)
Epoch (train): [2][57020/74490]	Time 0.092 (0.130)	Data 0.000 (0.054)	Loss 4.3395 (7.1737)
Epoch (train): [2][58020/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 5.5191 (7.1604)
Epoch (train): [2][59020/74490]	Time 0.079 (0.130)	Data 0.003 (0.054)	Loss 7.2292 (7.1443)
Epoch (train): [2][60020/74490]	Time 0.091 (0.130)	Data 0.000 (0.054)	Loss 6.5371 (7.1320)
Epoch (train): [2][61020/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 6.3485 (7.1189)
Epoch (train): [2][62020/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 6.0489 (7.1031)
Epoch (train): [2][63020/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 2.8998 (7.0879)
Epoch (train): [2][64020/74490]	Time 0.085 (0.129)	Data 0.001 (0.054)	Loss 5.3657 (7.0722)
Epoch (train): [2][65020/74490]	Time 0.084 (0.129)	Data 0.001 (0.054)	Loss 5.4687 (7.0590)
Epoch (train): [2][66020/74490]	Time 0.083 (0.129)	Data 0.001 (0.054)	Loss 5.3691 (7.0456)
Epoch (train): [2][67020/74490]	Time 0.093 (0.129)	Data 0.000 (0.054)	Loss 6.8724 (7.0283)
Epoch (train): [2][68020/74490]	Time 0.078 (0.129)	Data 0.001 (0.054)	Loss 2.9507 (7.0141)
Epoch (train): [2][69020/74490]	Time 0.089 (0.129)	Data 0.001 (0.053)	Loss 7.1489 (7.0025)
Epoch (train): [2][70020/74490]	Time 0.089 (0.129)	Data 0.000 (0.053)	Loss 5.1067 (6.9888)
Epoch (train): [2][71020/74490]	Time 0.082 (0.129)	Data 0.000 (0.053)	Loss 6.4565 (6.9748)
Epoch (train): [2][72020/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 4.2964 (6.9617)
Epoch (train): [2][73020/74490]	Time 0.083 (0.129)	Data 0.000 (0.053)	Loss 5.2122 (6.9481)
Epoch (train): [2][74020/74490]	Time 0.084 (0.129)	Data 0.000 (0.053)	Loss 4.0279 (6.9347)
Epoch (train): [3][530/74490]	Time 0.262 (0.131)	Data 0.229 (0.054)	Loss 10.6803 (6.0595)
Epoch (train): [3][1530/74490]	Time 0.077 (0.129)	Data 0.000 (0.054)	Loss 2.4045 (5.9451)
Epoch (train): [3][2530/74490]	Time 0.088 (0.129)	Data 0.000 (0.052)	Loss 5.6482 (5.9078)
Epoch (train): [3][3530/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 6.5583 (5.8882)
Epoch (train): [3][4530/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 4.2878 (5.8732)
Epoch (train): [3][5530/74490]	Time 0.081 (0.127)	Data 0.001 (0.052)	Loss 5.1867 (5.8529)
Epoch (train): [3][6530/74490]	Time 0.079 (0.127)	Data 0.000 (0.052)	Loss 6.7792 (5.8409)
Epoch (train): [3][7530/74490]	Time 0.411 (0.128)	Data 0.376 (0.052)	Loss 10.8289 (5.8413)
Epoch (train): [3][8530/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 4.7497 (5.8387)
Epoch (train): [3][9530/74490]	Time 0.080 (0.127)	Data 0.000 (0.052)	Loss 4.3123 (5.8086)
Epoch (train): [3][10530/74490]	Time 0.373 (0.127)	Data 0.336 (0.052)	Loss 5.6018 (5.8008)
Epoch (train): [3][11530/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 6.4028 (5.7925)
Epoch (train): [3][12530/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 3.9468 (5.7785)
Epoch (train): [3][13530/74490]	Time 0.096 (0.127)	Data 0.000 (0.052)	Loss 4.4660 (5.7793)
Epoch (train): [3][14530/74490]	Time 0.080 (0.127)	Data 0.001 (0.052)	Loss 4.1564 (5.7713)
Epoch (train): [3][15530/74490]	Time 0.083 (0.127)	Data 0.000 (0.052)	Loss 3.6263 (5.7607)
Epoch (train): [3][16530/74490]	Time 0.088 (0.127)	Data 0.000 (0.052)	Loss 1.6759 (5.7580)
Epoch (train): [3][17530/74490]	Time 0.080 (0.127)	Data 0.000 (0.052)	Loss 4.9537 (5.7482)
Epoch (train): [3][18530/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 4.6749 (5.7435)
Epoch (train): [3][19530/74490]	Time 0.084 (0.127)	Data 0.000 (0.051)	Loss 5.2989 (5.7313)
Epoch (train): [3][20530/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 4.5728 (5.7203)
Epoch (train): [3][21530/74490]	Time 0.077 (0.127)	Data 0.000 (0.051)	Loss 4.3270 (5.7144)
Epoch (train): [3][22530/74490]	Time 0.080 (0.127)	Data 0.000 (0.051)	Loss 6.3692 (5.7002)
Epoch (train): [3][23530/74490]	Time 0.084 (0.127)	Data 0.000 (0.051)	Loss 9.2563 (5.6894)
Epoch (train): [3][24530/74490]	Time 0.083 (0.127)	Data 0.000 (0.051)	Loss 8.9189 (5.6821)
Epoch (train): [3][25530/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 9.8825 (5.6829)
Epoch (train): [3][26530/74490]	Time 0.083 (0.127)	Data 0.000 (0.051)	Loss 4.1039 (5.6748)
Epoch (train): [3][27530/74490]	Time 0.092 (0.127)	Data 0.000 (0.051)	Loss 3.8730 (5.6673)
Epoch (train): [3][28530/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 5.3121 (5.6550)
Epoch (train): [3][29530/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 2.5788 (5.6510)
Epoch (train): [3][30530/74490]	Time 0.296 (0.128)	Data 0.258 (0.052)	Loss 21.9254 (5.6419)
Epoch (train): [3][31530/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 5.5495 (5.6373)
Epoch (train): [3][32530/74490]	Time 0.082 (0.128)	Data 0.000 (0.052)	Loss 6.1364 (5.6325)
Epoch (train): [3][33530/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 3.1818 (5.6253)
Epoch (train): [3][34530/74490]	Time 0.084 (0.128)	Data 0.001 (0.052)	Loss 7.5241 (5.6160)
Epoch (train): [3][35530/74490]	Time 0.088 (0.128)	Data 0.003 (0.052)	Loss 5.0286 (5.6068)
Epoch (train): [3][36530/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 7.8327 (5.5984)
Epoch (train): [3][37530/74490]	Time 0.091 (0.128)	Data 0.000 (0.052)	Loss 4.8105 (5.5926)
Epoch (train): [3][38530/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 5.1816 (5.5861)
Epoch (train): [3][39530/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 3.5773 (5.5783)
Epoch (train): [3][40530/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 10.9744 (5.5765)
Epoch (train): [3][41530/74490]	Time 0.089 (0.128)	Data 0.000 (0.052)	Loss 4.2884 (5.5668)
Epoch (train): [3][42530/74490]	Time 0.085 (0.128)	Data 0.003 (0.052)	Loss 7.5212 (5.5613)
Epoch (train): [3][43530/74490]	Time 0.083 (0.128)	Data 0.000 (0.052)	Loss 5.9105 (5.5551)
Epoch (train): [3][44530/74490]	Time 0.072 (0.128)	Data 0.000 (0.053)	Loss 3.1007 (5.5462)
Epoch (train): [3][45530/74490]	Time 0.073 (0.128)	Data 0.000 (0.053)	Loss 5.8406 (5.5392)
Epoch (train): [3][46530/74490]	Time 0.089 (0.128)	Data 0.000 (0.053)	Loss 4.2940 (5.5324)
Epoch (train): [3][47530/74490]	Time 0.094 (0.128)	Data 0.000 (0.053)	Loss 2.2916 (5.5260)
Epoch (train): [3][48530/74490]	Time 0.611 (0.129)	Data 0.571 (0.053)	Loss 3.9921 (5.5192)
Epoch (train): [3][49530/74490]	Time 0.099 (0.129)	Data 0.000 (0.053)	Loss 3.7400 (5.5101)
Epoch (train): [3][50530/74490]	Time 0.082 (0.129)	Data 0.000 (0.053)	Loss 6.9451 (5.5020)
Epoch (train): [3][51530/74490]	Time 0.086 (0.129)	Data 0.000 (0.053)	Loss 6.4033 (5.4930)
Epoch (train): [3][52530/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 6.6400 (5.4875)
Epoch (train): [3][53530/74490]	Time 0.086 (0.129)	Data 0.000 (0.053)	Loss 3.0107 (5.4784)
Epoch (train): [3][54530/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 4.6729 (5.4728)
Epoch (train): [3][55530/74490]	Time 0.080 (0.129)	Data 0.000 (0.054)	Loss 3.0001 (5.4664)
Epoch (train): [3][56530/74490]	Time 0.078 (0.129)	Data 0.005 (0.054)	Loss 4.5674 (5.4630)
Epoch (train): [3][57530/74490]	Time 0.084 (0.129)	Data 0.001 (0.054)	Loss 3.8454 (5.4570)
Epoch (train): [3][58530/74490]	Time 0.477 (0.129)	Data 0.432 (0.054)	Loss 2.8659 (5.4508)
Epoch (train): [3][59530/74490]	Time 0.441 (0.129)	Data 0.401 (0.054)	Loss 5.1039 (5.4438)
Epoch (train): [3][60530/74490]	Time 0.086 (0.129)	Data 0.000 (0.054)	Loss 4.9260 (5.4359)
Epoch (train): [3][61530/74490]	Time 0.083 (0.129)	Data 0.000 (0.054)	Loss 9.0972 (5.4286)
Epoch (train): [3][62530/74490]	Time 0.089 (0.129)	Data 0.000 (0.054)	Loss 16.1793 (5.4207)
Epoch (train): [3][63530/74490]	Time 0.076 (0.129)	Data 0.002 (0.054)	Loss 7.9359 (5.4146)
Epoch (train): [3][64530/74490]	Time 0.093 (0.129)	Data 0.000 (0.054)	Loss 2.4817 (5.4094)
Epoch (train): [3][65530/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 10.1185 (5.4030)
Epoch (train): [3][66530/74490]	Time 0.086 (0.129)	Data 0.000 (0.054)	Loss 2.8668 (5.3975)
Epoch (train): [3][67530/74490]	Time 0.089 (0.129)	Data 0.001 (0.054)	Loss 5.5158 (5.3905)
Epoch (train): [3][68530/74490]	Time 0.086 (0.130)	Data 0.002 (0.055)	Loss 2.2657 (5.3835)
Epoch (train): [3][69530/74490]	Time 0.117 (0.130)	Data 0.080 (0.055)	Loss 16.3956 (5.3781)
Epoch (train): [3][70530/74490]	Time 0.395 (0.130)	Data 0.355 (0.055)	Loss 3.9275 (5.3735)
Epoch (train): [3][71530/74490]	Time 0.081 (0.130)	Data 0.000 (0.055)	Loss 11.6013 (5.3655)
Epoch (train): [3][72530/74490]	Time 0.085 (0.130)	Data 0.000 (0.055)	Loss 6.1567 (5.3577)
Epoch (train): [3][73530/74490]	Time 0.086 (0.130)	Data 0.000 (0.055)	Loss 7.0533 (5.3528)
Epoch (train): [4][40/74490]	Time 0.084 (0.337)	Data 0.000 (0.261)	Loss 3.9442 (5.2248)
Epoch (train): [4][1040/74490]	Time 0.082 (0.161)	Data 0.000 (0.084)	Loss 3.4626 (4.7274)
Epoch (train): [4][2040/74490]	Time 0.190 (0.150)	Data 0.151 (0.073)	Loss 4.4079 (4.7243)
Epoch (train): [4][3040/74490]	Time 0.419 (0.146)	Data 0.379 (0.070)	Loss 4.0696 (4.8051)
Epoch (train): [4][4040/74490]	Time 0.089 (0.145)	Data 0.002 (0.069)	Loss 2.4441 (4.7745)
Epoch (train): [4][5040/74490]	Time 0.160 (0.145)	Data 0.121 (0.069)	Loss 3.3441 (4.7731)
Epoch (train): [4][6040/74490]	Time 0.082 (0.144)	Data 0.000 (0.068)	Loss 3.0880 (4.7732)
Epoch (train): [4][7040/74490]	Time 0.082 (0.144)	Data 0.000 (0.068)	Loss 4.4355 (4.7876)
Epoch (train): [4][8040/74490]	Time 0.086 (0.144)	Data 0.000 (0.067)	Loss 6.9857 (4.7835)
Epoch (train): [4][9040/74490]	Time 0.073 (0.142)	Data 0.000 (0.066)	Loss 2.1385 (4.7802)
Epoch (train): [4][10040/74490]	Time 0.081 (0.141)	Data 0.000 (0.065)	Loss 2.4997 (4.7747)
Epoch (train): [4][11040/74490]	Time 0.492 (0.141)	Data 0.456 (0.064)	Loss 4.3750 (4.7671)
Epoch (train): [4][12040/74490]	Time 0.437 (0.140)	Data 0.395 (0.063)	Loss 2.6518 (4.7583)
Epoch (train): [4][13040/74490]	Time 0.086 (0.139)	Data 0.000 (0.062)	Loss 3.8721 (4.7512)
Epoch (train): [4][14040/74490]	Time 0.417 (0.138)	Data 0.377 (0.062)	Loss 5.6578 (4.7541)
Epoch (train): [4][15040/74490]	Time 0.084 (0.138)	Data 0.000 (0.061)	Loss 6.0479 (4.7425)
Epoch (train): [4][16040/74490]	Time 0.086 (0.137)	Data 0.000 (0.061)	Loss 2.6163 (4.7389)
Epoch (train): [4][17040/74490]	Time 0.084 (0.137)	Data 0.000 (0.061)	Loss 2.7835 (4.7341)
Epoch (train): [4][18040/74490]	Time 0.072 (0.137)	Data 0.000 (0.061)	Loss 2.5234 (4.7293)
Epoch (train): [4][19040/74490]	Time 0.085 (0.137)	Data 0.000 (0.060)	Loss 8.5383 (4.7202)
Epoch (train): [4][20040/74490]	Time 0.086 (0.136)	Data 0.000 (0.060)	Loss 7.2288 (4.7164)
Epoch (train): [4][21040/74490]	Time 0.077 (0.136)	Data 0.001 (0.060)	Loss 4.3447 (4.7048)
Epoch (train): [4][22040/74490]	Time 0.083 (0.136)	Data 0.000 (0.060)	Loss 4.9557 (4.7028)
Epoch (train): [4][23040/74490]	Time 0.084 (0.136)	Data 0.000 (0.060)	Loss 3.7015 (4.6974)
Epoch (train): [4][24040/74490]	Time 0.082 (0.136)	Data 0.000 (0.060)	Loss 4.7825 (4.6951)
Epoch (train): [4][25040/74490]	Time 0.515 (0.137)	Data 0.475 (0.060)	Loss 3.8225 (4.6932)
Epoch (train): [4][26040/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 5.1046 (4.6900)
Epoch (train): [4][27040/74490]	Time 0.083 (0.136)	Data 0.000 (0.060)	Loss 1.7065 (4.6856)
Epoch (train): [4][28040/74490]	Time 0.095 (0.136)	Data 0.000 (0.060)	Loss 3.1667 (4.6851)
Epoch (train): [4][29040/74490]	Time 0.089 (0.136)	Data 0.000 (0.060)	Loss 10.6164 (4.6791)
Epoch (train): [4][30040/74490]	Time 0.082 (0.136)	Data 0.000 (0.060)	Loss 3.7458 (4.6747)
Epoch (train): [4][31040/74490]	Time 0.098 (0.136)	Data 0.000 (0.060)	Loss 7.8777 (4.6687)
Epoch (train): [4][32040/74490]	Time 0.314 (0.136)	Data 0.274 (0.060)	Loss 2.8893 (4.6627)
Epoch (train): [4][33040/74490]	Time 0.081 (0.136)	Data 0.000 (0.060)	Loss 2.8689 (4.6588)
Epoch (train): [4][34040/74490]	Time 0.067 (0.136)	Data 0.029 (0.060)	Loss 3.4605 (4.6602)
Epoch (train): [4][35040/74490]	Time 0.081 (0.135)	Data 0.000 (0.059)	Loss 4.0967 (4.6581)
Epoch (train): [4][36040/74490]	Time 0.140 (0.135)	Data 0.101 (0.059)	Loss 1.6143 (4.6563)
Epoch (train): [4][37040/74490]	Time 0.302 (0.135)	Data 0.265 (0.059)	Loss 2.2338 (4.6540)
Epoch (train): [4][38040/74490]	Time 0.391 (0.135)	Data 0.354 (0.059)	Loss 4.9841 (4.6514)
Epoch (train): [4][39040/74490]	Time 0.463 (0.135)	Data 0.420 (0.059)	Loss 5.4427 (4.6463)
Epoch (train): [4][40040/74490]	Time 0.455 (0.135)	Data 0.419 (0.059)	Loss 5.4375 (4.6406)
Epoch (train): [4][41040/74490]	Time 0.081 (0.135)	Data 0.000 (0.058)	Loss 4.6196 (4.6343)
Epoch (train): [4][42040/74490]	Time 0.078 (0.134)	Data 0.000 (0.058)	Loss 5.4622 (4.6297)
Epoch (train): [4][43040/74490]	Time 0.083 (0.134)	Data 0.002 (0.058)	Loss 2.9102 (4.6272)
Epoch (train): [4][44040/74490]	Time 0.139 (0.135)	Data 0.102 (0.058)	Loss 2.7316 (4.6201)
Epoch (train): [4][45040/74490]	Time 0.083 (0.135)	Data 0.000 (0.059)	Loss 3.4291 (4.6178)
Epoch (train): [4][46040/74490]	Time 0.086 (0.135)	Data 0.000 (0.059)	Loss 4.8988 (4.6150)
Epoch (train): [4][47040/74490]	Time 0.090 (0.135)	Data 0.000 (0.059)	Loss 4.1332 (4.6086)
Epoch (train): [4][48040/74490]	Time 0.070 (0.135)	Data 0.000 (0.059)	Loss 3.6410 (4.6035)
Epoch (train): [4][49040/74490]	Time 0.483 (0.135)	Data 0.438 (0.059)	Loss 2.8847 (4.5997)
Epoch (train): [4][50040/74490]	Time 0.089 (0.135)	Data 0.000 (0.059)	Loss 11.1514 (4.5943)
Epoch (train): [4][51040/74490]	Time 0.084 (0.135)	Data 0.000 (0.059)	Loss 4.5701 (4.5900)
Epoch (train): [4][52040/74490]	Time 0.083 (0.135)	Data 0.000 (0.058)	Loss 5.6300 (4.5885)
Epoch (train): [4][53040/74490]	Time 0.088 (0.135)	Data 0.015 (0.058)	Loss 5.8915 (4.5838)
Epoch (train): [4][54040/74490]	Time 0.195 (0.134)	Data 0.156 (0.058)	Loss 2.6421 (4.5787)
Epoch (train): [4][55040/74490]	Time 0.398 (0.134)	Data 0.362 (0.058)	Loss 4.9313 (4.5760)
Epoch (train): [4][56040/74490]	Time 0.208 (0.134)	Data 0.170 (0.058)	Loss 6.9727 (4.5716)
Epoch (train): [4][57040/74490]	Time 0.081 (0.134)	Data 0.000 (0.058)	Loss 3.7720 (4.5667)
Epoch (train): [4][58040/74490]	Time 0.088 (0.134)	Data 0.000 (0.058)	Loss 3.6365 (4.5638)
Epoch (train): [4][59040/74490]	Time 0.080 (0.134)	Data 0.000 (0.058)	Loss 6.8736 (4.5605)
Epoch (train): [4][60040/74490]	Time 0.084 (0.134)	Data 0.000 (0.058)	Loss 3.8285 (4.5564)
Epoch (train): [4][61040/74490]	Time 0.085 (0.134)	Data 0.000 (0.058)	Loss 2.0571 (4.5522)
Epoch (train): [4][62040/74490]	Time 0.085 (0.134)	Data 0.000 (0.058)	Loss 5.6763 (4.5493)
Epoch (train): [4][63040/74490]	Time 0.084 (0.134)	Data 0.000 (0.058)	Loss 3.8694 (4.5456)
Epoch (train): [4][64040/74490]	Time 0.528 (0.135)	Data 0.484 (0.058)	Loss 3.8198 (4.5440)
Epoch (train): [4][65040/74490]	Time 0.078 (0.135)	Data 0.000 (0.058)	Loss 7.1671 (4.5398)
Epoch (train): [4][66040/74490]	Time 0.087 (0.134)	Data 0.000 (0.058)	Loss 3.9306 (4.5371)
Epoch (train): [4][67040/74490]	Time 0.084 (0.134)	Data 0.000 (0.058)	Loss 4.4927 (4.5356)
Epoch (train): [4][68040/74490]	Time 0.081 (0.134)	Data 0.000 (0.058)	Loss 3.6397 (4.5308)
Epoch (train): [4][69040/74490]	Time 0.085 (0.134)	Data 0.023 (0.058)	Loss 2.7149 (4.5287)
Epoch (train): [4][70040/74490]	Time 0.455 (0.134)	Data 0.419 (0.058)	Loss 4.9890 (4.5271)
Epoch (train): [4][71040/74490]	Time 0.395 (0.134)	Data 0.361 (0.058)	Loss 9.1806 (4.5226)
Epoch (train): [4][72040/74490]	Time 0.078 (0.134)	Data 0.000 (0.058)	Loss 3.3205 (4.5192)
Epoch (train): [4][73040/74490]	Time 0.427 (0.134)	Data 0.386 (0.058)	Loss 2.5674 (4.5156)
Epoch (train): [4][74040/74490]	Time 0.360 (0.134)	Data 0.325 (0.058)	Loss 13.3356 (4.5105)
Epoch (train): [5][550/74490]	Time 0.084 (0.132)	Data 0.000 (0.055)	Loss 3.7693 (4.2173)
Epoch (train): [5][1550/74490]	Time 0.070 (0.130)	Data 0.000 (0.055)	Loss 7.0277 (4.1724)
Epoch (train): [5][2550/74490]	Time 0.083 (0.130)	Data 0.000 (0.054)	Loss 8.8805 (4.1729)
Epoch (train): [5][3550/74490]	Time 0.081 (0.130)	Data 0.001 (0.054)	Loss 4.1020 (4.1825)
Epoch (train): [5][4550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 5.5451 (4.1677)
Epoch (train): [5][5550/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 1.6292 (4.1337)
Epoch (train): [5][6550/74490]	Time 0.083 (0.130)	Data 0.000 (0.054)	Loss 2.5180 (4.1324)
Epoch (train): [5][7550/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 4.2054 (4.1402)
Epoch (train): [5][8550/74490]	Time 0.087 (0.130)	Data 0.003 (0.054)	Loss 2.2969 (4.1253)
Epoch (train): [5][9550/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 4.9299 (4.1254)
Epoch (train): [5][10550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 1.8682 (4.1232)
Epoch (train): [5][11550/74490]	Time 0.529 (0.131)	Data 0.494 (0.055)	Loss 3.4974 (4.1247)
Epoch (train): [5][12550/74490]	Time 0.081 (0.131)	Data 0.000 (0.055)	Loss 1.7900 (4.1156)
Epoch (train): [5][13550/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 9.2897 (4.1056)
Epoch (train): [5][14550/74490]	Time 0.078 (0.131)	Data 0.000 (0.055)	Loss 2.0813 (4.0953)
Epoch (train): [5][15550/74490]	Time 0.078 (0.131)	Data 0.000 (0.055)	Loss 4.2877 (4.0926)
Epoch (train): [5][16550/74490]	Time 0.070 (0.131)	Data 0.000 (0.055)	Loss 4.4379 (4.0950)
Epoch (train): [5][17550/74490]	Time 0.072 (0.132)	Data 0.000 (0.056)	Loss 3.7553 (4.0901)
Epoch (train): [5][18550/74490]	Time 0.160 (0.132)	Data 0.127 (0.056)	Loss 4.8030 (4.0852)
Epoch (train): [5][19550/74490]	Time 0.080 (0.132)	Data 0.000 (0.057)	Loss 3.5723 (4.0861)
Epoch (train): [5][20550/74490]	Time 0.084 (0.132)	Data 0.000 (0.056)	Loss 8.1885 (4.0888)
Epoch (train): [5][21550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 3.7550 (4.0847)
Epoch (train): [5][22550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.4708 (4.0789)
Epoch (train): [5][23550/74490]	Time 0.090 (0.132)	Data 0.000 (0.056)	Loss 7.4564 (4.0812)
Epoch (train): [5][24550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.9842 (4.0789)
Epoch (train): [5][25550/74490]	Time 0.080 (0.132)	Data 0.000 (0.056)	Loss 2.4458 (4.0796)
Epoch (train): [5][26550/74490]	Time 0.082 (0.132)	Data 0.000 (0.056)	Loss 3.7404 (4.0766)
Epoch (train): [5][27550/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 3.0340 (4.0758)
Epoch (train): [5][28550/74490]	Time 0.086 (0.132)	Data 0.000 (0.056)	Loss 1.2398 (4.0744)
Epoch (train): [5][29550/74490]	Time 0.084 (0.132)	Data 0.000 (0.056)	Loss 6.9661 (4.0732)
Epoch (train): [5][30550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.4985 (4.0737)
Epoch (train): [5][31550/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 4.4467 (4.0707)
Epoch (train): [5][32550/74490]	Time 0.086 (0.132)	Data 0.000 (0.056)	Loss 2.1401 (4.0685)
Epoch (train): [5][33550/74490]	Time 0.094 (0.132)	Data 0.000 (0.056)	Loss 3.6160 (4.0667)
Epoch (train): [5][34550/74490]	Time 0.084 (0.132)	Data 0.000 (0.056)	Loss 2.1293 (4.0656)
Epoch (train): [5][35550/74490]	Time 0.087 (0.131)	Data 0.000 (0.055)	Loss 2.5546 (4.0644)
Epoch (train): [5][36550/74490]	Time 0.084 (0.131)	Data 0.000 (0.055)	Loss 5.9266 (4.0629)
Epoch (train): [5][37550/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 3.3369 (4.0599)
Epoch (train): [5][38550/74490]	Time 0.080 (0.131)	Data 0.000 (0.055)	Loss 10.5456 (4.0561)
Epoch (train): [5][39550/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 5.7791 (4.0533)
Epoch (train): [5][40550/74490]	Time 0.090 (0.131)	Data 0.000 (0.055)	Loss 6.0771 (4.0495)
Epoch (train): [5][41550/74490]	Time 0.089 (0.131)	Data 0.000 (0.055)	Loss 3.8653 (4.0489)
Epoch (train): [5][42550/74490]	Time 0.082 (0.131)	Data 0.000 (0.054)	Loss 4.7074 (4.0466)
Epoch (train): [5][43550/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.4432 (4.0465)
Epoch (train): [5][44550/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 1.9130 (4.0438)
Epoch (train): [5][45550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 9.6105 (4.0396)
Epoch (train): [5][46550/74490]	Time 0.096 (0.130)	Data 0.000 (0.054)	Loss 2.9097 (4.0409)
Epoch (train): [5][47550/74490]	Time 0.077 (0.130)	Data 0.028 (0.054)	Loss 3.8083 (4.0363)
Epoch (train): [5][48550/74490]	Time 0.086 (0.130)	Data 0.002 (0.054)	Loss 4.7143 (4.0358)
Epoch (train): [5][49550/74490]	Time 0.122 (0.130)	Data 0.088 (0.054)	Loss 2.5541 (4.0321)
Epoch (train): [5][50550/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 5.9153 (4.0296)
Epoch (train): [5][51550/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 1.2818 (4.0292)
Epoch (train): [5][52550/74490]	Time 0.158 (0.130)	Data 0.120 (0.054)	Loss 3.8815 (4.0275)
Epoch (train): [5][53550/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 2.7629 (4.0263)
Epoch (train): [5][54550/74490]	Time 0.099 (0.130)	Data 0.000 (0.054)	Loss 5.8861 (4.0240)
Epoch (train): [5][55550/74490]	Time 0.075 (0.130)	Data 0.000 (0.054)	Loss 3.8427 (4.0197)
Epoch (train): [5][56550/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 6.2459 (4.0179)
Epoch (train): [5][57550/74490]	Time 0.092 (0.130)	Data 0.000 (0.054)	Loss 1.4713 (4.0152)
Epoch (train): [5][58550/74490]	Time 0.181 (0.130)	Data 0.141 (0.054)	Loss 2.8685 (4.0123)
Epoch (train): [5][59550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 2.5928 (4.0107)
Epoch (train): [5][60550/74490]	Time 0.140 (0.130)	Data 0.103 (0.054)	Loss 4.8140 (4.0070)
Epoch (train): [5][61550/74490]	Time 0.087 (0.130)	Data 0.000 (0.054)	Loss 2.7314 (4.0076)
Epoch (train): [5][62550/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.2216 (4.0048)
Epoch (train): [5][63550/74490]	Time 0.089 (0.130)	Data 0.000 (0.054)	Loss 3.5194 (4.0031)
Epoch (train): [5][64550/74490]	Time 0.351 (0.130)	Data 0.315 (0.054)	Loss 2.2041 (4.0021)
Epoch (train): [5][65550/74490]	Time 0.450 (0.130)	Data 0.411 (0.054)	Loss 15.9300 (4.0011)
Epoch (train): [5][66550/74490]	Time 0.176 (0.131)	Data 0.135 (0.054)	Loss 3.5363 (3.9990)
Epoch (train): [5][67550/74490]	Time 0.085 (0.131)	Data 0.000 (0.055)	Loss 2.4967 (3.9977)
Epoch (train): [5][68550/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 2.9045 (3.9956)
Epoch (train): [5][69550/74490]	Time 0.079 (0.131)	Data 0.001 (0.055)	Loss 3.3790 (3.9932)
Epoch (train): [5][70550/74490]	Time 0.092 (0.131)	Data 0.000 (0.055)	Loss 5.7808 (3.9919)
Epoch (train): [5][71550/74490]	Time 0.089 (0.131)	Data 0.000 (0.055)	Loss 3.0162 (3.9895)
Epoch (train): [5][72550/74490]	Time 0.677 (0.131)	Data 0.639 (0.055)	Loss 3.3252 (3.9867)
Epoch (train): [5][73550/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 4.3319 (3.9853)
Epoch (train): [6][60/74490]	Time 0.080 (0.146)	Data 0.000 (0.069)	Loss 2.9914 (3.1934)
Epoch (train): [6][1060/74490]	Time 0.085 (0.125)	Data 0.000 (0.050)	Loss 2.9254 (3.6531)
Epoch (train): [6][2060/74490]	Time 0.082 (0.125)	Data 0.000 (0.051)	Loss 5.7368 (3.6816)
Epoch (train): [6][3060/74490]	Time 0.086 (0.125)	Data 0.000 (0.050)	Loss 2.9208 (3.6911)
Epoch (train): [6][4060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 3.6727 (3.6833)
Epoch (train): [6][5060/74490]	Time 0.096 (0.125)	Data 0.000 (0.049)	Loss 2.4257 (3.7021)
Epoch (train): [6][6060/74490]	Time 0.082 (0.125)	Data 0.000 (0.050)	Loss 4.7792 (3.6956)
Epoch (train): [6][7060/74490]	Time 0.082 (0.125)	Data 0.000 (0.049)	Loss 3.8928 (3.6870)
Epoch (train): [6][8060/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 2.2871 (3.6891)
Epoch (train): [6][9060/74490]	Time 0.089 (0.126)	Data 0.000 (0.050)	Loss 3.7318 (3.6815)
Epoch (train): [6][10060/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 2.3558 (3.6906)
Epoch (train): [6][11060/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 3.1304 (3.6913)
Epoch (train): [6][12060/74490]	Time 0.094 (0.126)	Data 0.000 (0.050)	Loss 2.7280 (3.6877)
Epoch (train): [6][13060/74490]	Time 0.084 (0.126)	Data 0.000 (0.050)	Loss 2.3805 (3.6814)
Epoch (train): [6][14060/74490]	Time 0.087 (0.126)	Data 0.002 (0.050)	Loss 4.7527 (3.6834)
Epoch (train): [6][15060/74490]	Time 0.079 (0.126)	Data 0.000 (0.050)	Loss 3.2174 (3.6832)
Epoch (train): [6][16060/74490]	Time 0.089 (0.126)	Data 0.001 (0.050)	Loss 2.5881 (3.6853)
Epoch (train): [6][17060/74490]	Time 0.079 (0.126)	Data 0.000 (0.050)	Loss 4.7498 (3.6859)
Epoch (train): [6][18060/74490]	Time 0.099 (0.126)	Data 0.000 (0.050)	Loss 3.7847 (3.6854)
Epoch (train): [6][19060/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 3.1952 (3.6885)
Epoch (train): [6][20060/74490]	Time 0.082 (0.126)	Data 0.000 (0.050)	Loss 3.5194 (3.6867)
Epoch (train): [6][21060/74490]	Time 0.090 (0.126)	Data 0.000 (0.050)	Loss 2.1210 (3.6841)
Epoch (train): [6][22060/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 3.2779 (3.6803)
Epoch (train): [6][23060/74490]	Time 0.086 (0.126)	Data 0.002 (0.050)	Loss 3.4046 (3.6765)
Epoch (train): [6][24060/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 3.3655 (3.6781)
Epoch (train): [6][25060/74490]	Time 0.089 (0.126)	Data 0.000 (0.050)	Loss 5.9292 (3.6800)
Epoch (train): [6][26060/74490]	Time 0.082 (0.126)	Data 0.000 (0.050)	Loss 5.9465 (3.6710)
Epoch (train): [6][27060/74490]	Time 0.094 (0.125)	Data 0.000 (0.050)	Loss 2.9150 (3.6706)
Epoch (train): [6][28060/74490]	Time 0.096 (0.125)	Data 0.000 (0.050)	Loss 2.2489 (3.6709)
Epoch (train): [6][29060/74490]	Time 0.091 (0.125)	Data 0.000 (0.050)	Loss 3.7287 (3.6717)
Epoch (train): [6][30060/74490]	Time 0.090 (0.125)	Data 0.000 (0.049)	Loss 2.5575 (3.6714)
Epoch (train): [6][31060/74490]	Time 0.099 (0.125)	Data 0.000 (0.049)	Loss 2.5016 (3.6710)
Epoch (train): [6][32060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 3.5870 (3.6686)
Epoch (train): [6][33060/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 4.0276 (3.6687)
Epoch (train): [6][34060/74490]	Time 0.079 (0.125)	Data 0.000 (0.049)	Loss 8.9554 (3.6666)
Epoch (train): [6][35060/74490]	Time 0.094 (0.125)	Data 0.000 (0.049)	Loss 1.2979 (3.6645)
Epoch (train): [6][36060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 1.8760 (3.6623)
Epoch (train): [6][37060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 2.0693 (3.6590)
Epoch (train): [6][38060/74490]	Time 0.082 (0.125)	Data 0.000 (0.049)	Loss 3.1629 (3.6576)
Epoch (train): [6][39060/74490]	Time 0.077 (0.125)	Data 0.000 (0.049)	Loss 2.4357 (3.6574)
Epoch (train): [6][40060/74490]	Time 0.080 (0.125)	Data 0.000 (0.049)	Loss 3.9798 (3.6565)
Epoch (train): [6][41060/74490]	Time 0.067 (0.125)	Data 0.001 (0.049)	Loss 2.5002 (3.6551)
Epoch (train): [6][42060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 3.8763 (3.6512)
Epoch (train): [6][43060/74490]	Time 0.092 (0.125)	Data 0.000 (0.049)	Loss 14.5349 (3.6501)
Epoch (train): [6][44060/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 3.5407 (3.6504)
Epoch (train): [6][45060/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 3.7447 (3.6493)
Epoch (train): [6][46060/74490]	Time 0.092 (0.125)	Data 0.000 (0.049)	Loss 3.4079 (3.6471)
Epoch (train): [6][47060/74490]	Time 0.081 (0.125)	Data 0.000 (0.049)	Loss 5.5281 (3.6480)
Epoch (train): [6][48060/74490]	Time 0.084 (0.125)	Data 0.000 (0.049)	Loss 5.7246 (3.6436)
Epoch (train): [6][49060/74490]	Time 0.085 (0.125)	Data 0.001 (0.049)	Loss 4.1070 (3.6420)
Epoch (train): [6][50060/74490]	Time 0.085 (0.125)	Data 0.001 (0.049)	Loss 8.9947 (3.6402)
Epoch (train): [6][51060/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 2.6427 (3.6364)
Epoch (train): [6][52060/74490]	Time 0.086 (0.125)	Data 0.000 (0.050)	Loss 5.5915 (3.6343)
Epoch (train): [6][53060/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 1.3666 (3.6346)
Epoch (train): [6][54060/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 2.3634 (3.6333)
Epoch (train): [6][55060/74490]	Time 0.086 (0.125)	Data 0.001 (0.049)	Loss 3.1398 (3.6325)
Epoch (train): [6][56060/74490]	Time 0.098 (0.125)	Data 0.001 (0.049)	Loss 5.7761 (3.6304)
Epoch (train): [6][57060/74490]	Time 0.071 (0.125)	Data 0.000 (0.049)	Loss 1.8979 (3.6287)
Epoch (train): [6][58060/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 2.5851 (3.6268)
Epoch (train): [6][59060/74490]	Time 0.086 (0.125)	Data 0.000 (0.050)	Loss 2.1266 (3.6257)
Epoch (train): [6][60060/74490]	Time 0.070 (0.125)	Data 0.000 (0.049)	Loss 3.2833 (3.6245)
Epoch (train): [6][61060/74490]	Time 0.088 (0.125)	Data 0.000 (0.050)	Loss 4.9813 (3.6246)
Epoch (train): [6][62060/74490]	Time 0.084 (0.125)	Data 0.000 (0.050)	Loss 4.2069 (3.6236)
Epoch (train): [6][63060/74490]	Time 0.102 (0.125)	Data 0.000 (0.050)	Loss 2.6477 (3.6217)
Epoch (train): [6][64060/74490]	Time 0.084 (0.125)	Data 0.001 (0.050)	Loss 2.6125 (3.6187)
Epoch (train): [6][65060/74490]	Time 0.082 (0.125)	Data 0.000 (0.050)	Loss 3.3908 (3.6201)
Epoch (train): [6][66060/74490]	Time 0.080 (0.125)	Data 0.000 (0.050)	Loss 4.5107 (3.6191)
Epoch (train): [6][67060/74490]	Time 0.084 (0.125)	Data 0.000 (0.050)	Loss 2.2480 (3.6177)
Epoch (train): [6][68060/74490]	Time 0.089 (0.126)	Data 0.002 (0.050)	Loss 1.9811 (3.6166)
Epoch (train): [6][69060/74490]	Time 0.086 (0.126)	Data 0.001 (0.050)	Loss 2.6853 (3.6158)
Epoch (train): [6][70060/74490]	Time 0.085 (0.126)	Data 0.001 (0.050)	Loss 2.6212 (3.6163)
Epoch (train): [6][71060/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 2.7254 (3.6147)
Epoch (train): [6][72060/74490]	Time 0.086 (0.126)	Data 0.000 (0.050)	Loss 3.4186 (3.6137)
Epoch (train): [6][73060/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 3.9275 (3.6133)
Epoch (train): [6][74060/74490]	Time 0.084 (0.126)	Data 0.000 (0.050)	Loss 4.5275 (3.6120)
Epoch (train): [7][570/74490]	Time 0.075 (0.127)	Data 0.000 (0.053)	Loss 3.3109 (3.3693)
Epoch (train): [7][1570/74490]	Time 0.083 (0.123)	Data 0.000 (0.049)	Loss 2.5126 (3.4021)
Epoch (train): [7][2570/74490]	Time 0.083 (0.123)	Data 0.000 (0.048)	Loss 4.9098 (3.4356)
Epoch (train): [7][3570/74490]	Time 0.094 (0.122)	Data 0.000 (0.047)	Loss 4.7479 (3.3960)
Epoch (train): [7][4570/74490]	Time 0.086 (0.122)	Data 0.000 (0.046)	Loss 6.6466 (3.3767)
Epoch (train): [7][5570/74490]	Time 0.086 (0.122)	Data 0.000 (0.046)	Loss 3.4986 (3.3827)
Epoch (train): [7][6570/74490]	Time 0.095 (0.123)	Data 0.000 (0.046)	Loss 2.6632 (3.3813)
Epoch (train): [7][7570/74490]	Time 0.086 (0.123)	Data 0.000 (0.047)	Loss 1.9628 (3.3884)
Epoch (train): [7][8570/74490]	Time 0.085 (0.123)	Data 0.001 (0.046)	Loss 3.4633 (3.3874)
Epoch (train): [7][9570/74490]	Time 0.095 (0.123)	Data 0.000 (0.046)	Loss 3.2766 (3.3937)
Epoch (train): [7][10570/74490]	Time 0.088 (0.122)	Data 0.000 (0.046)	Loss 3.4083 (3.3950)
Epoch (train): [7][11570/74490]	Time 0.098 (0.122)	Data 0.000 (0.045)	Loss 1.1297 (3.3860)
Epoch (train): [7][12570/74490]	Time 0.093 (0.122)	Data 0.011 (0.046)	Loss 2.3429 (3.3821)
Epoch (train): [7][13570/74490]	Time 0.090 (0.123)	Data 0.000 (0.046)	Loss 7.4679 (3.3831)
Epoch (train): [7][14570/74490]	Time 0.084 (0.123)	Data 0.000 (0.046)	Loss 1.6354 (3.3875)
Epoch (train): [7][15570/74490]	Time 0.087 (0.123)	Data 0.000 (0.046)	Loss 8.9151 (3.3912)
Epoch (train): [7][16570/74490]	Time 0.083 (0.123)	Data 0.000 (0.046)	Loss 5.8616 (3.3858)
Epoch (train): [7][17570/74490]	Time 0.081 (0.123)	Data 0.000 (0.047)	Loss 2.9238 (3.3865)
Epoch (train): [7][18570/74490]	Time 0.088 (0.123)	Data 0.000 (0.047)	Loss 5.7383 (3.3830)
Epoch (train): [7][19570/74490]	Time 0.086 (0.123)	Data 0.000 (0.047)	Loss 8.3074 (3.3789)
Epoch (train): [7][20570/74490]	Time 0.089 (0.123)	Data 0.000 (0.047)	Loss 2.7262 (3.3787)
Epoch (train): [7][21570/74490]	Time 0.084 (0.123)	Data 0.000 (0.047)	Loss 2.6458 (3.3806)
Epoch (train): [7][22570/74490]	Time 0.085 (0.123)	Data 0.000 (0.047)	Loss 4.5697 (3.3751)
Epoch (train): [7][23570/74490]	Time 0.082 (0.124)	Data 0.000 (0.047)	Loss 3.5156 (3.3788)
Epoch (train): [7][24570/74490]	Time 0.077 (0.123)	Data 0.000 (0.047)	Loss 3.2283 (3.3740)
Epoch (train): [7][25570/74490]	Time 0.082 (0.123)	Data 0.000 (0.047)	Loss 5.7880 (3.3712)
Epoch (train): [7][26570/74490]	Time 0.085 (0.124)	Data 0.000 (0.047)	Loss 3.4019 (3.3690)
Epoch (train): [7][27570/74490]	Time 0.084 (0.124)	Data 0.001 (0.047)	Loss 3.6956 (3.3669)
Epoch (train): [7][28570/74490]	Time 0.088 (0.124)	Data 0.000 (0.047)	Loss 3.2040 (3.3666)
Epoch (train): [7][29570/74490]	Time 0.090 (0.124)	Data 0.000 (0.047)	Loss 7.7089 (3.3645)
Epoch (train): [7][30570/74490]	Time 0.088 (0.124)	Data 0.000 (0.047)	Loss 2.5612 (3.3626)
Epoch (train): [7][31570/74490]	Time 0.086 (0.124)	Data 0.000 (0.047)	Loss 3.0302 (3.3634)
Epoch (train): [7][32570/74490]	Time 0.074 (0.124)	Data 0.000 (0.047)	Loss 2.0688 (3.3611)
Epoch (train): [7][33570/74490]	Time 0.071 (0.124)	Data 0.000 (0.047)	Loss 4.5751 (3.3622)
Epoch (train): [7][34570/74490]	Time 0.079 (0.124)	Data 0.000 (0.047)	Loss 2.1976 (3.3613)
Epoch (train): [7][35570/74490]	Time 0.084 (0.124)	Data 0.000 (0.047)	Loss 2.1548 (3.3602)
Epoch (train): [7][36570/74490]	Time 0.088 (0.124)	Data 0.000 (0.048)	Loss 3.9269 (3.3561)
Epoch (train): [7][37570/74490]	Time 0.069 (0.124)	Data 0.002 (0.048)	Loss 2.4828 (3.3536)
Epoch (train): [7][38570/74490]	Time 0.081 (0.124)	Data 0.000 (0.048)	Loss 2.3336 (3.3553)
Epoch (train): [7][39570/74490]	Time 0.068 (0.124)	Data 0.000 (0.048)	Loss 2.9540 (3.3539)
Epoch (train): [7][40570/74490]	Time 0.082 (0.124)	Data 0.000 (0.048)	Loss 2.1530 (3.3525)
Epoch (train): [7][41570/74490]	Time 0.081 (0.124)	Data 0.000 (0.048)	Loss 4.1739 (3.3531)
Epoch (train): [7][42570/74490]	Time 0.082 (0.124)	Data 0.000 (0.048)	Loss 2.3472 (3.3500)
Epoch (train): [7][43570/74490]	Time 0.089 (0.124)	Data 0.002 (0.048)	Loss 1.7686 (3.3493)
Epoch (train): [7][44570/74490]	Time 0.099 (0.124)	Data 0.000 (0.048)	Loss 1.9803 (3.3454)
Epoch (train): [7][45570/74490]	Time 0.085 (0.124)	Data 0.002 (0.048)	Loss 3.8125 (3.3429)
Epoch (train): [7][46570/74490]	Time 0.090 (0.125)	Data 0.000 (0.048)	Loss 4.8135 (3.3419)
Epoch (train): [7][47570/74490]	Time 0.456 (0.125)	Data 0.416 (0.048)	Loss 2.9201 (3.3405)
Epoch (train): [7][48570/74490]	Time 0.080 (0.125)	Data 0.000 (0.049)	Loss 4.9993 (3.3400)
Epoch (train): [7][49570/74490]	Time 0.084 (0.125)	Data 0.000 (0.049)	Loss 4.3776 (3.3393)
Epoch (train): [7][50570/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 2.5767 (3.3366)
Epoch (train): [7][51570/74490]	Time 0.077 (0.125)	Data 0.000 (0.049)	Loss 2.7986 (3.3354)
Epoch (train): [7][52570/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 3.3924 (3.3338)
Epoch (train): [7][53570/74490]	Time 0.083 (0.126)	Data 0.000 (0.049)	Loss 2.7003 (3.3326)
Epoch (train): [7][54570/74490]	Time 0.088 (0.126)	Data 0.000 (0.049)	Loss 2.9775 (3.3316)
Epoch (train): [7][55570/74490]	Time 0.092 (0.126)	Data 0.000 (0.049)	Loss 3.0919 (3.3305)
Epoch (train): [7][56570/74490]	Time 0.082 (0.126)	Data 0.001 (0.049)	Loss 2.5481 (3.3291)
Epoch (train): [7][57570/74490]	Time 0.086 (0.126)	Data 0.000 (0.049)	Loss 2.0072 (3.3286)
Epoch (train): [7][58570/74490]	Time 0.080 (0.126)	Data 0.000 (0.050)	Loss 1.4303 (3.3293)
Epoch (train): [7][59570/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 3.4031 (3.3282)
Epoch (train): [7][60570/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 2.8838 (3.3252)
Epoch (train): [7][61570/74490]	Time 0.085 (0.126)	Data 0.001 (0.050)	Loss 1.7951 (3.3240)
Epoch (train): [7][62570/74490]	Time 0.082 (0.126)	Data 0.000 (0.050)	Loss 4.9065 (3.3230)
Epoch (train): [7][63570/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 2.8880 (3.3228)
Epoch (train): [7][64570/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 3.6365 (3.3216)
Epoch (train): [7][65570/74490]	Time 0.078 (0.127)	Data 0.000 (0.050)	Loss 2.2251 (3.3209)
Epoch (train): [7][66570/74490]	Time 0.087 (0.127)	Data 0.000 (0.050)	Loss 1.4549 (3.3187)
Epoch (train): [7][67570/74490]	Time 0.085 (0.127)	Data 0.000 (0.050)	Loss 1.4236 (3.3185)
Epoch (train): [7][68570/74490]	Time 0.090 (0.127)	Data 0.001 (0.050)	Loss 1.9821 (3.3187)
Epoch (train): [7][69570/74490]	Time 0.081 (0.127)	Data 0.000 (0.050)	Loss 1.9541 (3.3174)
Epoch (train): [7][70570/74490]	Time 0.089 (0.127)	Data 0.000 (0.050)	Loss 2.6758 (3.3166)
Epoch (train): [7][71570/74490]	Time 0.087 (0.127)	Data 0.000 (0.050)	Loss 1.8746 (3.3148)
Epoch (train): [7][72570/74490]	Time 0.084 (0.127)	Data 0.000 (0.050)	Loss 1.9278 (3.3121)
Epoch (train): [7][73570/74490]	Time 0.132 (0.127)	Data 0.094 (0.050)	Loss 3.8564 (3.3096)
Epoch (train): [8][80/74490]	Time 0.393 (0.150)	Data 0.354 (0.076)	Loss 1.8910 (2.9702)
Epoch (train): [8][1080/74490]	Time 0.088 (0.133)	Data 0.000 (0.057)	Loss 2.6646 (3.0776)
Epoch (train): [8][2080/74490]	Time 0.093 (0.132)	Data 0.000 (0.056)	Loss 2.2250 (3.1768)
Epoch (train): [8][3080/74490]	Time 0.085 (0.132)	Data 0.000 (0.055)	Loss 3.9815 (3.1280)
Epoch (train): [8][4080/74490]	Time 0.202 (0.131)	Data 0.163 (0.055)	Loss 9.5865 (3.1126)
Epoch (train): [8][5080/74490]	Time 0.081 (0.131)	Data 0.000 (0.054)	Loss 1.5141 (3.1178)
Epoch (train): [8][6080/74490]	Time 0.089 (0.131)	Data 0.000 (0.054)	Loss 2.9594 (3.1174)
Epoch (train): [8][7080/74490]	Time 0.077 (0.131)	Data 0.000 (0.054)	Loss 2.8261 (3.1123)
Epoch (train): [8][8080/74490]	Time 0.082 (0.131)	Data 0.000 (0.054)	Loss 3.4163 (3.1221)
Epoch (train): [8][9080/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 11.5331 (3.1152)
Epoch (train): [8][10080/74490]	Time 0.083 (0.130)	Data 0.000 (0.054)	Loss 5.1740 (3.1037)
Epoch (train): [8][11080/74490]	Time 0.081 (0.130)	Data 0.000 (0.053)	Loss 1.0760 (3.1065)
Epoch (train): [8][12080/74490]	Time 0.085 (0.130)	Data 0.000 (0.053)	Loss 5.4501 (3.1096)
Epoch (train): [8][13080/74490]	Time 0.089 (0.130)	Data 0.000 (0.054)	Loss 3.7167 (3.1036)
Epoch (train): [8][14080/74490]	Time 0.084 (0.130)	Data 0.000 (0.053)	Loss 3.1744 (3.1030)
Epoch (train): [8][15080/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 7.2866 (3.1010)
Epoch (train): [8][16080/74490]	Time 0.079 (0.131)	Data 0.000 (0.054)	Loss 3.0446 (3.0974)
Epoch (train): [8][17080/74490]	Time 0.085 (0.131)	Data 0.001 (0.054)	Loss 1.6810 (3.0934)
Epoch (train): [8][18080/74490]	Time 0.090 (0.131)	Data 0.000 (0.054)	Loss 6.2656 (3.0956)
Epoch (train): [8][19080/74490]	Time 0.080 (0.131)	Data 0.000 (0.054)	Loss 3.6269 (3.0971)
Epoch (train): [8][20080/74490]	Time 0.507 (0.131)	Data 0.466 (0.053)	Loss 3.9990 (3.0990)
Epoch (train): [8][21080/74490]	Time 0.077 (0.131)	Data 0.000 (0.053)	Loss 2.2651 (3.1016)
Epoch (train): [8][22080/74490]	Time 0.086 (0.131)	Data 0.000 (0.053)	Loss 2.4888 (3.1036)
Epoch (train): [8][23080/74490]	Time 0.082 (0.130)	Data 0.001 (0.054)	Loss 4.4743 (3.1030)
Epoch (train): [8][24080/74490]	Time 0.082 (0.130)	Data 0.000 (0.053)	Loss 3.0075 (3.1027)
Epoch (train): [8][25080/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.6318 (3.1017)
Epoch (train): [8][26080/74490]	Time 0.081 (0.130)	Data 0.000 (0.053)	Loss 6.2704 (3.1003)
Epoch (train): [8][27080/74490]	Time 0.083 (0.130)	Data 0.000 (0.053)	Loss 2.9342 (3.0979)
Epoch (train): [8][28080/74490]	Time 0.099 (0.130)	Data 0.000 (0.053)	Loss 0.7380 (3.0943)
Epoch (train): [8][29080/74490]	Time 0.085 (0.130)	Data 0.000 (0.053)	Loss 2.4576 (3.0986)
Epoch (train): [8][30080/74490]	Time 0.085 (0.130)	Data 0.000 (0.053)	Loss 2.9072 (3.0981)
Epoch (train): [8][31080/74490]	Time 0.086 (0.130)	Data 0.001 (0.053)	Loss 2.2478 (3.0966)
Epoch (train): [8][32080/74490]	Time 0.084 (0.130)	Data 0.000 (0.053)	Loss 5.2855 (3.0977)
Epoch (train): [8][33080/74490]	Time 0.086 (0.130)	Data 0.003 (0.053)	Loss 2.4512 (3.1011)
Epoch (train): [8][34080/74490]	Time 0.101 (0.130)	Data 0.000 (0.053)	Loss 0.9474 (3.0969)
Epoch (train): [8][35080/74490]	Time 0.086 (0.130)	Data 0.000 (0.053)	Loss 5.6884 (3.0947)
Epoch (train): [8][36080/74490]	Time 0.087 (0.130)	Data 0.003 (0.053)	Loss 2.2185 (3.0967)
Epoch (train): [8][37080/74490]	Time 0.097 (0.130)	Data 0.000 (0.054)	Loss 1.8129 (3.0970)
Epoch (train): [8][38080/74490]	Time 0.090 (0.130)	Data 0.000 (0.054)	Loss 1.7656 (3.0990)
Epoch (train): [8][39080/74490]	Time 0.073 (0.131)	Data 0.000 (0.054)	Loss 4.3352 (3.0981)
Epoch (train): [8][40080/74490]	Time 0.085 (0.131)	Data 0.000 (0.054)	Loss 3.0026 (3.0990)
Epoch (train): [8][41080/74490]	Time 0.088 (0.131)	Data 0.000 (0.054)	Loss 1.7817 (3.0961)
Epoch (train): [8][42080/74490]	Time 0.383 (0.131)	Data 0.343 (0.054)	Loss 2.2755 (3.0946)
Epoch (train): [8][43080/74490]	Time 0.475 (0.131)	Data 0.433 (0.054)	Loss 2.3034 (3.0913)
Epoch (train): [8][44080/74490]	Time 0.390 (0.131)	Data 0.355 (0.054)	Loss 1.9453 (3.0921)
Epoch (train): [8][45080/74490]	Time 0.462 (0.131)	Data 0.423 (0.054)	Loss 2.7685 (3.0911)
Epoch (train): [8][46080/74490]	Time 0.087 (0.131)	Data 0.001 (0.054)	Loss 2.1486 (3.0903)
Epoch (train): [8][47080/74490]	Time 0.114 (0.131)	Data 0.074 (0.054)	Loss 2.2779 (3.0923)
Epoch (train): [8][48080/74490]	Time 0.102 (0.131)	Data 0.000 (0.054)	Loss 2.4228 (3.0913)
Epoch (train): [8][49080/74490]	Time 0.075 (0.131)	Data 0.004 (0.054)	Loss 2.9821 (3.0910)
Epoch (train): [8][50080/74490]	Time 0.084 (0.131)	Data 0.000 (0.054)	Loss 1.7409 (3.0905)
Epoch (train): [8][51080/74490]	Time 0.084 (0.131)	Data 0.001 (0.054)	Loss 2.4048 (3.0900)
Epoch (train): [8][52080/74490]	Time 0.077 (0.131)	Data 0.000 (0.054)	Loss 1.0194 (3.0901)
Epoch (train): [8][53080/74490]	Time 0.072 (0.131)	Data 0.000 (0.054)	Loss 3.7029 (3.0905)
Epoch (train): [8][54080/74490]	Time 0.090 (0.131)	Data 0.000 (0.054)	Loss 2.8003 (3.0893)
Epoch (train): [8][55080/74490]	Time 0.282 (0.131)	Data 0.233 (0.054)	Loss 1.2162 (3.0905)
Epoch (train): [8][56080/74490]	Time 0.154 (0.131)	Data 0.113 (0.054)	Loss 2.5087 (3.0889)
Epoch (train): [8][57080/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 1.7202 (3.0889)
Epoch (train): [8][58080/74490]	Time 0.074 (0.131)	Data 0.000 (0.055)	Loss 1.6588 (3.0882)
Epoch (train): [8][59080/74490]	Time 0.081 (0.131)	Data 0.000 (0.055)	Loss 2.1012 (3.0888)
Epoch (train): [8][60080/74490]	Time 0.081 (0.131)	Data 0.000 (0.055)	Loss 1.4308 (3.0870)
Epoch (train): [8][61080/74490]	Time 0.084 (0.131)	Data 0.000 (0.055)	Loss 2.7819 (3.0865)
Epoch (train): [8][62080/74490]	Time 0.087 (0.131)	Data 0.000 (0.055)	Loss 2.9239 (3.0860)
Epoch (train): [8][63080/74490]	Time 0.208 (0.131)	Data 0.172 (0.055)	Loss 3.1308 (3.0861)
Epoch (train): [8][64080/74490]	Time 0.087 (0.131)	Data 0.000 (0.055)	Loss 3.2921 (3.0849)
Epoch (train): [8][65080/74490]	Time 0.085 (0.131)	Data 0.000 (0.055)	Loss 1.6226 (3.0836)
Epoch (train): [8][66080/74490]	Time 0.099 (0.131)	Data 0.000 (0.055)	Loss 1.0065 (3.0808)
Epoch (train): [8][67080/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 4.5425 (3.0806)
Epoch (train): [8][68080/74490]	Time 0.084 (0.132)	Data 0.000 (0.055)	Loss 3.1524 (3.0788)
Epoch (train): [8][69080/74490]	Time 0.084 (0.132)	Data 0.000 (0.055)	Loss 2.2885 (3.0774)
Epoch (train): [8][70080/74490]	Time 0.085 (0.132)	Data 0.000 (0.055)	Loss 1.2819 (3.0773)
Epoch (train): [8][71080/74490]	Time 0.084 (0.132)	Data 0.000 (0.055)	Loss 1.9373 (3.0765)
Epoch (train): [8][72080/74490]	Time 0.081 (0.132)	Data 0.000 (0.055)	Loss 6.1547 (3.0763)
Epoch (train): [8][73080/74490]	Time 0.095 (0.132)	Data 0.001 (0.055)	Loss 1.7419 (3.0753)
Epoch (train): [8][74080/74490]	Time 0.083 (0.132)	Data 0.000 (0.055)	Loss 1.1296 (3.0747)
Epoch (train): [9][590/74490]	Time 0.084 (0.134)	Data 0.003 (0.062)	Loss 1.9970 (2.9179)
Epoch (train): [9][1590/74490]	Time 0.078 (0.133)	Data 0.000 (0.059)	Loss 2.5427 (2.9170)
Epoch (train): [9][2590/74490]	Time 0.085 (0.133)	Data 0.000 (0.058)	Loss 5.3814 (2.8798)
Epoch (train): [9][3590/74490]	Time 0.089 (0.133)	Data 0.000 (0.057)	Loss 1.3242 (2.8642)
Epoch (train): [9][4590/74490]	Time 0.231 (0.133)	Data 0.186 (0.057)	Loss 2.1428 (2.8658)
Epoch (train): [9][5590/74490]	Time 0.081 (0.134)	Data 0.000 (0.058)	Loss 0.7714 (2.8601)
Epoch (train): [9][6590/74490]	Time 0.201 (0.134)	Data 0.148 (0.058)	Loss 3.0216 (2.8556)
Epoch (train): [9][7590/74490]	Time 0.087 (0.134)	Data 0.000 (0.058)	Loss 2.2050 (2.8588)
Epoch (train): [9][8590/74490]	Time 0.497 (0.134)	Data 0.449 (0.059)	Loss 3.2386 (2.8714)
Epoch (train): [9][9590/74490]	Time 0.088 (0.134)	Data 0.000 (0.059)	Loss 2.5801 (2.8639)
Epoch (train): [9][10590/74490]	Time 0.081 (0.135)	Data 0.020 (0.059)	Loss 7.6586 (2.8740)
Epoch (train): [9][11590/74490]	Time 0.088 (0.135)	Data 0.000 (0.059)	Loss 3.7258 (2.8725)
Epoch (train): [9][12590/74490]	Time 0.089 (0.135)	Data 0.000 (0.059)	Loss 3.7125 (2.8712)
Epoch (train): [9][13590/74490]	Time 0.084 (0.135)	Data 0.000 (0.058)	Loss 2.8936 (2.8713)
Epoch (train): [9][14590/74490]	Time 0.407 (0.134)	Data 0.364 (0.058)	Loss 1.6891 (2.8681)
Epoch (train): [9][15590/74490]	Time 0.390 (0.134)	Data 0.339 (0.057)	Loss 5.1822 (2.8722)
Epoch (train): [9][16590/74490]	Time 0.081 (0.134)	Data 0.000 (0.057)	Loss 3.3244 (2.8790)
Epoch (train): [9][17590/74490]	Time 0.099 (0.133)	Data 0.000 (0.057)	Loss 1.7295 (2.8773)
Epoch (train): [9][18590/74490]	Time 0.304 (0.133)	Data 0.267 (0.057)	Loss 1.0104 (2.8727)
Epoch (train): [9][19590/74490]	Time 0.431 (0.133)	Data 0.378 (0.056)	Loss 1.5351 (2.8669)
Epoch (train): [9][20590/74490]	Time 0.395 (0.132)	Data 0.352 (0.056)	Loss 6.8155 (2.8726)
Epoch (train): [9][21590/74490]	Time 0.086 (0.132)	Data 0.000 (0.056)	Loss 4.9403 (2.8740)
Epoch (train): [9][22590/74490]	Time 0.091 (0.132)	Data 0.000 (0.055)	Loss 2.8725 (2.8721)
Epoch (train): [9][23590/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 4.6625 (2.8713)
Epoch (train): [9][24590/74490]	Time 0.086 (0.131)	Data 0.000 (0.055)	Loss 3.4524 (2.8762)
Epoch (train): [9][25590/74490]	Time 0.081 (0.131)	Data 0.000 (0.055)	Loss 5.5950 (2.8721)
Epoch (train): [9][26590/74490]	Time 0.074 (0.131)	Data 0.000 (0.054)	Loss 1.5984 (2.8752)
Epoch (train): [9][27590/74490]	Time 0.082 (0.131)	Data 0.000 (0.054)	Loss 4.8459 (2.8784)
Epoch (train): [9][28590/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.6114 (2.8763)
Epoch (train): [9][29590/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 6.5124 (2.8807)
Epoch (train): [9][30590/74490]	Time 0.083 (0.130)	Data 0.000 (0.054)	Loss 1.3398 (2.8779)
Epoch (train): [9][31590/74490]	Time 0.080 (0.130)	Data 0.000 (0.053)	Loss 1.7786 (2.8770)
Epoch (train): [9][32590/74490]	Time 0.089 (0.130)	Data 0.000 (0.053)	Loss 1.8230 (2.8777)
Epoch (train): [9][33590/74490]	Time 0.310 (0.130)	Data 0.271 (0.053)	Loss 1.9935 (2.8776)
Epoch (train): [9][34590/74490]	Time 0.438 (0.129)	Data 0.395 (0.053)	Loss 3.9271 (2.8750)
Epoch (train): [9][35590/74490]	Time 0.082 (0.129)	Data 0.000 (0.053)	Loss 2.4187 (2.8737)
Epoch (train): [9][36590/74490]	Time 0.082 (0.129)	Data 0.017 (0.053)	Loss 1.3557 (2.8739)
Epoch (train): [9][37590/74490]	Time 0.428 (0.129)	Data 0.390 (0.053)	Loss 4.1513 (2.8737)
Epoch (train): [9][38590/74490]	Time 0.090 (0.129)	Data 0.010 (0.053)	Loss 2.8175 (2.8746)
Epoch (train): [9][39590/74490]	Time 0.083 (0.129)	Data 0.000 (0.053)	Loss 2.0785 (2.8754)
Epoch (train): [9][40590/74490]	Time 0.087 (0.129)	Data 0.000 (0.053)	Loss 2.5178 (2.8746)
Epoch (train): [9][41590/74490]	Time 0.094 (0.129)	Data 0.000 (0.052)	Loss 3.1963 (2.8757)
Epoch (train): [9][42590/74490]	Time 0.121 (0.129)	Data 0.081 (0.053)	Loss 1.5597 (2.8740)
Epoch (train): [9][43590/74490]	Time 0.088 (0.128)	Data 0.000 (0.052)	Loss 1.6983 (2.8757)
Epoch (train): [9][44590/74490]	Time 0.083 (0.128)	Data 0.000 (0.052)	Loss 1.8621 (2.8759)
Epoch (train): [9][45590/74490]	Time 0.082 (0.128)	Data 0.000 (0.052)	Loss 1.2867 (2.8803)
Epoch (train): [9][46590/74490]	Time 0.082 (0.128)	Data 0.001 (0.052)	Loss 1.9652 (2.8804)
Epoch (train): [9][47590/74490]	Time 0.084 (0.128)	Data 0.000 (0.052)	Loss 1.9941 (2.8832)
Epoch (train): [9][48590/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 1.6600 (2.8850)
Epoch (train): [9][49590/74490]	Time 0.336 (0.128)	Data 0.299 (0.052)	Loss 2.9660 (2.8850)
Epoch (train): [9][50590/74490]	Time 0.295 (0.128)	Data 0.254 (0.052)	Loss 2.0662 (2.8862)
Epoch (train): [9][51590/74490]	Time 0.348 (0.128)	Data 0.305 (0.052)	Loss 1.6334 (2.8846)
Epoch (train): [9][52590/74490]	Time 0.082 (0.128)	Data 0.020 (0.052)	Loss 5.8187 (2.8848)
Epoch (train): [9][53590/74490]	Time 0.089 (0.128)	Data 0.000 (0.052)	Loss 1.2527 (2.8848)
Epoch (train): [9][54590/74490]	Time 0.199 (0.128)	Data 0.158 (0.052)	Loss 3.3406 (2.8849)
Epoch (train): [9][55590/74490]	Time 0.390 (0.128)	Data 0.355 (0.052)	Loss 1.0446 (2.8857)
Epoch (train): [9][56590/74490]	Time 0.097 (0.128)	Data 0.000 (0.052)	Loss 3.2715 (2.8836)
Epoch (train): [9][57590/74490]	Time 0.083 (0.128)	Data 0.000 (0.052)	Loss 3.6151 (2.8830)
Epoch (train): [9][58590/74490]	Time 0.086 (0.128)	Data 0.000 (0.051)	Loss 2.1468 (2.8833)
Epoch (train): [9][59590/74490]	Time 0.084 (0.128)	Data 0.000 (0.051)	Loss 1.3194 (2.8832)
Epoch (train): [9][60590/74490]	Time 0.080 (0.127)	Data 0.000 (0.051)	Loss 1.5160 (2.8824)
Epoch (train): [9][61590/74490]	Time 0.096 (0.127)	Data 0.000 (0.051)	Loss 3.5736 (2.8829)
Epoch (train): [9][62590/74490]	Time 0.335 (0.128)	Data 0.300 (0.052)	Loss 3.1128 (2.8824)
Epoch (train): [9][63590/74490]	Time 0.296 (0.128)	Data 0.259 (0.052)	Loss 3.4507 (2.8810)
Epoch (train): [9][64590/74490]	Time 0.332 (0.128)	Data 0.296 (0.052)	Loss 2.6466 (2.8813)
Epoch (train): [9][65590/74490]	Time 0.095 (0.128)	Data 0.055 (0.052)	Loss 2.7509 (2.8808)
Epoch (train): [9][66590/74490]	Time 0.083 (0.128)	Data 0.000 (0.052)	Loss 5.4540 (2.8795)
Epoch (train): [9][67590/74490]	Time 0.094 (0.128)	Data 0.002 (0.052)	Loss 1.5075 (2.8791)
Epoch (train): [9][68590/74490]	Time 0.088 (0.128)	Data 0.000 (0.052)	Loss 4.0243 (2.8786)
Epoch (train): [9][69590/74490]	Time 0.081 (0.128)	Data 0.041 (0.052)	Loss 1.7372 (2.8802)
Epoch (train): [9][70590/74490]	Time 0.084 (0.128)	Data 0.015 (0.052)	Loss 2.5708 (2.8808)
Epoch (train): [9][71590/74490]	Time 0.084 (0.128)	Data 0.000 (0.052)	Loss 5.5073 (2.8808)
Epoch (train): [9][72590/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 2.5941 (2.8807)
Epoch (train): [9][73590/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 1.5385 (2.8798)
Epoch (train): [10][100/74490]	Time 0.088 (0.150)	Data 0.000 (0.073)	Loss 1.8034 (2.7723)
Epoch (train): [10][1100/74490]	Time 0.327 (0.137)	Data 0.277 (0.061)	Loss 3.3618 (2.6637)
Epoch (train): [10][2100/74490]	Time 0.085 (0.137)	Data 0.000 (0.060)	Loss 1.4164 (2.6998)
Epoch (train): [10][3100/74490]	Time 0.086 (0.136)	Data 0.000 (0.059)	Loss 2.9303 (2.7029)
Epoch (train): [10][4100/74490]	Time 0.081 (0.136)	Data 0.000 (0.059)	Loss 2.1607 (2.6928)
Epoch (train): [10][5100/74490]	Time 0.084 (0.136)	Data 0.000 (0.059)	Loss 1.9816 (2.6967)
Epoch (train): [10][6100/74490]	Time 0.079 (0.136)	Data 0.000 (0.059)	Loss 4.8256 (2.6958)
Epoch (train): [10][7100/74490]	Time 0.080 (0.136)	Data 0.000 (0.059)	Loss 2.3723 (2.7026)
Epoch (train): [10][8100/74490]	Time 0.083 (0.136)	Data 0.000 (0.058)	Loss 11.4530 (2.7133)
Epoch (train): [10][9100/74490]	Time 0.084 (0.136)	Data 0.000 (0.058)	Loss 2.6684 (2.7123)
Epoch (train): [10][10100/74490]	Time 0.088 (0.135)	Data 0.000 (0.058)	Loss 1.9700 (2.7063)
Epoch (train): [10][11100/74490]	Time 0.083 (0.135)	Data 0.000 (0.057)	Loss 3.2862 (2.7067)
Epoch (train): [10][12100/74490]	Time 0.080 (0.135)	Data 0.000 (0.058)	Loss 2.4544 (2.7026)
Epoch (train): [10][13100/74490]	Time 0.093 (0.135)	Data 0.000 (0.058)	Loss 1.9395 (2.7027)
Epoch (train): [10][14100/74490]	Time 0.555 (0.135)	Data 0.516 (0.058)	Loss 2.9524 (2.7052)
Epoch (train): [10][15100/74490]	Time 0.318 (0.135)	Data 0.276 (0.058)	Loss 2.1145 (2.6984)
Epoch (train): [10][16100/74490]	Time 0.077 (0.135)	Data 0.003 (0.057)	Loss 1.9364 (2.7023)
Epoch (train): [10][17100/74490]	Time 0.090 (0.135)	Data 0.000 (0.057)	Loss 1.6833 (2.7027)
Epoch (train): [10][18100/74490]	Time 0.072 (0.135)	Data 0.000 (0.057)	Loss 2.5162 (2.7019)
Epoch (train): [10][19100/74490]	Time 0.220 (0.135)	Data 0.181 (0.057)	Loss 2.0102 (2.7060)
Epoch (train): [10][20100/74490]	Time 0.071 (0.135)	Data 0.000 (0.057)	Loss 5.2160 (2.7062)
Epoch (train): [10][21100/74490]	Time 0.102 (0.135)	Data 0.000 (0.057)	Loss 2.5070 (2.7080)
Epoch (train): [10][22100/74490]	Time 0.080 (0.135)	Data 0.000 (0.057)	Loss 7.1627 (2.7109)
Epoch (train): [10][23100/74490]	Time 0.073 (0.135)	Data 0.003 (0.057)	Loss 2.0049 (2.7092)
Epoch (train): [10][24100/74490]	Time 0.081 (0.135)	Data 0.000 (0.057)	Loss 1.2721 (2.7113)
Epoch (train): [10][25100/74490]	Time 0.447 (0.135)	Data 0.408 (0.057)	Loss 3.6056 (2.7122)
Epoch (train): [10][26100/74490]	Time 0.301 (0.135)	Data 0.259 (0.057)	Loss 1.4187 (2.7120)
Epoch (train): [10][27100/74490]	Time 0.080 (0.135)	Data 0.011 (0.058)	Loss 6.8320 (2.7103)
Epoch (train): [10][28100/74490]	Time 0.085 (0.135)	Data 0.016 (0.058)	Loss 1.6155 (2.7153)
Epoch (train): [10][29100/74490]	Time 0.459 (0.135)	Data 0.421 (0.058)	Loss 2.7479 (2.7183)
Epoch (train): [10][30100/74490]	Time 0.435 (0.135)	Data 0.392 (0.058)	Loss 4.2003 (2.7182)
Epoch (train): [10][31100/74490]	Time 0.522 (0.135)	Data 0.487 (0.058)	Loss 2.5072 (2.7161)
Epoch (train): [10][32100/74490]	Time 0.413 (0.135)	Data 0.375 (0.058)	Loss 5.3814 (2.7188)
Epoch (train): [10][33100/74490]	Time 0.084 (0.135)	Data 0.000 (0.058)	Loss 4.1204 (2.7179)
Epoch (train): [10][34100/74490]	Time 0.091 (0.135)	Data 0.000 (0.058)	Loss 2.8766 (2.7168)
Epoch (train): [10][35100/74490]	Time 0.139 (0.135)	Data 0.101 (0.058)	Loss 2.5984 (2.7154)
Epoch (train): [10][36100/74490]	Time 0.283 (0.135)	Data 0.241 (0.057)	Loss 8.5385 (2.7156)
Epoch (train): [10][37100/74490]	Time 0.455 (0.135)	Data 0.414 (0.057)	Loss 2.5887 (2.7174)
Epoch (train): [10][38100/74490]	Time 0.086 (0.135)	Data 0.000 (0.057)	Loss 3.2931 (2.7150)
Epoch (train): [10][39100/74490]	Time 0.097 (0.135)	Data 0.001 (0.058)	Loss 1.6386 (2.7130)
Epoch (train): [10][40100/74490]	Time 0.097 (0.135)	Data 0.000 (0.058)	Loss 4.0025 (2.7134)
Epoch (train): [10][41100/74490]	Time 0.463 (0.135)	Data 0.424 (0.058)	Loss 2.0859 (2.7146)
Epoch (train): [10][42100/74490]	Time 0.087 (0.135)	Data 0.000 (0.058)	Loss 3.3231 (2.7154)
Epoch (train): [10][43100/74490]	Time 0.087 (0.135)	Data 0.000 (0.058)	Loss 1.6997 (2.7150)
Epoch (train): [10][44100/74490]	Time 0.082 (0.135)	Data 0.000 (0.058)	Loss 2.7724 (2.7142)
Epoch (train): [10][45100/74490]	Time 0.084 (0.135)	Data 0.000 (0.058)	Loss 3.7429 (2.7130)
Epoch (train): [10][46100/74490]	Time 0.088 (0.135)	Data 0.000 (0.058)	Loss 4.8167 (2.7133)
Epoch (train): [10][47100/74490]	Time 0.374 (0.135)	Data 0.335 (0.058)	Loss 3.3318 (2.7125)
Epoch (train): [10][48100/74490]	Time 0.084 (0.136)	Data 0.000 (0.058)	Loss 1.9810 (2.7128)
Epoch (train): [10][49100/74490]	Time 0.084 (0.136)	Data 0.001 (0.058)	Loss 3.4936 (2.7124)
Epoch (train): [10][50100/74490]	Time 0.206 (0.136)	Data 0.168 (0.058)	Loss 4.9796 (2.7117)
Epoch (train): [10][51100/74490]	Time 0.577 (0.136)	Data 0.541 (0.058)	Loss 2.9801 (2.7114)
Epoch (train): [10][52100/74490]	Time 0.087 (0.136)	Data 0.003 (0.058)	Loss 1.5318 (2.7122)
Epoch (train): [10][53100/74490]	Time 0.088 (0.136)	Data 0.000 (0.058)	Loss 1.9347 (2.7133)
Epoch (train): [10][54100/74490]	Time 0.088 (0.136)	Data 0.000 (0.058)	Loss 1.7165 (2.7132)
Epoch (train): [10][55100/74490]	Time 0.095 (0.136)	Data 0.000 (0.058)	Loss 1.6126 (2.7133)
Epoch (train): [10][56100/74490]	Time 0.086 (0.136)	Data 0.001 (0.058)	Loss 1.9784 (2.7150)
Epoch (train): [10][57100/74490]	Time 0.098 (0.136)	Data 0.000 (0.058)	Loss 2.3715 (2.7150)
Epoch (train): [10][58100/74490]	Time 0.082 (0.136)	Data 0.000 (0.059)	Loss 1.7110 (2.7135)
Epoch (train): [10][59100/74490]	Time 0.087 (0.136)	Data 0.000 (0.059)	Loss 5.8494 (2.7156)
Epoch (train): [10][60100/74490]	Time 0.092 (0.136)	Data 0.000 (0.059)	Loss 4.0698 (2.7146)
Epoch (train): [10][61100/74490]	Time 0.082 (0.136)	Data 0.000 (0.059)	Loss 5.1620 (2.7166)
Epoch (train): [10][62100/74490]	Time 0.099 (0.136)	Data 0.000 (0.059)	Loss 3.2129 (2.7157)
Epoch (train): [10][63100/74490]	Time 0.082 (0.136)	Data 0.000 (0.059)	Loss 2.4054 (2.7149)
Epoch (train): [10][64100/74490]	Time 0.086 (0.136)	Data 0.000 (0.059)	Loss 1.6165 (2.7148)
Epoch (train): [10][65100/74490]	Time 0.081 (0.136)	Data 0.001 (0.059)	Loss 3.6866 (2.7152)
Epoch (train): [10][66100/74490]	Time 0.452 (0.136)	Data 0.411 (0.059)	Loss 9.1376 (2.7150)
Epoch (train): [10][67100/74490]	Time 0.080 (0.137)	Data 0.000 (0.059)	Loss 3.7904 (2.7152)
Epoch (train): [10][68100/74490]	Time 0.086 (0.137)	Data 0.000 (0.059)	Loss 1.7640 (2.7154)
Epoch (train): [10][69100/74490]	Time 0.088 (0.137)	Data 0.000 (0.059)	Loss 4.3421 (2.7155)
Epoch (train): [10][70100/74490]	Time 0.082 (0.136)	Data 0.000 (0.059)	Loss 1.6038 (2.7141)
Epoch (train): [10][71100/74490]	Time 0.088 (0.136)	Data 0.000 (0.059)	Loss 1.2325 (2.7136)
Epoch (train): [10][72100/74490]	Time 0.087 (0.136)	Data 0.000 (0.059)	Loss 2.5777 (2.7141)
Epoch (train): [10][73100/74490]	Time 0.087 (0.136)	Data 0.000 (0.059)	Loss 1.1191 (2.7145)
Epoch (train): [10][74100/74490]	Time 0.092 (0.136)	Data 0.000 (0.059)	Loss 2.1335 (2.7142)
Epoch (train): [11][610/74490]	Time 0.088 (0.135)	Data 0.000 (0.059)	Loss 1.8727 (2.7111)
Epoch (train): [11][1610/74490]	Time 0.084 (0.134)	Data 0.000 (0.056)	Loss 3.7631 (2.6310)
Epoch (train): [11][2610/74490]	Time 0.088 (0.134)	Data 0.000 (0.056)	Loss 1.1148 (2.6311)
Epoch (train): [11][3610/74490]	Time 0.085 (0.134)	Data 0.000 (0.056)	Loss 2.8685 (2.6066)
Epoch (train): [11][4610/74490]	Time 0.081 (0.134)	Data 0.000 (0.056)	Loss 1.6021 (2.5934)
Epoch (train): [11][5610/74490]	Time 0.093 (0.134)	Data 0.000 (0.056)	Loss 6.4919 (2.5830)
Epoch (train): [11][6610/74490]	Time 0.087 (0.135)	Data 0.000 (0.057)	Loss 1.9925 (2.5742)
Epoch (train): [11][7610/74490]	Time 0.081 (0.135)	Data 0.000 (0.058)	Loss 4.4282 (2.5687)
Epoch (train): [11][8610/74490]	Time 0.081 (0.136)	Data 0.000 (0.058)	Loss 5.1199 (2.5705)
Epoch (train): [11][9610/74490]	Time 0.089 (0.136)	Data 0.000 (0.058)	Loss 2.1056 (2.5731)
Epoch (train): [11][10610/74490]	Time 0.082 (0.136)	Data 0.000 (0.058)	Loss 1.8343 (2.5731)
Epoch (train): [11][11610/74490]	Time 0.098 (0.136)	Data 0.000 (0.058)	Loss 3.4477 (2.5738)
Epoch (train): [11][12610/74490]	Time 0.086 (0.136)	Data 0.000 (0.058)	Loss 3.6145 (2.5776)
Epoch (train): [11][13610/74490]	Time 0.084 (0.136)	Data 0.000 (0.058)	Loss 5.2715 (2.5804)
Epoch (train): [11][14610/74490]	Time 0.088 (0.137)	Data 0.000 (0.059)	Loss 1.3507 (2.5827)
Epoch (train): [11][15610/74490]	Time 0.081 (0.137)	Data 0.000 (0.059)	Loss 6.4434 (2.5867)
Epoch (train): [11][16610/74490]	Time 0.087 (0.137)	Data 0.000 (0.060)	Loss 2.5901 (2.5864)
Epoch (train): [11][17610/74490]	Time 0.084 (0.137)	Data 0.001 (0.060)	Loss 2.2194 (2.5875)
Epoch (train): [11][18610/74490]	Time 0.072 (0.138)	Data 0.000 (0.061)	Loss 1.1650 (2.5836)
Epoch (train): [11][19610/74490]	Time 0.084 (0.138)	Data 0.000 (0.061)	Loss 3.3589 (2.5813)
Epoch (train): [11][20610/74490]	Time 0.082 (0.138)	Data 0.001 (0.061)	Loss 2.7306 (2.5810)
Epoch (train): [11][21610/74490]	Time 0.082 (0.138)	Data 0.000 (0.061)	Loss 3.6380 (2.5808)
Epoch (train): [11][22610/74490]	Time 0.081 (0.138)	Data 0.000 (0.061)	Loss 8.7491 (2.5852)
Epoch (train): [11][23610/74490]	Time 0.086 (0.138)	Data 0.000 (0.061)	Loss 2.8907 (2.5822)
Epoch (train): [11][24610/74490]	Time 0.090 (0.138)	Data 0.000 (0.060)	Loss 1.3311 (2.5809)
Epoch (train): [11][25610/74490]	Time 0.081 (0.137)	Data 0.000 (0.060)	Loss 2.7250 (2.5792)
Epoch (train): [11][26610/74490]	Time 0.087 (0.137)	Data 0.000 (0.060)	Loss 1.4825 (2.5751)
Epoch (train): [11][27610/74490]	Time 0.086 (0.137)	Data 0.000 (0.059)	Loss 3.8595 (2.5741)
Epoch (train): [11][28610/74490]	Time 0.084 (0.137)	Data 0.000 (0.059)	Loss 2.2566 (2.5760)
Epoch (train): [11][29610/74490]	Time 0.098 (0.137)	Data 0.000 (0.060)	Loss 2.0663 (2.5771)
Epoch (train): [11][30610/74490]	Time 0.082 (0.137)	Data 0.000 (0.060)	Loss 0.8972 (2.5743)
Epoch (train): [11][31610/74490]	Time 0.094 (0.137)	Data 0.000 (0.060)	Loss 3.0074 (2.5749)
Epoch (train): [11][32610/74490]	Time 0.087 (0.137)	Data 0.001 (0.060)	Loss 3.5001 (2.5747)
Epoch (train): [11][33610/74490]	Time 0.070 (0.137)	Data 0.000 (0.060)	Loss 1.9512 (2.5714)
Epoch (train): [11][34610/74490]	Time 0.084 (0.137)	Data 0.001 (0.060)	Loss 1.6798 (2.5710)
Epoch (train): [11][35610/74490]	Time 0.072 (0.137)	Data 0.000 (0.060)	Loss 1.5708 (2.5706)
Epoch (train): [11][36610/74490]	Time 0.097 (0.137)	Data 0.000 (0.060)	Loss 1.4479 (2.5690)
Epoch (train): [11][37610/74490]	Time 0.087 (0.137)	Data 0.000 (0.060)	Loss 7.3761 (2.5692)
Epoch (train): [11][38610/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 1.9673 (2.5699)
Epoch (train): [11][39610/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 2.2559 (2.5690)
Epoch (train): [11][40610/74490]	Time 0.090 (0.137)	Data 0.000 (0.060)	Loss 1.8957 (2.5684)
Epoch (train): [11][41610/74490]	Time 0.098 (0.137)	Data 0.000 (0.060)	Loss 4.3960 (2.5673)
Epoch (train): [11][42610/74490]	Time 0.089 (0.137)	Data 0.000 (0.060)	Loss 9.7986 (2.5671)
Epoch (train): [11][43610/74490]	Time 0.197 (0.137)	Data 0.160 (0.060)	Loss 3.7415 (2.5659)
Epoch (train): [11][44610/74490]	Time 0.084 (0.137)	Data 0.000 (0.060)	Loss 1.6523 (2.5664)
Epoch (train): [11][45610/74490]	Time 0.095 (0.137)	Data 0.004 (0.060)	Loss 3.3605 (2.5661)
Epoch (train): [11][46610/74490]	Time 0.089 (0.137)	Data 0.000 (0.060)	Loss 2.4367 (2.5664)
Epoch (train): [11][47610/74490]	Time 0.085 (0.137)	Data 0.000 (0.060)	Loss 1.2743 (2.5656)
Epoch (train): [11][48610/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 5.4732 (2.5652)
Epoch (train): [11][49610/74490]	Time 0.085 (0.137)	Data 0.000 (0.060)	Loss 2.3762 (2.5653)
Epoch (train): [11][50610/74490]	Time 0.096 (0.137)	Data 0.000 (0.060)	Loss 4.0489 (2.5662)
Epoch (train): [11][51610/74490]	Time 0.080 (0.137)	Data 0.000 (0.060)	Loss 1.9037 (2.5671)
Epoch (train): [11][52610/74490]	Time 0.084 (0.137)	Data 0.000 (0.060)	Loss 1.6733 (2.5673)
Epoch (train): [11][53610/74490]	Time 0.082 (0.137)	Data 0.000 (0.060)	Loss 1.8531 (2.5668)
Epoch (train): [11][54610/74490]	Time 0.086 (0.137)	Data 0.000 (0.060)	Loss 2.3242 (2.5676)
Epoch (train): [11][55610/74490]	Time 0.084 (0.137)	Data 0.000 (0.060)	Loss 1.1084 (2.5671)
Epoch (train): [11][56610/74490]	Time 0.071 (0.137)	Data 0.001 (0.060)	Loss 2.6388 (2.5685)
Epoch (train): [11][57610/74490]	Time 0.093 (0.137)	Data 0.000 (0.060)	Loss 2.2809 (2.5676)
Epoch (train): [11][58610/74490]	Time 0.085 (0.137)	Data 0.000 (0.060)	Loss 0.9922 (2.5683)
Epoch (train): [11][59610/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 3.3053 (2.5688)
Epoch (train): [11][60610/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 3.6756 (2.5686)
Epoch (train): [11][61610/74490]	Time 0.087 (0.137)	Data 0.000 (0.060)	Loss 1.1118 (2.5679)
Epoch (train): [11][62610/74490]	Time 0.111 (0.137)	Data 0.000 (0.060)	Loss 3.7745 (2.5686)
Epoch (train): [11][63610/74490]	Time 0.083 (0.137)	Data 0.001 (0.060)	Loss 4.2019 (2.5686)
Epoch (train): [11][64610/74490]	Time 0.092 (0.137)	Data 0.000 (0.060)	Loss 2.6513 (2.5689)
Epoch (train): [11][65610/74490]	Time 0.084 (0.137)	Data 0.000 (0.060)	Loss 2.2458 (2.5682)
Epoch (train): [11][66610/74490]	Time 0.343 (0.137)	Data 0.290 (0.060)	Loss 1.4563 (2.5696)
Epoch (train): [11][67610/74490]	Time 0.219 (0.137)	Data 0.181 (0.060)	Loss 2.4283 (2.5694)
Epoch (train): [11][68610/74490]	Time 0.480 (0.138)	Data 0.439 (0.060)	Loss 1.1666 (2.5700)
Epoch (train): [11][69610/74490]	Time 0.086 (0.138)	Data 0.001 (0.060)	Loss 7.9141 (2.5687)
Epoch (train): [11][70610/74490]	Time 0.089 (0.138)	Data 0.002 (0.060)	Loss 1.5101 (2.5681)
Epoch (train): [11][71610/74490]	Time 0.432 (0.138)	Data 0.394 (0.060)	Loss 1.7192 (2.5676)
Epoch (train): [11][72610/74490]	Time 0.085 (0.138)	Data 0.001 (0.061)	Loss 2.5001 (2.5693)
Epoch (train): [11][73610/74490]	Time 0.080 (0.138)	Data 0.000 (0.061)	Loss 1.9705 (2.5698)
Epoch (train): [12][120/74490]	Time 0.127 (0.151)	Data 0.089 (0.080)	Loss 1.4649 (2.4954)
Epoch (train): [12][1120/74490]	Time 0.083 (0.131)	Data 0.000 (0.057)	Loss 1.4669 (2.5204)
Epoch (train): [12][2120/74490]	Time 0.366 (0.133)	Data 0.325 (0.058)	Loss 1.7376 (2.4752)
Epoch (train): [12][3120/74490]	Time 0.083 (0.131)	Data 0.000 (0.056)	Loss 1.1382 (2.4852)
Epoch (train): [12][4120/74490]	Time 0.087 (0.131)	Data 0.000 (0.056)	Loss 1.8856 (2.4933)
Epoch (train): [12][5120/74490]	Time 0.080 (0.137)	Data 0.000 (0.062)	Loss 3.6840 (2.4825)
Epoch (train): [12][6120/74490]	Time 0.091 (0.137)	Data 0.000 (0.062)	Loss 1.7432 (2.4728)
Epoch (train): [12][7120/74490]	Time 0.080 (0.136)	Data 0.000 (0.060)	Loss 2.8822 (2.4548)
Epoch (train): [12][8120/74490]	Time 0.083 (0.134)	Data 0.000 (0.059)	Loss 1.6788 (2.4496)
Epoch (train): [12][9120/74490]	Time 0.093 (0.134)	Data 0.001 (0.058)	Loss 1.3212 (2.4452)
Epoch (train): [12][10120/74490]	Time 0.075 (0.133)	Data 0.000 (0.058)	Loss 3.2706 (2.4439)
Epoch (train): [12][11120/74490]	Time 0.092 (0.133)	Data 0.000 (0.057)	Loss 1.8919 (2.4444)
Epoch (train): [12][12120/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.2477 (2.4353)
Epoch (train): [12][13120/74490]	Time 0.086 (0.131)	Data 0.000 (0.056)	Loss 1.4241 (2.4377)
Epoch (train): [12][14120/74490]	Time 0.099 (0.131)	Data 0.003 (0.056)	Loss 3.5186 (2.4402)
Epoch (train): [12][15120/74490]	Time 0.329 (0.132)	Data 0.291 (0.056)	Loss 1.7716 (2.4442)
Epoch (train): [12][16120/74490]	Time 0.083 (0.133)	Data 0.000 (0.058)	Loss 2.1682 (2.4438)
Epoch (train): [12][17120/74490]	Time 0.083 (0.132)	Data 0.000 (0.057)	Loss 1.7643 (2.4435)
Epoch (train): [12][18120/74490]	Time 0.080 (0.132)	Data 0.000 (0.056)	Loss 1.4356 (2.4411)
Epoch (train): [12][19120/74490]	Time 0.087 (0.131)	Data 0.000 (0.056)	Loss 1.4064 (2.4398)
Epoch (train): [12][20120/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 3.4326 (2.4383)
Epoch (train): [12][21120/74490]	Time 0.079 (0.130)	Data 0.000 (0.055)	Loss 4.7436 (2.4366)
Epoch (train): [12][22120/74490]	Time 0.082 (0.130)	Data 0.000 (0.055)	Loss 1.1232 (2.4337)
Epoch (train): [12][23120/74490]	Time 0.081 (0.130)	Data 0.001 (0.054)	Loss 1.5757 (2.4356)
Epoch (train): [12][24120/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 1.6832 (2.4411)
Epoch (train): [12][25120/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 4.4958 (2.4397)
Epoch (train): [12][26120/74490]	Time 0.078 (0.129)	Data 0.000 (0.054)	Loss 3.1150 (2.4424)
Epoch (train): [12][27120/74490]	Time 0.084 (0.129)	Data 0.000 (0.053)	Loss 1.7437 (2.4383)
Epoch (train): [12][28120/74490]	Time 0.094 (0.128)	Data 0.000 (0.053)	Loss 1.8266 (2.4364)
Epoch (train): [12][29120/74490]	Time 0.082 (0.128)	Data 0.000 (0.053)	Loss 3.1271 (2.4369)
Epoch (train): [12][30120/74490]	Time 0.078 (0.128)	Data 0.000 (0.053)	Loss 1.4260 (2.4364)
Epoch (train): [12][31120/74490]	Time 0.075 (0.128)	Data 0.000 (0.052)	Loss 2.5384 (2.4354)
Epoch (train): [12][32120/74490]	Time 0.096 (0.128)	Data 0.002 (0.052)	Loss 1.1974 (2.4358)
Epoch (train): [12][33120/74490]	Time 0.087 (0.127)	Data 0.002 (0.052)	Loss 7.6252 (2.4370)
Epoch (train): [12][34120/74490]	Time 0.081 (0.127)	Data 0.000 (0.052)	Loss 2.1558 (2.4355)
Epoch (train): [12][35120/74490]	Time 0.074 (0.127)	Data 0.000 (0.052)	Loss 2.7594 (2.4361)
Epoch (train): [12][36120/74490]	Time 0.089 (0.127)	Data 0.000 (0.051)	Loss 1.4925 (2.4389)
Epoch (train): [12][37120/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 3.8027 (2.4379)
Epoch (train): [12][38120/74490]	Time 0.084 (0.127)	Data 0.000 (0.051)	Loss 1.0945 (2.4391)
Epoch (train): [12][39120/74490]	Time 0.085 (0.127)	Data 0.000 (0.051)	Loss 1.5551 (2.4393)
Epoch (train): [12][40120/74490]	Time 0.083 (0.127)	Data 0.000 (0.051)	Loss 1.9190 (2.4402)
Epoch (train): [12][41120/74490]	Time 0.086 (0.126)	Data 0.000 (0.051)	Loss 0.9191 (2.4408)
Epoch (train): [12][42120/74490]	Time 0.087 (0.126)	Data 0.000 (0.051)	Loss 2.5955 (2.4395)
Epoch (train): [12][43120/74490]	Time 0.354 (0.126)	Data 0.315 (0.051)	Loss 1.5417 (2.4393)
Epoch (train): [12][44120/74490]	Time 0.314 (0.126)	Data 0.275 (0.051)	Loss 3.2491 (2.4404)
Epoch (train): [12][45120/74490]	Time 0.292 (0.126)	Data 0.254 (0.051)	Loss 3.2926 (2.4385)
Epoch (train): [12][46120/74490]	Time 0.091 (0.126)	Data 0.001 (0.051)	Loss 2.2291 (2.4382)
Epoch (train): [12][47120/74490]	Time 0.094 (0.126)	Data 0.000 (0.050)	Loss 1.2952 (2.4379)
Epoch (train): [12][48120/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 1.6331 (2.4394)
Epoch (train): [12][49120/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 1.6477 (2.4386)
Epoch (train): [12][50120/74490]	Time 0.081 (0.126)	Data 0.001 (0.050)	Loss 2.2413 (2.4400)
Epoch (train): [12][51120/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 0.5871 (2.4398)
Epoch (train): [12][52120/74490]	Time 0.079 (0.125)	Data 0.000 (0.050)	Loss 1.6488 (2.4403)
Epoch (train): [12][53120/74490]	Time 0.079 (0.125)	Data 0.000 (0.050)	Loss 1.6707 (2.4412)
Epoch (train): [12][54120/74490]	Time 0.078 (0.125)	Data 0.001 (0.050)	Loss 1.4314 (2.4406)
Epoch (train): [12][55120/74490]	Time 0.087 (0.125)	Data 0.000 (0.050)	Loss 3.2523 (2.4404)
Epoch (train): [12][56120/74490]	Time 0.082 (0.125)	Data 0.001 (0.050)	Loss 2.7569 (2.4400)
Epoch (train): [12][57120/74490]	Time 0.087 (0.125)	Data 0.000 (0.050)	Loss 2.3692 (2.4400)
Epoch (train): [12][58120/74490]	Time 0.092 (0.125)	Data 0.000 (0.050)	Loss 1.8954 (2.4399)
Epoch (train): [12][59120/74490]	Time 0.084 (0.125)	Data 0.000 (0.050)	Loss 6.9091 (2.4394)
Epoch (train): [12][60120/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 2.3293 (2.4378)
Epoch (train): [12][61120/74490]	Time 0.075 (0.125)	Data 0.000 (0.049)	Loss 0.9325 (2.4375)
Epoch (train): [12][62120/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 1.7229 (2.4384)
Epoch (train): [12][63120/74490]	Time 0.351 (0.125)	Data 0.302 (0.049)	Loss 2.0088 (2.4380)
Epoch (train): [12][64120/74490]	Time 0.096 (0.125)	Data 0.058 (0.049)	Loss 2.0980 (2.4400)
Epoch (train): [12][65120/74490]	Time 0.080 (0.125)	Data 0.000 (0.049)	Loss 2.5985 (2.4393)
Epoch (train): [12][66120/74490]	Time 0.346 (0.125)	Data 0.309 (0.049)	Loss 1.8012 (2.4397)
Epoch (train): [12][67120/74490]	Time 0.077 (0.125)	Data 0.000 (0.049)	Loss 1.8210 (2.4398)
Epoch (train): [12][68120/74490]	Time 0.080 (0.125)	Data 0.000 (0.049)	Loss 1.6140 (2.4406)
Epoch (train): [12][69120/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 14.4662 (2.4403)
Epoch (train): [12][70120/74490]	Time 0.089 (0.125)	Data 0.000 (0.049)	Loss 2.1588 (2.4393)
Epoch (train): [12][71120/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 3.9187 (2.4395)
Epoch (train): [12][72120/74490]	Time 0.079 (0.125)	Data 0.000 (0.049)	Loss 4.7441 (2.4398)
Epoch (train): [12][73120/74490]	Time 0.090 (0.124)	Data 0.000 (0.049)	Loss 1.2535 (2.4401)
Epoch (train): [12][74120/74490]	Time 0.105 (0.124)	Data 0.010 (0.049)	Loss 1.1449 (2.4408)
Epoch (train): [13][630/74490]	Time 0.082 (0.125)	Data 0.000 (0.052)	Loss 1.2643 (2.3080)
Epoch (train): [13][1630/74490]	Time 0.082 (0.122)	Data 0.000 (0.047)	Loss 2.8848 (2.3342)
Epoch (train): [13][2630/74490]	Time 0.091 (0.122)	Data 0.000 (0.048)	Loss 3.9451 (2.2856)
Epoch (train): [13][3630/74490]	Time 0.095 (0.122)	Data 0.001 (0.048)	Loss 2.7100 (2.2962)
Epoch (train): [13][4630/74490]	Time 0.076 (0.122)	Data 0.000 (0.047)	Loss 2.6701 (2.3035)
Epoch (train): [13][5630/74490]	Time 0.081 (0.122)	Data 0.000 (0.047)	Loss 1.4670 (2.2987)
Epoch (train): [13][6630/74490]	Time 0.194 (0.122)	Data 0.147 (0.047)	Loss 0.8362 (2.2987)
Epoch (train): [13][7630/74490]	Time 0.382 (0.122)	Data 0.346 (0.047)	Loss 1.9652 (2.2994)
Epoch (train): [13][8630/74490]	Time 0.327 (0.122)	Data 0.290 (0.047)	Loss 2.1370 (2.3081)
Epoch (train): [13][9630/74490]	Time 0.153 (0.122)	Data 0.118 (0.047)	Loss 2.1870 (2.3076)
Epoch (train): [13][10630/74490]	Time 0.263 (0.121)	Data 0.228 (0.047)	Loss 2.0819 (2.3062)
Epoch (train): [13][11630/74490]	Time 0.378 (0.121)	Data 0.341 (0.047)	Loss 1.7033 (2.3067)
Epoch (train): [13][12630/74490]	Time 0.428 (0.121)	Data 0.389 (0.047)	Loss 1.6310 (2.3063)
Epoch (train): [13][13630/74490]	Time 0.435 (0.122)	Data 0.399 (0.046)	Loss 1.9055 (2.2970)
Epoch (train): [13][14630/74490]	Time 0.084 (0.122)	Data 0.000 (0.047)	Loss 6.3604 (2.2962)
Epoch (train): [13][15630/74490]	Time 0.085 (0.122)	Data 0.001 (0.047)	Loss 4.4149 (2.2938)
Epoch (train): [13][16630/74490]	Time 0.080 (0.122)	Data 0.000 (0.047)	Loss 1.4010 (2.2915)
Epoch (train): [13][17630/74490]	Time 0.084 (0.122)	Data 0.000 (0.047)	Loss 1.1170 (2.2913)
Epoch (train): [13][18630/74490]	Time 0.091 (0.122)	Data 0.000 (0.047)	Loss 1.7994 (2.2941)
Epoch (train): [13][19630/74490]	Time 0.256 (0.122)	Data 0.215 (0.047)	Loss 1.5997 (2.2945)
Epoch (train): [13][20630/74490]	Time 0.090 (0.122)	Data 0.000 (0.047)	Loss 1.7711 (2.2949)
Epoch (train): [13][21630/74490]	Time 0.080 (0.122)	Data 0.003 (0.047)	Loss 2.6517 (2.2932)
Epoch (train): [13][22630/74490]	Time 0.070 (0.122)	Data 0.031 (0.047)	Loss 1.6698 (2.2981)
Epoch (train): [13][23630/74490]	Time 0.089 (0.122)	Data 0.000 (0.047)	Loss 1.0140 (2.3005)
Epoch (train): [13][24630/74490]	Time 0.083 (0.122)	Data 0.000 (0.047)	Loss 3.1723 (2.3029)
Epoch (train): [13][25630/74490]	Time 0.082 (0.122)	Data 0.000 (0.047)	Loss 1.8232 (2.3059)
Epoch (train): [13][26630/74490]	Time 0.077 (0.122)	Data 0.000 (0.047)	Loss 0.5955 (2.3070)
Epoch (train): [13][27630/74490]	Time 0.430 (0.122)	Data 0.376 (0.047)	Loss 3.3309 (2.3100)
Epoch (train): [13][28630/74490]	Time 0.466 (0.122)	Data 0.427 (0.047)	Loss 3.9881 (2.3089)
Epoch (train): [13][29630/74490]	Time 0.502 (0.123)	Data 0.457 (0.047)	Loss 1.7634 (2.3107)
Epoch (train): [13][30630/74490]	Time 0.074 (0.123)	Data 0.000 (0.047)	Loss 1.8012 (2.3111)
Epoch (train): [13][31630/74490]	Time 0.084 (0.123)	Data 0.001 (0.048)	Loss 1.9944 (2.3126)
Epoch (train): [13][32630/74490]	Time 0.081 (0.123)	Data 0.000 (0.047)	Loss 1.9180 (2.3128)
Epoch (train): [13][33630/74490]	Time 0.081 (0.123)	Data 0.000 (0.047)	Loss 5.1956 (2.3159)
Epoch (train): [13][34630/74490]	Time 0.092 (0.123)	Data 0.000 (0.048)	Loss 3.6159 (2.3161)
Epoch (train): [13][35630/74490]	Time 0.093 (0.123)	Data 0.000 (0.048)	Loss 3.6148 (2.3162)
Epoch (train): [13][36630/74490]	Time 0.084 (0.123)	Data 0.002 (0.048)	Loss 3.5252 (2.3182)
Epoch (train): [13][37630/74490]	Time 0.070 (0.123)	Data 0.000 (0.048)	Loss 0.9186 (2.3184)
Epoch (train): [13][38630/74490]	Time 0.081 (0.123)	Data 0.000 (0.048)	Loss 1.6225 (2.3188)
Epoch (train): [13][39630/74490]	Time 0.079 (0.123)	Data 0.003 (0.048)	Loss 5.1467 (2.3203)
Epoch (train): [13][40630/74490]	Time 0.089 (0.123)	Data 0.000 (0.048)	Loss 1.0705 (2.3227)
Epoch (train): [13][41630/74490]	Time 0.082 (0.123)	Data 0.000 (0.048)	Loss 1.9178 (2.3256)
Epoch (train): [13][42630/74490]	Time 0.085 (0.123)	Data 0.000 (0.048)	Loss 2.4816 (2.3247)
Epoch (train): [13][43630/74490]	Time 0.086 (0.123)	Data 0.002 (0.048)	Loss 2.1069 (2.3216)
Epoch (train): [13][44630/74490]	Time 0.083 (0.123)	Data 0.000 (0.048)	Loss 1.7424 (2.3205)
Epoch (train): [13][45630/74490]	Time 0.205 (0.123)	Data 0.166 (0.048)	Loss 3.0615 (2.3206)
Epoch (train): [13][46630/74490]	Time 0.273 (0.123)	Data 0.237 (0.048)	Loss 1.6955 (2.3191)
Epoch (train): [13][47630/74490]	Time 0.534 (0.123)	Data 0.496 (0.048)	Loss 2.4865 (2.3186)
Epoch (train): [13][48630/74490]	Time 0.431 (0.123)	Data 0.389 (0.048)	Loss 0.9487 (2.3192)
Epoch (train): [13][49630/74490]	Time 0.413 (0.123)	Data 0.373 (0.048)	Loss 2.1955 (2.3189)
Epoch (train): [13][50630/74490]	Time 0.151 (0.123)	Data 0.116 (0.048)	Loss 2.5511 (2.3209)
Epoch (train): [13][51630/74490]	Time 0.248 (0.123)	Data 0.210 (0.048)	Loss 1.7372 (2.3206)
Epoch (train): [13][52630/74490]	Time 0.531 (0.124)	Data 0.482 (0.048)	Loss 2.0049 (2.3225)
Epoch (train): [13][53630/74490]	Time 0.441 (0.124)	Data 0.401 (0.048)	Loss 2.9013 (2.3232)
Epoch (train): [13][54630/74490]	Time 0.440 (0.124)	Data 0.392 (0.048)	Loss 2.3857 (2.3234)
Epoch (train): [13][55630/74490]	Time 0.376 (0.124)	Data 0.339 (0.048)	Loss 13.2185 (2.3233)
Epoch (train): [13][56630/74490]	Time 0.282 (0.124)	Data 0.241 (0.048)	Loss 2.4071 (2.3234)
Epoch (train): [13][57630/74490]	Time 0.356 (0.124)	Data 0.318 (0.048)	Loss 2.5137 (2.3222)
Epoch (train): [13][58630/74490]	Time 0.084 (0.124)	Data 0.000 (0.048)	Loss 2.9621 (2.3227)
Epoch (train): [13][59630/74490]	Time 0.082 (0.124)	Data 0.000 (0.048)	Loss 1.8112 (2.3225)
Epoch (train): [13][60630/74490]	Time 0.086 (0.124)	Data 0.000 (0.049)	Loss 3.1904 (2.3216)
Epoch (train): [13][61630/74490]	Time 0.086 (0.124)	Data 0.017 (0.049)	Loss 1.2996 (2.3217)
Epoch (train): [13][62630/74490]	Time 0.145 (0.124)	Data 0.107 (0.049)	Loss 2.2132 (2.3224)
Epoch (train): [13][63630/74490]	Time 0.082 (0.124)	Data 0.000 (0.049)	Loss 1.9360 (2.3222)
Epoch (train): [13][64630/74490]	Time 0.086 (0.124)	Data 0.000 (0.049)	Loss 7.8936 (2.3222)
Epoch (train): [13][65630/74490]	Time 0.385 (0.124)	Data 0.349 (0.049)	Loss 1.6136 (2.3222)
Epoch (train): [13][66630/74490]	Time 0.276 (0.124)	Data 0.234 (0.049)	Loss 9.3357 (2.3220)
Epoch (train): [13][67630/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 0.9071 (2.3224)
Epoch (train): [13][68630/74490]	Time 0.090 (0.125)	Data 0.000 (0.049)	Loss 1.7000 (2.3222)
Epoch (train): [13][69630/74490]	Time 0.090 (0.125)	Data 0.000 (0.049)	Loss 5.3718 (2.3234)
Epoch (train): [13][70630/74490]	Time 0.224 (0.125)	Data 0.190 (0.049)	Loss 2.1969 (2.3238)
Epoch (train): [13][71630/74490]	Time 0.163 (0.125)	Data 0.122 (0.049)	Loss 2.5961 (2.3232)
Epoch (train): [13][72630/74490]	Time 0.106 (0.125)	Data 0.069 (0.049)	Loss 2.0904 (2.3239)
Epoch (train): [13][73630/74490]	Time 0.084 (0.125)	Data 0.000 (0.049)	Loss 3.8373 (2.3240)
Epoch (train): [14][140/74490]	Time 0.079 (0.151)	Data 0.002 (0.073)	Loss 2.1149 (2.2343)
Epoch (train): [14][1140/74490]	Time 0.080 (0.132)	Data 0.018 (0.057)	Loss 6.6447 (2.1388)
Epoch (train): [14][2140/74490]	Time 0.430 (0.129)	Data 0.388 (0.055)	Loss 2.1809 (2.1690)
Epoch (train): [14][3140/74490]	Time 0.083 (0.129)	Data 0.000 (0.054)	Loss 2.4816 (2.1776)
Epoch (train): [14][4140/74490]	Time 0.093 (0.128)	Data 0.001 (0.053)	Loss 1.5393 (2.1911)
Epoch (train): [14][5140/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 1.1445 (2.2016)
Epoch (train): [14][6140/74490]	Time 0.086 (0.127)	Data 0.000 (0.052)	Loss 3.0657 (2.1967)
Epoch (train): [14][7140/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 2.1865 (2.1931)
Epoch (train): [14][8140/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 0.9249 (2.1950)
Epoch (train): [14][9140/74490]	Time 0.083 (0.127)	Data 0.001 (0.052)	Loss 2.2448 (2.1963)
Epoch (train): [14][10140/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 4.4947 (2.1899)
Epoch (train): [14][11140/74490]	Time 0.088 (0.128)	Data 0.003 (0.053)	Loss 1.7623 (2.1919)
Epoch (train): [14][12140/74490]	Time 0.079 (0.128)	Data 0.000 (0.052)	Loss 1.8032 (2.1888)
Epoch (train): [14][13140/74490]	Time 0.075 (0.128)	Data 0.000 (0.052)	Loss 2.5068 (2.1844)
Epoch (train): [14][14140/74490]	Time 0.088 (0.128)	Data 0.000 (0.052)	Loss 2.6133 (2.1880)
Epoch (train): [14][15140/74490]	Time 0.086 (0.128)	Data 0.000 (0.052)	Loss 1.2196 (2.1885)
Epoch (train): [14][16140/74490]	Time 0.386 (0.128)	Data 0.351 (0.052)	Loss 1.2109 (2.1921)
Epoch (train): [14][17140/74490]	Time 0.239 (0.128)	Data 0.203 (0.052)	Loss 2.7235 (2.1899)
Epoch (train): [14][18140/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 4.4280 (2.1938)
Epoch (train): [14][19140/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 1.4312 (2.1885)
Epoch (train): [14][20140/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 4.0108 (2.1909)
Epoch (train): [14][21140/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 2.5477 (2.1930)
Epoch (train): [14][22140/74490]	Time 0.400 (0.128)	Data 0.365 (0.053)	Loss 2.3000 (2.1951)
Epoch (train): [14][23140/74490]	Time 0.132 (0.128)	Data 0.093 (0.053)	Loss 2.6299 (2.1944)
Epoch (train): [14][24140/74490]	Time 0.072 (0.128)	Data 0.000 (0.053)	Loss 1.2997 (2.1952)
Epoch (train): [14][25140/74490]	Time 0.082 (0.128)	Data 0.001 (0.053)	Loss 2.0731 (2.1985)
Epoch (train): [14][26140/74490]	Time 0.086 (0.128)	Data 0.000 (0.053)	Loss 2.9800 (2.2015)
Epoch (train): [14][27140/74490]	Time 0.096 (0.128)	Data 0.000 (0.053)	Loss 7.2810 (2.2043)
Epoch (train): [14][28140/74490]	Time 0.097 (0.128)	Data 0.000 (0.053)	Loss 2.3940 (2.2038)
Epoch (train): [14][29140/74490]	Time 0.085 (0.128)	Data 0.000 (0.053)	Loss 3.8848 (2.2058)
Epoch (train): [14][30140/74490]	Time 0.084 (0.128)	Data 0.000 (0.052)	Loss 2.7510 (2.2080)
Epoch (train): [14][31140/74490]	Time 0.084 (0.128)	Data 0.000 (0.052)	Loss 8.0408 (2.2096)
Epoch (train): [14][32140/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 3.8425 (2.2107)
Epoch (train): [14][33140/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 0.5689 (2.2095)
Epoch (train): [14][34140/74490]	Time 0.099 (0.128)	Data 0.000 (0.052)	Loss 4.8398 (2.2073)
Epoch (train): [14][35140/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 3.2239 (2.2102)
Epoch (train): [14][36140/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 1.4843 (2.2119)
Epoch (train): [14][37140/74490]	Time 0.089 (0.128)	Data 0.000 (0.052)	Loss 1.8760 (2.2108)
Epoch (train): [14][38140/74490]	Time 0.088 (0.128)	Data 0.000 (0.052)	Loss 2.3487 (2.2130)
Epoch (train): [14][39140/74490]	Time 0.084 (0.128)	Data 0.001 (0.052)	Loss 1.4770 (2.2139)
Epoch (train): [14][40140/74490]	Time 0.092 (0.128)	Data 0.000 (0.052)	Loss 1.2632 (2.2156)
Epoch (train): [14][41140/74490]	Time 0.083 (0.128)	Data 0.000 (0.052)	Loss 1.0687 (2.2171)
Epoch (train): [14][42140/74490]	Time 0.090 (0.128)	Data 0.000 (0.052)	Loss 0.9819 (2.2167)
Epoch (train): [14][43140/74490]	Time 0.113 (0.128)	Data 0.076 (0.052)	Loss 1.9547 (2.2198)
Epoch (train): [14][44140/74490]	Time 0.120 (0.128)	Data 0.080 (0.052)	Loss 1.4482 (2.2190)
Epoch (train): [14][45140/74490]	Time 0.409 (0.128)	Data 0.373 (0.052)	Loss 3.1074 (2.2195)
Epoch (train): [14][46140/74490]	Time 0.103 (0.128)	Data 0.069 (0.052)	Loss 1.1064 (2.2189)
Epoch (train): [14][47140/74490]	Time 0.085 (0.128)	Data 0.001 (0.052)	Loss 3.9316 (2.2181)
Epoch (train): [14][48140/74490]	Time 0.094 (0.128)	Data 0.000 (0.052)	Loss 1.4898 (2.2183)
Epoch (train): [14][49140/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 5.6859 (2.2196)
Epoch (train): [14][50140/74490]	Time 0.082 (0.128)	Data 0.000 (0.052)	Loss 2.4594 (2.2206)
Epoch (train): [14][51140/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 3.9648 (2.2201)
Epoch (train): [14][52140/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 2.7654 (2.2194)
Epoch (train): [14][53140/74490]	Time 0.086 (0.128)	Data 0.000 (0.052)	Loss 2.9857 (2.2199)
Epoch (train): [14][54140/74490]	Time 0.079 (0.128)	Data 0.000 (0.052)	Loss 1.3393 (2.2180)
Epoch (train): [14][55140/74490]	Time 0.084 (0.128)	Data 0.000 (0.052)	Loss 1.6605 (2.2177)
Epoch (train): [14][56140/74490]	Time 0.083 (0.128)	Data 0.001 (0.052)	Loss 1.9286 (2.2170)
Epoch (train): [14][57140/74490]	Time 0.079 (0.128)	Data 0.000 (0.052)	Loss 3.7094 (2.2174)
Epoch (train): [14][58140/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 1.9943 (2.2175)
Epoch (train): [14][59140/74490]	Time 0.088 (0.127)	Data 0.000 (0.052)	Loss 1.9535 (2.2168)
Epoch (train): [14][60140/74490]	Time 0.080 (0.127)	Data 0.000 (0.052)	Loss 1.1474 (2.2164)
Epoch (train): [14][61140/74490]	Time 0.087 (0.127)	Data 0.000 (0.052)	Loss 1.7708 (2.2161)
Epoch (train): [14][62140/74490]	Time 0.095 (0.127)	Data 0.000 (0.052)	Loss 2.7860 (2.2150)
Epoch (train): [14][63140/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 2.0624 (2.2165)
Epoch (train): [14][64140/74490]	Time 0.097 (0.127)	Data 0.000 (0.052)	Loss 0.9053 (2.2174)
Epoch (train): [14][65140/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 1.6944 (2.2168)
Epoch (train): [14][66140/74490]	Time 0.090 (0.127)	Data 0.000 (0.052)	Loss 1.0335 (2.2163)
Epoch (train): [14][67140/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 1.9067 (2.2171)
Epoch (train): [14][68140/74490]	Time 0.083 (0.127)	Data 0.000 (0.052)	Loss 6.7543 (2.2170)
Epoch (train): [14][69140/74490]	Time 0.083 (0.127)	Data 0.000 (0.052)	Loss 2.6869 (2.2175)
Epoch (train): [14][70140/74490]	Time 0.088 (0.127)	Data 0.000 (0.052)	Loss 1.7229 (2.2187)
Epoch (train): [14][71140/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 1.4767 (2.2183)
Epoch (train): [14][72140/74490]	Time 0.096 (0.127)	Data 0.000 (0.052)	Loss 1.7911 (2.2184)
Epoch (train): [14][73140/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 1.7066 (2.2182)
Epoch (train): [14][74140/74490]	Time 0.082 (0.127)	Data 0.001 (0.052)	Loss 2.4793 (2.2190)
Epoch (train): [15][650/74490]	Time 0.084 (0.129)	Data 0.000 (0.053)	Loss 6.7463 (1.9890)
Epoch (train): [15][1650/74490]	Time 0.089 (0.127)	Data 0.000 (0.052)	Loss 2.0299 (2.0196)
Epoch (train): [15][2650/74490]	Time 0.083 (0.127)	Data 0.000 (0.052)	Loss 1.0784 (2.0613)
Epoch (train): [15][3650/74490]	Time 0.086 (0.126)	Data 0.000 (0.049)	Loss 1.8088 (2.0796)
Epoch (train): [15][4650/74490]	Time 0.084 (0.125)	Data 0.000 (0.049)	Loss 4.1739 (2.0773)
Epoch (train): [15][5650/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 3.4224 (2.0762)
Epoch (train): [15][6650/74490]	Time 0.089 (0.125)	Data 0.000 (0.048)	Loss 2.1356 (2.0866)
Epoch (train): [15][7650/74490]	Time 0.094 (0.124)	Data 0.000 (0.048)	Loss 0.8862 (2.0823)
Epoch (train): [15][8650/74490]	Time 0.087 (0.124)	Data 0.000 (0.048)	Loss 2.3638 (2.0827)
Epoch (train): [15][9650/74490]	Time 0.085 (0.124)	Data 0.000 (0.048)	Loss 1.3767 (2.0857)
Epoch (train): [15][10650/74490]	Time 0.085 (0.124)	Data 0.000 (0.048)	Loss 0.9552 (2.0839)
Epoch (train): [15][11650/74490]	Time 0.089 (0.124)	Data 0.000 (0.048)	Loss 3.8306 (2.0835)
Epoch (train): [15][12650/74490]	Time 0.097 (0.124)	Data 0.000 (0.047)	Loss 2.6860 (2.0833)
Epoch (train): [15][13650/74490]	Time 0.089 (0.124)	Data 0.000 (0.048)	Loss 1.8834 (2.0859)
Epoch (train): [15][14650/74490]	Time 0.070 (0.124)	Data 0.000 (0.048)	Loss 1.3162 (2.0938)
Epoch (train): [15][15650/74490]	Time 0.090 (0.124)	Data 0.000 (0.048)	Loss 1.9224 (2.0956)
Epoch (train): [15][16650/74490]	Time 0.089 (0.125)	Data 0.000 (0.048)	Loss 2.9792 (2.0974)
Epoch (train): [15][17650/74490]	Time 0.083 (0.125)	Data 0.000 (0.048)	Loss 1.2066 (2.0985)
Epoch (train): [15][18650/74490]	Time 0.120 (0.125)	Data 0.076 (0.049)	Loss 1.9997 (2.1007)
Epoch (train): [15][19650/74490]	Time 0.092 (0.125)	Data 0.000 (0.049)	Loss 1.8933 (2.1017)
Epoch (train): [15][20650/74490]	Time 0.215 (0.125)	Data 0.178 (0.050)	Loss 2.1504 (2.1023)
Epoch (train): [15][21650/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 1.5116 (2.1056)
Epoch (train): [15][22650/74490]	Time 0.080 (0.126)	Data 0.000 (0.050)	Loss 2.0223 (2.1051)
Epoch (train): [15][23650/74490]	Time 0.089 (0.126)	Data 0.000 (0.050)	Loss 3.4047 (2.1058)
Epoch (train): [15][24650/74490]	Time 0.530 (0.126)	Data 0.488 (0.050)	Loss 2.3573 (2.1065)
Epoch (train): [15][25650/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 1.8997 (2.1071)
Epoch (train): [15][26650/74490]	Time 0.597 (0.126)	Data 0.559 (0.050)	Loss 1.9386 (2.1060)
Epoch (train): [15][27650/74490]	Time 0.559 (0.127)	Data 0.522 (0.051)	Loss 1.8815 (2.1093)
Epoch (train): [15][28650/74490]	Time 0.521 (0.127)	Data 0.484 (0.051)	Loss 2.1812 (2.1102)
Epoch (train): [15][29650/74490]	Time 0.212 (0.127)	Data 0.177 (0.051)	Loss 0.8652 (2.1096)
Epoch (train): [15][30650/74490]	Time 0.085 (0.127)	Data 0.000 (0.051)	Loss 1.4433 (2.1109)
Epoch (train): [15][31650/74490]	Time 0.088 (0.127)	Data 0.000 (0.051)	Loss 1.3264 (2.1092)
Epoch (train): [15][32650/74490]	Time 0.085 (0.127)	Data 0.000 (0.051)	Loss 3.4569 (2.1071)
Epoch (train): [15][33650/74490]	Time 0.092 (0.127)	Data 0.001 (0.051)	Loss 2.5877 (2.1063)
Epoch (train): [15][34650/74490]	Time 0.082 (0.127)	Data 0.001 (0.051)	Loss 3.6073 (2.1088)
Epoch (train): [15][35650/74490]	Time 0.083 (0.127)	Data 0.000 (0.051)	Loss 9.4433 (2.1097)
Epoch (train): [15][36650/74490]	Time 0.082 (0.127)	Data 0.000 (0.051)	Loss 1.3821 (2.1100)
Epoch (train): [15][37650/74490]	Time 0.087 (0.127)	Data 0.047 (0.051)	Loss 3.2339 (2.1094)
Epoch (train): [15][38650/74490]	Time 0.454 (0.127)	Data 0.417 (0.051)	Loss 3.7285 (2.1106)
Epoch (train): [15][39650/74490]	Time 0.099 (0.127)	Data 0.057 (0.051)	Loss 0.8064 (2.1114)
Epoch (train): [15][40650/74490]	Time 0.084 (0.127)	Data 0.000 (0.051)	Loss 1.6037 (2.1141)
Epoch (train): [15][41650/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 3.1926 (2.1138)
Epoch (train): [15][42650/74490]	Time 0.082 (0.127)	Data 0.000 (0.051)	Loss 1.5987 (2.1138)
Epoch (train): [15][43650/74490]	Time 0.071 (0.127)	Data 0.000 (0.051)	Loss 3.7469 (2.1144)
Epoch (train): [15][44650/74490]	Time 0.085 (0.127)	Data 0.000 (0.051)	Loss 1.9975 (2.1153)
Epoch (train): [15][45650/74490]	Time 0.080 (0.127)	Data 0.000 (0.051)	Loss 2.0391 (2.1151)
Epoch (train): [15][46650/74490]	Time 0.088 (0.127)	Data 0.000 (0.051)	Loss 1.5814 (2.1151)
Epoch (train): [15][47650/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 1.3077 (2.1156)
Epoch (train): [15][48650/74490]	Time 0.086 (0.127)	Data 0.000 (0.051)	Loss 3.7467 (2.1164)
Epoch (train): [15][49650/74490]	Time 0.374 (0.127)	Data 0.338 (0.051)	Loss 1.1494 (2.1162)
Epoch (train): [15][50650/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 2.3428 (2.1164)
Epoch (train): [15][51650/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 1.8474 (2.1168)
Epoch (train): [15][52650/74490]	Time 0.084 (0.127)	Data 0.000 (0.050)	Loss 0.9939 (2.1182)
Epoch (train): [15][53650/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 1.5242 (2.1180)
Epoch (train): [15][54650/74490]	Time 0.078 (0.126)	Data 0.000 (0.050)	Loss 1.9205 (2.1183)
Epoch (train): [15][55650/74490]	Time 0.143 (0.126)	Data 0.105 (0.050)	Loss 1.9569 (2.1172)
Epoch (train): [15][56650/74490]	Time 0.074 (0.126)	Data 0.000 (0.050)	Loss 2.2768 (2.1181)
Epoch (train): [15][57650/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 3.5347 (2.1179)
Epoch (train): [15][58650/74490]	Time 0.079 (0.126)	Data 0.000 (0.050)	Loss 2.2427 (2.1184)
Epoch (train): [15][59650/74490]	Time 0.086 (0.126)	Data 0.000 (0.050)	Loss 1.3899 (2.1182)
Epoch (train): [15][60650/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 2.2552 (2.1197)
Epoch (train): [15][61650/74490]	Time 0.088 (0.126)	Data 0.000 (0.050)	Loss 1.6398 (2.1193)
Epoch (train): [15][62650/74490]	Time 0.086 (0.126)	Data 0.000 (0.050)	Loss 0.9989 (2.1198)
Epoch (train): [15][63650/74490]	Time 0.070 (0.126)	Data 0.000 (0.050)	Loss 2.1236 (2.1194)
Epoch (train): [15][64650/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 10.5324 (2.1203)
Epoch (train): [15][65650/74490]	Time 0.083 (0.125)	Data 0.001 (0.050)	Loss 2.9275 (2.1210)
Epoch (train): [15][66650/74490]	Time 0.324 (0.125)	Data 0.289 (0.050)	Loss 1.9903 (2.1202)
Epoch (train): [15][67650/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 1.5953 (2.1198)
Epoch (train): [15][68650/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 10.9797 (2.1198)
Epoch (train): [15][69650/74490]	Time 0.081 (0.125)	Data 0.000 (0.049)	Loss 1.8338 (2.1201)
Epoch (train): [15][70650/74490]	Time 0.077 (0.125)	Data 0.000 (0.049)	Loss 1.8358 (2.1197)
Epoch (train): [15][71650/74490]	Time 0.082 (0.125)	Data 0.000 (0.049)	Loss 2.2158 (2.1205)
Epoch (train): [15][72650/74490]	Time 0.079 (0.125)	Data 0.000 (0.049)	Loss 1.3574 (2.1208)
Epoch (train): [15][73650/74490]	Time 0.082 (0.125)	Data 0.001 (0.049)	Loss 1.5495 (2.1219)
Epoch (train): [16][160/74490]	Time 0.085 (0.129)	Data 0.000 (0.056)	Loss 1.7921 (1.8350)
Epoch (train): [16][1160/74490]	Time 0.088 (0.121)	Data 0.000 (0.044)	Loss 1.7362 (1.9983)
Epoch (train): [16][2160/74490]	Time 0.077 (0.121)	Data 0.000 (0.045)	Loss 3.8187 (1.9904)
Epoch (train): [16][3160/74490]	Time 0.083 (0.121)	Data 0.001 (0.045)	Loss 1.7048 (1.9890)
Epoch (train): [16][4160/74490]	Time 0.087 (0.121)	Data 0.000 (0.045)	Loss 1.4097 (1.9992)
Epoch (train): [16][5160/74490]	Time 0.079 (0.121)	Data 0.000 (0.044)	Loss 1.8068 (1.9970)
Epoch (train): [16][6160/74490]	Time 0.085 (0.121)	Data 0.000 (0.045)	Loss 2.2341 (2.0015)
Epoch (train): [16][7160/74490]	Time 0.082 (0.121)	Data 0.000 (0.044)	Loss 2.5737 (2.0003)
Epoch (train): [16][8160/74490]	Time 0.086 (0.120)	Data 0.000 (0.044)	Loss 1.0836 (2.0045)
Epoch (train): [16][9160/74490]	Time 0.086 (0.120)	Data 0.000 (0.043)	Loss 2.2022 (2.0082)
Epoch (train): [16][10160/74490]	Time 0.082 (0.119)	Data 0.000 (0.043)	Loss 2.5674 (2.0143)
Epoch (train): [16][11160/74490]	Time 0.085 (0.119)	Data 0.000 (0.043)	Loss 2.9546 (2.0132)
Epoch (train): [16][12160/74490]	Time 0.084 (0.118)	Data 0.000 (0.043)	Loss 2.6085 (2.0150)
Epoch (train): [16][13160/74490]	Time 0.094 (0.118)	Data 0.000 (0.042)	Loss 1.4982 (2.0139)
Epoch (train): [16][14160/74490]	Time 0.085 (0.118)	Data 0.000 (0.042)	Loss 0.8602 (2.0127)
Epoch (train): [16][15160/74490]	Time 0.088 (0.118)	Data 0.000 (0.042)	Loss 5.3370 (2.0120)
Epoch (train): [16][16160/74490]	Time 0.080 (0.118)	Data 0.000 (0.042)	Loss 1.7368 (2.0133)
Epoch (train): [16][17160/74490]	Time 0.086 (0.118)	Data 0.000 (0.042)	Loss 1.0773 (2.0172)
Epoch (train): [16][18160/74490]	Time 0.084 (0.118)	Data 0.000 (0.042)	Loss 1.6040 (2.0142)
Epoch (train): [16][19160/74490]	Time 0.081 (0.118)	Data 0.000 (0.042)	Loss 2.0295 (2.0125)
Epoch (train): [16][20160/74490]	Time 0.094 (0.119)	Data 0.000 (0.042)	Loss 1.1990 (2.0120)
Epoch (train): [16][21160/74490]	Time 0.081 (0.119)	Data 0.000 (0.042)	Loss 1.6352 (2.0092)
Epoch (train): [16][22160/74490]	Time 0.086 (0.119)	Data 0.001 (0.042)	Loss 3.1564 (2.0068)
Epoch (train): [16][23160/74490]	Time 0.090 (0.119)	Data 0.000 (0.042)	Loss 1.5129 (2.0075)
Epoch (train): [16][24160/74490]	Time 0.085 (0.119)	Data 0.000 (0.043)	Loss 1.0171 (2.0087)
Epoch (train): [16][25160/74490]	Time 0.087 (0.119)	Data 0.000 (0.043)	Loss 1.0539 (2.0082)
Epoch (train): [16][26160/74490]	Time 0.082 (0.119)	Data 0.001 (0.043)	Loss 3.2667 (2.0087)
Epoch (train): [16][27160/74490]	Time 0.085 (0.119)	Data 0.000 (0.043)	Loss 1.7117 (2.0082)
Epoch (train): [16][28160/74490]	Time 0.084 (0.120)	Data 0.000 (0.043)	Loss 2.0493 (2.0109)
Epoch (train): [16][29160/74490]	Time 0.091 (0.120)	Data 0.000 (0.043)	Loss 7.5844 (2.0116)
Epoch (train): [16][30160/74490]	Time 0.086 (0.120)	Data 0.000 (0.043)	Loss 0.8607 (2.0132)
Epoch (train): [16][31160/74490]	Time 0.081 (0.120)	Data 0.000 (0.043)	Loss 1.3178 (2.0138)
Epoch (train): [16][32160/74490]	Time 0.083 (0.120)	Data 0.000 (0.043)	Loss 1.9747 (2.0157)
Epoch (train): [16][33160/74490]	Time 0.084 (0.120)	Data 0.000 (0.043)	Loss 2.4072 (2.0163)
Epoch (train): [16][34160/74490]	Time 0.085 (0.120)	Data 0.000 (0.043)	Loss 1.8558 (2.0164)
Epoch (train): [16][35160/74490]	Time 0.081 (0.120)	Data 0.000 (0.043)	Loss 1.9159 (2.0153)
Epoch (train): [16][36160/74490]	Time 0.081 (0.120)	Data 0.000 (0.043)	Loss 2.4309 (2.0173)
Epoch (train): [16][37160/74490]	Time 0.088 (0.120)	Data 0.000 (0.043)	Loss 5.2086 (2.0179)
Epoch (train): [16][38160/74490]	Time 0.083 (0.120)	Data 0.000 (0.044)	Loss 1.0512 (2.0190)
Epoch (train): [16][39160/74490]	Time 0.079 (0.120)	Data 0.000 (0.044)	Loss 1.1481 (2.0177)
Epoch (train): [16][40160/74490]	Time 0.093 (0.120)	Data 0.000 (0.044)	Loss 2.7463 (2.0196)
Epoch (train): [16][41160/74490]	Time 0.083 (0.121)	Data 0.000 (0.044)	Loss 1.0610 (2.0210)
Epoch (train): [16][42160/74490]	Time 0.093 (0.121)	Data 0.000 (0.044)	Loss 0.5933 (2.0204)
Epoch (train): [16][43160/74490]	Time 0.089 (0.121)	Data 0.000 (0.044)	Loss 2.2360 (2.0222)
Epoch (train): [16][44160/74490]	Time 0.082 (0.121)	Data 0.000 (0.044)	Loss 1.5576 (2.0225)
Epoch (train): [16][45160/74490]	Time 0.099 (0.121)	Data 0.000 (0.044)	Loss 2.0100 (2.0222)
Epoch (train): [16][46160/74490]	Time 0.083 (0.121)	Data 0.000 (0.044)	Loss 1.1617 (2.0235)
Epoch (train): [16][47160/74490]	Time 0.091 (0.121)	Data 0.000 (0.044)	Loss 1.9842 (2.0239)
Epoch (train): [16][48160/74490]	Time 0.087 (0.121)	Data 0.000 (0.044)	Loss 1.5391 (2.0259)
Epoch (train): [16][49160/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 1.0385 (2.0269)
Epoch (train): [16][50160/74490]	Time 0.085 (0.121)	Data 0.000 (0.045)	Loss 0.8854 (2.0269)
Epoch (train): [16][51160/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 1.4315 (2.0275)
Epoch (train): [16][52160/74490]	Time 0.085 (0.122)	Data 0.000 (0.045)	Loss 0.5077 (2.0277)
Epoch (train): [16][53160/74490]	Time 0.082 (0.122)	Data 0.000 (0.045)	Loss 5.2607 (2.0279)
Epoch (train): [16][54160/74490]	Time 0.071 (0.122)	Data 0.000 (0.045)	Loss 1.3900 (2.0281)
Epoch (train): [16][55160/74490]	Time 0.084 (0.122)	Data 0.001 (0.045)	Loss 0.7898 (2.0290)
Epoch (train): [16][56160/74490]	Time 0.084 (0.122)	Data 0.000 (0.045)	Loss 1.7688 (2.0298)
Epoch (train): [16][57160/74490]	Time 0.084 (0.122)	Data 0.000 (0.045)	Loss 3.4599 (2.0310)
Epoch (train): [16][58160/74490]	Time 0.082 (0.122)	Data 0.000 (0.045)	Loss 3.5536 (2.0306)
Epoch (train): [16][59160/74490]	Time 0.084 (0.122)	Data 0.000 (0.045)	Loss 1.1883 (2.0302)
Epoch (train): [16][60160/74490]	Time 0.085 (0.122)	Data 0.000 (0.045)	Loss 0.7595 (2.0305)
Epoch (train): [16][61160/74490]	Time 0.082 (0.122)	Data 0.001 (0.045)	Loss 2.6979 (2.0312)
Epoch (train): [16][62160/74490]	Time 0.083 (0.122)	Data 0.000 (0.046)	Loss 1.3620 (2.0315)
Epoch (train): [16][63160/74490]	Time 0.088 (0.122)	Data 0.000 (0.046)	Loss 1.7528 (2.0306)
Epoch (train): [16][64160/74490]	Time 0.099 (0.122)	Data 0.000 (0.046)	Loss 2.3261 (2.0303)
Epoch (train): [16][65160/74490]	Time 0.085 (0.122)	Data 0.000 (0.046)	Loss 2.5747 (2.0310)
Epoch (train): [16][66160/74490]	Time 0.085 (0.123)	Data 0.000 (0.046)	Loss 2.7959 (2.0315)
Epoch (train): [16][67160/74490]	Time 0.084 (0.123)	Data 0.001 (0.046)	Loss 1.6184 (2.0314)
Epoch (train): [16][68160/74490]	Time 0.082 (0.123)	Data 0.000 (0.046)	Loss 5.6139 (2.0315)
Epoch (train): [16][69160/74490]	Time 0.082 (0.123)	Data 0.000 (0.046)	Loss 0.8678 (2.0319)
Epoch (train): [16][70160/74490]	Time 0.086 (0.123)	Data 0.000 (0.046)	Loss 1.8167 (2.0318)
Epoch (train): [16][71160/74490]	Time 0.081 (0.123)	Data 0.000 (0.046)	Loss 2.7544 (2.0323)
Epoch (train): [16][72160/74490]	Time 0.081 (0.123)	Data 0.000 (0.046)	Loss 1.8429 (2.0327)
Epoch (train): [16][73160/74490]	Time 0.081 (0.123)	Data 0.000 (0.046)	Loss 5.7704 (2.0336)
Epoch (train): [16][74160/74490]	Time 0.089 (0.123)	Data 0.000 (0.046)	Loss 2.0546 (2.0342)
Epoch (train): [17][670/74490]	Time 0.094 (0.131)	Data 0.000 (0.058)	Loss 1.2127 (1.7740)
Epoch (train): [17][1670/74490]	Time 0.154 (0.130)	Data 0.114 (0.055)	Loss 1.8532 (1.8501)
Epoch (train): [17][2670/74490]	Time 0.455 (0.130)	Data 0.414 (0.054)	Loss 2.9053 (1.8532)
Epoch (train): [17][3670/74490]	Time 0.442 (0.129)	Data 0.402 (0.053)	Loss 5.6860 (1.8645)
Epoch (train): [17][4670/74490]	Time 0.087 (0.129)	Data 0.001 (0.053)	Loss 2.2757 (1.8815)
Epoch (train): [17][5670/74490]	Time 0.079 (0.129)	Data 0.000 (0.054)	Loss 1.9169 (1.8728)
Epoch (train): [17][6670/74490]	Time 0.160 (0.129)	Data 0.128 (0.054)	Loss 1.0568 (1.8780)
Epoch (train): [17][7670/74490]	Time 0.083 (0.128)	Data 0.000 (0.053)	Loss 1.8223 (1.8855)
Epoch (train): [17][8670/74490]	Time 0.101 (0.128)	Data 0.000 (0.053)	Loss 1.5253 (1.8798)
Epoch (train): [17][9670/74490]	Time 0.086 (0.128)	Data 0.000 (0.053)	Loss 1.2167 (1.8877)
Epoch (train): [17][10670/74490]	Time 0.085 (0.127)	Data 0.000 (0.053)	Loss 1.5438 (1.8988)
Epoch (train): [17][11670/74490]	Time 0.336 (0.127)	Data 0.301 (0.052)	Loss 2.1564 (1.9022)
Epoch (train): [17][12670/74490]	Time 0.337 (0.127)	Data 0.296 (0.052)	Loss 1.4149 (1.9036)
Epoch (train): [17][13670/74490]	Time 0.377 (0.126)	Data 0.337 (0.051)	Loss 1.6699 (1.9091)
Epoch (train): [17][14670/74490]	Time 0.380 (0.126)	Data 0.340 (0.051)	Loss 1.3893 (1.9127)
Epoch (train): [17][15670/74490]	Time 0.337 (0.126)	Data 0.297 (0.051)	Loss 1.8404 (1.9154)
Epoch (train): [17][16670/74490]	Time 0.084 (0.126)	Data 0.000 (0.050)	Loss 0.7700 (1.9143)
Epoch (train): [17][17670/74490]	Time 0.093 (0.126)	Data 0.002 (0.050)	Loss 0.6583 (1.9153)
Epoch (train): [17][18670/74490]	Time 0.487 (0.126)	Data 0.445 (0.050)	Loss 0.7237 (1.9152)
Epoch (train): [17][19670/74490]	Time 0.130 (0.125)	Data 0.092 (0.050)	Loss 0.7105 (1.9145)
Epoch (train): [17][20670/74490]	Time 0.412 (0.125)	Data 0.377 (0.050)	Loss 1.6804 (1.9177)
Epoch (train): [17][21670/74490]	Time 0.350 (0.125)	Data 0.311 (0.049)	Loss 2.1683 (1.9180)
Epoch (train): [17][22670/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 1.5535 (1.9198)
Epoch (train): [17][23670/74490]	Time 0.081 (0.125)	Data 0.000 (0.049)	Loss 2.2709 (1.9218)
Epoch (train): [17][24670/74490]	Time 0.085 (0.125)	Data 0.038 (0.049)	Loss 1.9342 (1.9189)
Epoch (train): [17][25670/74490]	Time 0.285 (0.125)	Data 0.248 (0.049)	Loss 2.1055 (1.9168)
Epoch (train): [17][26670/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 0.8305 (1.9182)
Epoch (train): [17][27670/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 2.4007 (1.9201)
Epoch (train): [17][28670/74490]	Time 0.125 (0.125)	Data 0.089 (0.049)	Loss 2.4150 (1.9220)
Epoch (train): [17][29670/74490]	Time 0.275 (0.125)	Data 0.242 (0.049)	Loss 1.7048 (1.9235)
Epoch (train): [17][30670/74490]	Time 0.082 (0.125)	Data 0.000 (0.049)	Loss 2.3074 (1.9225)
Epoch (train): [17][31670/74490]	Time 0.096 (0.125)	Data 0.000 (0.049)	Loss 1.2473 (1.9236)
Epoch (train): [17][32670/74490]	Time 0.084 (0.125)	Data 0.000 (0.049)	Loss 0.8145 (1.9241)
Epoch (train): [17][33670/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 1.1205 (1.9256)
Epoch (train): [17][34670/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 3.0597 (1.9295)
Epoch (train): [17][35670/74490]	Time 0.097 (0.125)	Data 0.000 (0.049)	Loss 5.4267 (1.9308)
Epoch (train): [17][36670/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 2.6688 (1.9311)
Epoch (train): [17][37670/74490]	Time 0.083 (0.125)	Data 0.003 (0.049)	Loss 1.1191 (1.9314)
Epoch (train): [17][38670/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 1.4966 (1.9305)
Epoch (train): [17][39670/74490]	Time 0.091 (0.125)	Data 0.000 (0.049)	Loss 2.6745 (1.9313)
Epoch (train): [17][40670/74490]	Time 0.145 (0.125)	Data 0.108 (0.049)	Loss 1.6888 (1.9325)
Epoch (train): [17][41670/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 1.1584 (1.9341)
Epoch (train): [17][42670/74490]	Time 0.437 (0.125)	Data 0.400 (0.049)	Loss 1.4951 (1.9346)
Epoch (train): [17][43670/74490]	Time 0.425 (0.125)	Data 0.388 (0.049)	Loss 1.9821 (1.9351)
Epoch (train): [17][44670/74490]	Time 0.367 (0.125)	Data 0.324 (0.049)	Loss 1.5768 (1.9371)
Epoch (train): [17][45670/74490]	Time 0.454 (0.125)	Data 0.418 (0.049)	Loss 1.2723 (1.9359)
Epoch (train): [17][46670/74490]	Time 0.441 (0.125)	Data 0.404 (0.049)	Loss 1.1631 (1.9345)
Epoch (train): [17][47670/74490]	Time 0.365 (0.125)	Data 0.326 (0.049)	Loss 1.4178 (1.9358)
Epoch (train): [17][48670/74490]	Time 0.321 (0.125)	Data 0.285 (0.049)	Loss 1.5267 (1.9364)
Epoch (train): [17][49670/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 4.8988 (1.9355)
Epoch (train): [17][50670/74490]	Time 0.143 (0.125)	Data 0.101 (0.049)	Loss 0.7167 (1.9349)
Epoch (train): [17][51670/74490]	Time 0.397 (0.125)	Data 0.353 (0.049)	Loss 1.5947 (1.9354)
Epoch (train): [17][52670/74490]	Time 0.302 (0.125)	Data 0.253 (0.049)	Loss 1.0409 (1.9369)
Epoch (train): [17][53670/74490]	Time 0.411 (0.125)	Data 0.373 (0.049)	Loss 1.3052 (1.9387)
Epoch (train): [17][54670/74490]	Time 0.340 (0.125)	Data 0.302 (0.049)	Loss 2.1801 (1.9407)
Epoch (train): [17][55670/74490]	Time 0.384 (0.125)	Data 0.350 (0.049)	Loss 2.2066 (1.9421)
Epoch (train): [17][56670/74490]	Time 0.458 (0.125)	Data 0.416 (0.049)	Loss 1.7769 (1.9433)
Epoch (train): [17][57670/74490]	Time 0.099 (0.125)	Data 0.000 (0.049)	Loss 3.5203 (1.9433)
Epoch (train): [17][58670/74490]	Time 0.073 (0.125)	Data 0.000 (0.049)	Loss 3.0877 (1.9443)
Epoch (train): [17][59670/74490]	Time 0.086 (0.125)	Data 0.002 (0.049)	Loss 2.1315 (1.9450)
Epoch (train): [17][60670/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 1.5446 (1.9460)
Epoch (train): [17][61670/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 1.3507 (1.9468)
Epoch (train): [17][62670/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 1.6882 (1.9465)
Epoch (train): [17][63670/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 4.0468 (1.9486)
Epoch (train): [17][64670/74490]	Time 0.411 (0.125)	Data 0.363 (0.049)	Loss 1.0930 (1.9486)
Epoch (train): [17][65670/74490]	Time 0.079 (0.126)	Data 0.000 (0.049)	Loss 0.7872 (1.9489)
Epoch (train): [17][66670/74490]	Time 0.084 (0.126)	Data 0.000 (0.049)	Loss 2.4071 (1.9495)
Epoch (train): [17][67670/74490]	Time 0.071 (0.126)	Data 0.000 (0.049)	Loss 2.1988 (1.9491)
Epoch (train): [17][68670/74490]	Time 0.079 (0.126)	Data 0.000 (0.049)	Loss 1.7199 (1.9498)
Epoch (train): [17][69670/74490]	Time 0.088 (0.126)	Data 0.000 (0.049)	Loss 2.7210 (1.9506)
Epoch (train): [17][70670/74490]	Time 0.092 (0.126)	Data 0.000 (0.049)	Loss 1.1832 (1.9505)
Epoch (train): [17][71670/74490]	Time 0.088 (0.126)	Data 0.000 (0.049)	Loss 1.5795 (1.9513)
Epoch (train): [17][72670/74490]	Time 0.083 (0.126)	Data 0.000 (0.049)	Loss 3.0575 (1.9511)
Epoch (train): [17][73670/74490]	Time 0.083 (0.126)	Data 0.000 (0.049)	Loss 0.7146 (1.9519)
Epoch (train): [18][180/74490]	Time 0.089 (0.157)	Data 0.000 (0.079)	Loss 1.5006 (1.9341)
Epoch (train): [18][1180/74490]	Time 0.088 (0.147)	Data 0.000 (0.070)	Loss 3.9812 (1.9004)
Epoch (train): [18][2180/74490]	Time 0.080 (0.143)	Data 0.000 (0.066)	Loss 1.4715 (1.8522)
Epoch (train): [18][3180/74490]	Time 0.085 (0.140)	Data 0.000 (0.064)	Loss 3.1967 (1.8267)
Epoch (train): [18][4180/74490]	Time 0.082 (0.139)	Data 0.000 (0.062)	Loss 1.3100 (1.8288)
Epoch (train): [18][5180/74490]	Time 0.076 (0.138)	Data 0.000 (0.061)	Loss 2.0347 (1.8277)
Epoch (train): [18][6180/74490]	Time 0.080 (0.137)	Data 0.000 (0.061)	Loss 1.3903 (1.8262)
Epoch (train): [18][7180/74490]	Time 0.120 (0.136)	Data 0.086 (0.060)	Loss 1.4700 (1.8323)
Epoch (train): [18][8180/74490]	Time 0.085 (0.136)	Data 0.000 (0.060)	Loss 0.9432 (1.8380)
Epoch (train): [18][9180/74490]	Time 0.082 (0.135)	Data 0.000 (0.059)	Loss 1.2733 (1.8382)
Epoch (train): [18][10180/74490]	Time 0.096 (0.135)	Data 0.061 (0.059)	Loss 2.6061 (1.8399)
Epoch (train): [18][11180/74490]	Time 0.080 (0.135)	Data 0.000 (0.060)	Loss 2.0630 (1.8402)
Epoch (train): [18][12180/74490]	Time 0.089 (0.134)	Data 0.000 (0.059)	Loss 1.7333 (1.8420)
Epoch (train): [18][13180/74490]	Time 0.090 (0.134)	Data 0.000 (0.059)	Loss 2.0338 (1.8407)
Epoch (train): [18][14180/74490]	Time 0.087 (0.134)	Data 0.000 (0.059)	Loss 1.6205 (1.8429)
Epoch (train): [18][15180/74490]	Time 0.082 (0.134)	Data 0.000 (0.059)	Loss 0.7001 (1.8413)
Epoch (train): [18][16180/74490]	Time 0.083 (0.134)	Data 0.000 (0.059)	Loss 1.4678 (1.8428)
Epoch (train): [18][17180/74490]	Time 0.074 (0.133)	Data 0.000 (0.058)	Loss 2.1006 (1.8395)
Epoch (train): [18][18180/74490]	Time 0.081 (0.133)	Data 0.000 (0.058)	Loss 2.6246 (1.8418)
Epoch (train): [18][19180/74490]	Time 0.082 (0.133)	Data 0.000 (0.058)	Loss 3.1915 (1.8424)
Epoch (train): [18][20180/74490]	Time 0.081 (0.133)	Data 0.000 (0.058)	Loss 1.6952 (1.8452)
Epoch (train): [18][21180/74490]	Time 0.087 (0.132)	Data 0.000 (0.057)	Loss 2.2828 (1.8431)
Epoch (train): [18][22180/74490]	Time 0.090 (0.132)	Data 0.000 (0.057)	Loss 2.0128 (1.8450)
Epoch (train): [18][23180/74490]	Time 0.097 (0.132)	Data 0.000 (0.057)	Loss 1.8754 (1.8458)
Epoch (train): [18][24180/74490]	Time 0.074 (0.131)	Data 0.000 (0.056)	Loss 1.1912 (1.8469)
Epoch (train): [18][25180/74490]	Time 0.086 (0.131)	Data 0.000 (0.056)	Loss 1.5589 (1.8472)
Epoch (train): [18][26180/74490]	Time 0.086 (0.131)	Data 0.000 (0.056)	Loss 0.8948 (1.8484)
Epoch (train): [18][27180/74490]	Time 0.087 (0.131)	Data 0.000 (0.056)	Loss 2.2286 (1.8476)
Epoch (train): [18][28180/74490]	Time 0.452 (0.131)	Data 0.417 (0.055)	Loss 1.0759 (1.8470)
Epoch (train): [18][29180/74490]	Time 0.365 (0.131)	Data 0.323 (0.055)	Loss 1.5031 (1.8475)
Epoch (train): [18][30180/74490]	Time 0.105 (0.130)	Data 0.057 (0.055)	Loss 2.5695 (1.8469)
Epoch (train): [18][31180/74490]	Time 0.277 (0.130)	Data 0.239 (0.055)	Loss 0.8394 (1.8476)
Epoch (train): [18][32180/74490]	Time 0.080 (0.130)	Data 0.000 (0.055)	Loss 1.7751 (1.8490)
Epoch (train): [18][33180/74490]	Time 0.090 (0.130)	Data 0.000 (0.055)	Loss 0.9035 (1.8497)
Epoch (train): [18][34180/74490]	Time 0.085 (0.130)	Data 0.000 (0.055)	Loss 1.2189 (1.8525)
Epoch (train): [18][35180/74490]	Time 0.078 (0.130)	Data 0.000 (0.055)	Loss 1.2271 (1.8521)
Epoch (train): [18][36180/74490]	Time 0.086 (0.130)	Data 0.000 (0.055)	Loss 1.2629 (1.8524)
Epoch (train): [18][37180/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 2.0742 (1.8532)
Epoch (train): [18][38180/74490]	Time 0.089 (0.130)	Data 0.000 (0.054)	Loss 3.3674 (1.8542)
Epoch (train): [18][39180/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 1.0623 (1.8566)
Epoch (train): [18][40180/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 0.9234 (1.8577)
Epoch (train): [18][41180/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 0.6791 (1.8589)
Epoch (train): [18][42180/74490]	Time 0.087 (0.130)	Data 0.000 (0.054)	Loss 0.8152 (1.8582)
Epoch (train): [18][43180/74490]	Time 0.083 (0.129)	Data 0.000 (0.054)	Loss 2.0889 (1.8598)
Epoch (train): [18][44180/74490]	Time 0.070 (0.129)	Data 0.000 (0.054)	Loss 1.9430 (1.8605)
Epoch (train): [18][45180/74490]	Time 0.085 (0.129)	Data 0.000 (0.054)	Loss 2.0940 (1.8604)
Epoch (train): [18][46180/74490]	Time 0.086 (0.129)	Data 0.002 (0.054)	Loss 0.7842 (1.8611)
Epoch (train): [18][47180/74490]	Time 0.090 (0.129)	Data 0.000 (0.054)	Loss 2.3016 (1.8623)
Epoch (train): [18][48180/74490]	Time 0.089 (0.129)	Data 0.000 (0.054)	Loss 1.7839 (1.8629)
Epoch (train): [18][49180/74490]	Time 0.080 (0.129)	Data 0.000 (0.054)	Loss 1.1435 (1.8630)
Epoch (train): [18][50180/74490]	Time 0.085 (0.129)	Data 0.000 (0.054)	Loss 1.3111 (1.8643)
Epoch (train): [18][51180/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 1.1003 (1.8644)
Epoch (train): [18][52180/74490]	Time 0.228 (0.129)	Data 0.191 (0.054)	Loss 1.2780 (1.8647)
Epoch (train): [18][53180/74490]	Time 0.538 (0.129)	Data 0.491 (0.053)	Loss 1.7917 (1.8647)
Epoch (train): [18][54180/74490]	Time 0.087 (0.129)	Data 0.000 (0.053)	Loss 1.8557 (1.8650)
Epoch (train): [18][55180/74490]	Time 0.088 (0.129)	Data 0.002 (0.053)	Loss 1.2691 (1.8650)
Epoch (train): [18][56180/74490]	Time 0.089 (0.129)	Data 0.000 (0.053)	Loss 1.5312 (1.8665)
Epoch (train): [18][57180/74490]	Time 0.082 (0.129)	Data 0.000 (0.053)	Loss 2.1960 (1.8659)
Epoch (train): [18][58180/74490]	Time 0.084 (0.129)	Data 0.000 (0.053)	Loss 1.7795 (1.8686)
Epoch (train): [18][59180/74490]	Time 0.086 (0.129)	Data 0.000 (0.053)	Loss 2.4902 (1.8689)
Epoch (train): [18][60180/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 2.1524 (1.8696)
Epoch (train): [18][61180/74490]	Time 0.084 (0.129)	Data 0.000 (0.053)	Loss 1.0590 (1.8714)
Epoch (train): [18][62180/74490]	Time 0.086 (0.129)	Data 0.000 (0.053)	Loss 0.7041 (1.8714)
Epoch (train): [18][63180/74490]	Time 0.085 (0.129)	Data 0.000 (0.053)	Loss 2.7205 (1.8723)
Epoch (train): [18][64180/74490]	Time 0.083 (0.129)	Data 0.000 (0.053)	Loss 2.6926 (1.8731)
Epoch (train): [18][65180/74490]	Time 0.085 (0.129)	Data 0.000 (0.053)	Loss 1.8484 (1.8729)
Epoch (train): [18][66180/74490]	Time 0.085 (0.129)	Data 0.000 (0.053)	Loss 2.0248 (1.8731)
Epoch (train): [18][67180/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 3.8993 (1.8726)
Epoch (train): [18][68180/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 5.7492 (1.8733)
Epoch (train): [18][69180/74490]	Time 0.084 (0.129)	Data 0.000 (0.054)	Loss 1.1448 (1.8743)
Epoch (train): [18][70180/74490]	Time 0.079 (0.129)	Data 0.000 (0.054)	Loss 1.5840 (1.8747)
Epoch (train): [18][71180/74490]	Time 0.081 (0.129)	Data 0.000 (0.054)	Loss 1.1356 (1.8744)
Epoch (train): [18][72180/74490]	Time 0.086 (0.129)	Data 0.000 (0.054)	Loss 2.8939 (1.8745)
Epoch (train): [18][73180/74490]	Time 0.086 (0.129)	Data 0.000 (0.054)	Loss 1.0790 (1.8748)
Epoch (train): [18][74180/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 0.8531 (1.8766)
Epoch (train): [19][690/74490]	Time 0.139 (0.121)	Data 0.102 (0.050)	Loss 1.9620 (1.6983)
Epoch (train): [19][1690/74490]	Time 0.306 (0.121)	Data 0.266 (0.048)	Loss 1.5398 (1.7421)
Epoch (train): [19][2690/74490]	Time 0.269 (0.120)	Data 0.234 (0.046)	Loss 1.4251 (1.7429)
Epoch (train): [19][3690/74490]	Time 0.089 (0.120)	Data 0.000 (0.045)	Loss 1.2091 (1.7522)
Epoch (train): [19][4690/74490]	Time 0.085 (0.120)	Data 0.000 (0.044)	Loss 0.9776 (1.7483)
