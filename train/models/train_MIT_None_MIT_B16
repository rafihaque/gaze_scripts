Epoch (train): [0][0/74490]	Time 1.986 (1.986)	Data 1.288 (1.288)	Loss 17.6998 (17.6998)
Epoch (train): [0][1000/74490]	Time 0.083 (0.122)	Data 0.000 (0.046)	Loss 31.9574 (30.6864)
Epoch (train): [0][2000/74490]	Time 0.090 (0.121)	Data 0.000 (0.045)	Loss 22.6640 (30.3700)
Epoch (train): [0][3000/74490]	Time 0.076 (0.121)	Data 0.001 (0.044)	Loss 12.1449 (29.2319)
Epoch (train): [0][4000/74490]	Time 0.084 (0.120)	Data 0.000 (0.044)	Loss 20.7989 (27.5574)
Epoch (train): [0][5000/74490]	Time 0.080 (0.121)	Data 0.000 (0.044)	Loss 19.3753 (25.2540)
Epoch (train): [0][6000/74490]	Time 0.084 (0.121)	Data 0.000 (0.044)	Loss 7.3919 (23.4739)
Epoch (train): [0][7000/74490]	Time 0.089 (0.121)	Data 0.000 (0.044)	Loss 21.8045 (22.1770)
Epoch (train): [0][8000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 19.4650 (21.1376)
Epoch (train): [0][9000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 27.8295 (20.3612)
Epoch (train): [0][10000/74490]	Time 0.085 (0.121)	Data 0.000 (0.045)	Loss 18.1899 (19.6977)
Epoch (train): [0][11000/74490]	Time 0.083 (0.121)	Data 0.000 (0.045)	Loss 11.6471 (19.0981)
Epoch (train): [0][12000/74490]	Time 0.090 (0.121)	Data 0.000 (0.045)	Loss 11.4695 (18.6134)
Epoch (train): [0][13000/74490]	Time 0.076 (0.121)	Data 0.000 (0.045)	Loss 14.8521 (18.1762)
Epoch (train): [0][14000/74490]	Time 0.080 (0.121)	Data 0.000 (0.045)	Loss 6.7990 (17.7948)
Epoch (train): [0][15000/74490]	Time 0.084 (0.121)	Data 0.000 (0.045)	Loss 7.1835 (17.4781)
Epoch (train): [0][16000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 8.9725 (17.1831)
Epoch (train): [0][17000/74490]	Time 0.085 (0.121)	Data 0.000 (0.045)	Loss 11.9297 (16.9264)
Epoch (train): [0][18000/74490]	Time 0.079 (0.121)	Data 0.000 (0.045)	Loss 14.0742 (16.6896)
Epoch (train): [0][19000/74490]	Time 0.077 (0.121)	Data 0.000 (0.045)	Loss 9.7632 (16.4744)
Epoch (train): [0][20000/74490]	Time 0.087 (0.121)	Data 0.000 (0.045)	Loss 12.4675 (16.2772)
Epoch (train): [0][21000/74490]	Time 0.089 (0.121)	Data 0.000 (0.045)	Loss 13.5318 (16.0939)
Epoch (train): [0][22000/74490]	Time 0.082 (0.121)	Data 0.000 (0.045)	Loss 19.4371 (15.9321)
Epoch (train): [0][23000/74490]	Time 0.095 (0.121)	Data 0.000 (0.045)	Loss 10.0183 (15.7868)
Epoch (train): [0][24000/74490]	Time 0.086 (0.122)	Data 0.003 (0.045)	Loss 17.0535 (15.6346)
Epoch (train): [0][25000/74490]	Time 0.086 (0.122)	Data 0.002 (0.045)	Loss 5.2958 (15.4957)
Epoch (train): [0][26000/74490]	Time 0.072 (0.122)	Data 0.000 (0.045)	Loss 8.2184 (15.3667)
Epoch (train): [0][27000/74490]	Time 0.081 (0.122)	Data 0.000 (0.045)	Loss 10.4329 (15.2538)
Epoch (train): [0][28000/74490]	Time 0.077 (0.122)	Data 0.001 (0.045)	Loss 12.2500 (15.1532)
Epoch (train): [0][29000/74490]	Time 0.096 (0.122)	Data 0.002 (0.045)	Loss 7.0237 (15.0609)
Epoch (train): [0][30000/74490]	Time 0.081 (0.123)	Data 0.001 (0.046)	Loss 10.6201 (14.9647)
Epoch (train): [0][31000/74490]	Time 0.083 (0.123)	Data 0.001 (0.046)	Loss 10.0719 (14.8769)
Epoch (train): [0][32000/74490]	Time 0.082 (0.123)	Data 0.000 (0.047)	Loss 7.3069 (14.7911)
Epoch (train): [0][33000/74490]	Time 0.081 (0.124)	Data 0.000 (0.047)	Loss 6.2986 (14.7064)
Epoch (train): [0][34000/74490]	Time 0.099 (0.124)	Data 0.000 (0.047)	Loss 7.7048 (14.6358)
Epoch (train): [0][35000/74490]	Time 0.085 (0.125)	Data 0.000 (0.048)	Loss 8.6893 (14.5684)
Epoch (train): [0][36000/74490]	Time 0.077 (0.125)	Data 0.000 (0.048)	Loss 17.9132 (14.4982)
Epoch (train): [0][37000/74490]	Time 0.079 (0.125)	Data 0.000 (0.048)	Loss 5.9215 (14.4306)
Epoch (train): [0][38000/74490]	Time 0.086 (0.126)	Data 0.000 (0.048)	Loss 6.9176 (14.3595)
Epoch (train): [0][39000/74490]	Time 0.087 (0.126)	Data 0.000 (0.049)	Loss 15.0232 (14.3004)
Epoch (train): [0][40000/74490]	Time 0.077 (0.126)	Data 0.001 (0.049)	Loss 16.7143 (14.2500)
Epoch (train): [0][41000/74490]	Time 0.071 (0.126)	Data 0.000 (0.049)	Loss 8.3035 (14.1945)
Epoch (train): [0][42000/74490]	Time 0.082 (0.126)	Data 0.000 (0.049)	Loss 17.7448 (14.1395)
Epoch (train): [0][43000/74490]	Time 0.091 (0.127)	Data 0.000 (0.049)	Loss 17.7781 (14.0902)
Epoch (train): [0][44000/74490]	Time 0.081 (0.127)	Data 0.000 (0.049)	Loss 12.7499 (14.0384)
Epoch (train): [0][45000/74490]	Time 0.088 (0.127)	Data 0.000 (0.049)	Loss 9.9648 (13.9899)
Epoch (train): [0][46000/74490]	Time 0.083 (0.127)	Data 0.000 (0.049)	Loss 18.3363 (13.9456)
Epoch (train): [0][47000/74490]	Time 0.077 (0.127)	Data 0.000 (0.049)	Loss 10.1903 (13.9033)
Epoch (train): [0][48000/74490]	Time 0.101 (0.127)	Data 0.000 (0.050)	Loss 13.5348 (13.8628)
Epoch (train): [0][49000/74490]	Time 0.083 (0.127)	Data 0.000 (0.050)	Loss 14.4800 (13.8256)
Epoch (train): [0][50000/74490]	Time 0.076 (0.127)	Data 0.000 (0.050)	Loss 14.2707 (13.7928)
Epoch (train): [0][51000/74490]	Time 0.095 (0.127)	Data 0.000 (0.050)	Loss 18.2562 (13.7599)
Epoch (train): [0][52000/74490]	Time 0.085 (0.128)	Data 0.000 (0.050)	Loss 9.3083 (13.7272)
Epoch (train): [0][53000/74490]	Time 0.088 (0.128)	Data 0.000 (0.050)	Loss 11.2948 (13.6962)
Epoch (train): [0][54000/74490]	Time 0.083 (0.128)	Data 0.003 (0.050)	Loss 10.0118 (13.6615)
Epoch (train): [0][55000/74490]	Time 0.085 (0.128)	Data 0.000 (0.050)	Loss 15.7170 (13.6260)
Epoch (train): [0][56000/74490]	Time 0.079 (0.128)	Data 0.000 (0.050)	Loss 25.4339 (13.5956)
Epoch (train): [0][57000/74490]	Time 0.085 (0.128)	Data 0.000 (0.050)	Loss 16.3099 (13.5693)
Epoch (train): [0][58000/74490]	Time 0.081 (0.128)	Data 0.000 (0.050)	Loss 9.8447 (13.5398)
Epoch (train): [0][59000/74490]	Time 0.086 (0.128)	Data 0.000 (0.051)	Loss 6.8152 (13.5096)
Epoch (train): [0][60000/74490]	Time 0.087 (0.128)	Data 0.000 (0.051)	Loss 10.0001 (13.4804)
Epoch (train): [0][61000/74490]	Time 0.083 (0.128)	Data 0.000 (0.051)	Loss 12.6149 (13.4574)
Epoch (train): [0][62000/74490]	Time 0.085 (0.129)	Data 0.000 (0.051)	Loss 6.5452 (13.4292)
Epoch (train): [0][63000/74490]	Time 0.096 (0.129)	Data 0.000 (0.051)	Loss 9.9987 (13.4024)
Epoch (train): [0][64000/74490]	Time 0.080 (0.129)	Data 0.000 (0.051)	Loss 8.0524 (13.3769)
Epoch (train): [0][65000/74490]	Time 0.091 (0.129)	Data 0.000 (0.051)	Loss 5.2985 (13.3556)
Epoch (train): [0][66000/74490]	Time 0.081 (0.129)	Data 0.000 (0.051)	Loss 9.5915 (13.3350)
Epoch (train): [0][67000/74490]	Time 0.090 (0.129)	Data 0.000 (0.051)	Loss 30.1812 (13.3113)
Epoch (train): [0][68000/74490]	Time 0.088 (0.129)	Data 0.000 (0.051)	Loss 13.3134 (13.2879)
Epoch (train): [0][69000/74490]	Time 0.088 (0.129)	Data 0.004 (0.051)	Loss 10.8081 (13.2693)
Epoch (train): [0][70000/74490]	Time 0.080 (0.129)	Data 0.001 (0.051)	Loss 17.5205 (13.2474)
Epoch (train): [0][71000/74490]	Time 0.089 (0.129)	Data 0.000 (0.051)	Loss 6.4525 (13.2220)
Epoch (train): [0][72000/74490]	Time 0.087 (0.129)	Data 0.000 (0.051)	Loss 10.5482 (13.2011)
Epoch (train): [0][73000/74490]	Time 0.074 (0.129)	Data 0.000 (0.051)	Loss 7.6953 (13.1769)
Epoch (train): [0][74000/74490]	Time 0.083 (0.129)	Data 0.000 (0.051)	Loss 6.7546 (13.1555)
Epoch (train): [1][510/74490]	Time 0.153 (0.136)	Data 0.115 (0.062)	Loss 6.8178 (11.3408)
Epoch (train): [1][1510/74490]	Time 0.088 (0.134)	Data 0.000 (0.061)	Loss 7.3645 (11.3710)
Epoch (train): [1][2510/74490]	Time 0.091 (0.134)	Data 0.000 (0.059)	Loss 6.9416 (11.3758)
Epoch (train): [1][3510/74490]	Time 0.085 (0.133)	Data 0.016 (0.057)	Loss 10.3922 (11.3664)
Epoch (train): [1][4510/74490]	Time 0.080 (0.134)	Data 0.000 (0.057)	Loss 11.8671 (11.3738)
Epoch (train): [1][5510/74490]	Time 0.193 (0.134)	Data 0.153 (0.057)	Loss 10.4879 (11.3726)
Epoch (train): [1][6510/74490]	Time 0.465 (0.134)	Data 0.427 (0.057)	Loss 7.4263 (11.3392)
Epoch (train): [1][7510/74490]	Time 0.358 (0.134)	Data 0.319 (0.057)	Loss 10.4291 (11.3089)
Epoch (train): [1][8510/74490]	Time 0.087 (0.134)	Data 0.000 (0.057)	Loss 22.2782 (11.2648)
Epoch (train): [1][9510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 14.7364 (11.2473)
Epoch (train): [1][10510/74490]	Time 0.087 (0.134)	Data 0.000 (0.057)	Loss 8.0828 (11.2093)
Epoch (train): [1][11510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 7.9917 (11.1742)
Epoch (train): [1][12510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 11.6104 (11.1274)
Epoch (train): [1][13510/74490]	Time 0.089 (0.134)	Data 0.000 (0.057)	Loss 9.3070 (11.0977)
Epoch (train): [1][14510/74490]	Time 0.093 (0.134)	Data 0.001 (0.057)	Loss 6.4588 (11.0670)
Epoch (train): [1][15510/74490]	Time 0.975 (0.134)	Data 0.938 (0.057)	Loss 6.4880 (11.0487)
Epoch (train): [1][16510/74490]	Time 0.446 (0.134)	Data 0.412 (0.057)	Loss 7.0927 (11.0211)
Epoch (train): [1][17510/74490]	Time 0.090 (0.134)	Data 0.000 (0.057)	Loss 6.7033 (11.0025)
Epoch (train): [1][18510/74490]	Time 0.176 (0.134)	Data 0.135 (0.057)	Loss 15.7798 (10.9760)
Epoch (train): [1][19510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 8.9392 (10.9553)
Epoch (train): [1][20510/74490]	Time 0.091 (0.134)	Data 0.000 (0.057)	Loss 7.0225 (10.9354)
Epoch (train): [1][21510/74490]	Time 0.083 (0.134)	Data 0.000 (0.057)	Loss 7.9176 (10.9121)
Epoch (train): [1][22510/74490]	Time 0.083 (0.133)	Data 0.000 (0.057)	Loss 17.3537 (10.8823)
Epoch (train): [1][23510/74490]	Time 0.430 (0.133)	Data 0.388 (0.056)	Loss 5.0644 (10.8495)
Epoch (train): [1][24510/74490]	Time 0.082 (0.133)	Data 0.000 (0.056)	Loss 6.9442 (10.8238)
Epoch (train): [1][25510/74490]	Time 0.453 (0.133)	Data 0.415 (0.056)	Loss 8.6824 (10.8097)
Epoch (train): [1][26510/74490]	Time 0.078 (0.133)	Data 0.000 (0.056)	Loss 7.9667 (10.7926)
Epoch (train): [1][27510/74490]	Time 0.080 (0.133)	Data 0.000 (0.056)	Loss 15.3064 (10.7743)
Epoch (train): [1][28510/74490]	Time 0.062 (0.133)	Data 0.000 (0.056)	Loss 12.9763 (10.7440)
Epoch (train): [1][29510/74490]	Time 0.080 (0.133)	Data 0.000 (0.056)	Loss 16.0642 (10.7167)
Epoch (train): [1][30510/74490]	Time 0.087 (0.134)	Data 0.000 (0.057)	Loss 11.5243 (10.6999)
Epoch (train): [1][31510/74490]	Time 0.086 (0.134)	Data 0.000 (0.057)	Loss 7.4952 (10.6800)
Epoch (train): [1][32510/74490]	Time 0.068 (0.134)	Data 0.000 (0.057)	Loss 7.7612 (10.6542)
Epoch (train): [1][33510/74490]	Time 0.090 (0.134)	Data 0.000 (0.056)	Loss 15.2555 (10.6355)
Epoch (train): [1][34510/74490]	Time 0.083 (0.134)	Data 0.000 (0.056)	Loss 11.7699 (10.6092)
Epoch (train): [1][35510/74490]	Time 0.503 (0.134)	Data 0.464 (0.057)	Loss 11.0966 (10.5877)
Epoch (train): [1][36510/74490]	Time 0.082 (0.134)	Data 0.000 (0.057)	Loss 2.9445 (10.5639)
Epoch (train): [1][37510/74490]	Time 0.090 (0.134)	Data 0.000 (0.057)	Loss 15.6480 (10.5433)
Epoch (train): [1][38510/74490]	Time 0.093 (0.134)	Data 0.000 (0.057)	Loss 8.7091 (10.5205)
Epoch (train): [1][39510/74490]	Time 0.091 (0.134)	Data 0.000 (0.057)	Loss 9.9193 (10.5005)
Epoch (train): [1][40510/74490]	Time 0.096 (0.134)	Data 0.000 (0.057)	Loss 5.3574 (10.4784)
Epoch (train): [1][41510/74490]	Time 0.096 (0.134)	Data 0.001 (0.057)	Loss 10.7326 (10.4535)
Epoch (train): [1][42510/74490]	Time 0.083 (0.134)	Data 0.000 (0.057)	Loss 6.3389 (10.4308)
Epoch (train): [1][43510/74490]	Time 0.084 (0.134)	Data 0.000 (0.057)	Loss 11.6080 (10.4096)
Epoch (train): [1][44510/74490]	Time 0.398 (0.134)	Data 0.358 (0.057)	Loss 7.9409 (10.3801)
Epoch (train): [1][45510/74490]	Time 0.601 (0.134)	Data 0.561 (0.057)	Loss 10.3134 (10.3561)
Epoch (train): [1][46510/74490]	Time 0.088 (0.134)	Data 0.000 (0.057)	Loss 10.8804 (10.3300)
Epoch (train): [1][47510/74490]	Time 0.100 (0.134)	Data 0.000 (0.057)	Loss 3.4223 (10.3063)
Epoch (train): [1][48510/74490]	Time 0.083 (0.134)	Data 0.000 (0.057)	Loss 14.8553 (10.2825)
Epoch (train): [1][49510/74490]	Time 0.473 (0.134)	Data 0.434 (0.057)	Loss 6.4213 (10.2669)
Epoch (train): [1][50510/74490]	Time 0.083 (0.134)	Data 0.047 (0.057)	Loss 10.7460 (10.2476)
Epoch (train): [1][51510/74490]	Time 0.086 (0.134)	Data 0.002 (0.057)	Loss 16.5232 (10.2266)
Epoch (train): [1][52510/74490]	Time 0.080 (0.134)	Data 0.000 (0.057)	Loss 5.7677 (10.2032)
Epoch (train): [1][53510/74490]	Time 0.088 (0.134)	Data 0.000 (0.057)	Loss 5.3444 (10.1806)
Epoch (train): [1][54510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 4.8256 (10.1607)
Epoch (train): [1][55510/74490]	Time 0.354 (0.134)	Data 0.316 (0.057)	Loss 3.0684 (10.1369)
Epoch (train): [1][56510/74490]	Time 0.434 (0.134)	Data 0.398 (0.057)	Loss 16.5449 (10.1149)
Epoch (train): [1][57510/74490]	Time 0.081 (0.134)	Data 0.000 (0.057)	Loss 10.9093 (10.0917)
Epoch (train): [1][58510/74490]	Time 0.082 (0.134)	Data 0.000 (0.057)	Loss 11.7888 (10.0685)
Epoch (train): [1][59510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 15.0366 (10.0447)
Epoch (train): [1][60510/74490]	Time 0.080 (0.134)	Data 0.000 (0.057)	Loss 12.3119 (10.0204)
Epoch (train): [1][61510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 8.6902 (10.0015)
Epoch (train): [1][62510/74490]	Time 0.081 (0.134)	Data 0.046 (0.057)	Loss 9.5692 (9.9761)
Epoch (train): [1][63510/74490]	Time 0.442 (0.134)	Data 0.409 (0.057)	Loss 7.8585 (9.9573)
Epoch (train): [1][64510/74490]	Time 0.762 (0.134)	Data 0.717 (0.057)	Loss 8.8236 (9.9348)
Epoch (train): [1][65510/74490]	Time 0.085 (0.134)	Data 0.000 (0.057)	Loss 6.9724 (9.9140)
Epoch (train): [1][66510/74490]	Time 0.070 (0.135)	Data 0.000 (0.057)	Loss 3.5284 (9.8920)
Epoch (train): [1][67510/74490]	Time 0.189 (0.135)	Data 0.151 (0.057)	Loss 10.4315 (9.8701)
Epoch (train): [1][68510/74490]	Time 0.085 (0.135)	Data 0.000 (0.058)	Loss 10.9078 (9.8499)
Epoch (train): [1][69510/74490]	Time 0.089 (0.135)	Data 0.000 (0.058)	Loss 10.8112 (9.8291)
Epoch (train): [1][70510/74490]	Time 0.085 (0.135)	Data 0.001 (0.058)	Loss 3.4866 (9.8061)
Epoch (train): [1][71510/74490]	Time 0.086 (0.135)	Data 0.001 (0.057)	Loss 5.2696 (9.7842)
Epoch (train): [1][72510/74490]	Time 0.144 (0.135)	Data 0.102 (0.057)	Loss 5.2275 (9.7635)
Epoch (train): [1][73510/74490]	Time 0.093 (0.135)	Data 0.000 (0.057)	Loss 3.8314 (9.7427)
Epoch (train): [2][20/74490]	Time 0.086 (0.183)	Data 0.000 (0.110)	Loss 5.3445 (7.6000)
Epoch (train): [2][1020/74490]	Time 0.088 (0.123)	Data 0.001 (0.048)	Loss 9.6148 (8.4718)
Epoch (train): [2][2020/74490]	Time 0.134 (0.122)	Data 0.095 (0.047)	Loss 8.4224 (8.2229)
Epoch (train): [2][3020/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 8.3889 (8.1566)
Epoch (train): [2][4020/74490]	Time 0.087 (0.125)	Data 0.000 (0.050)	Loss 7.5816 (8.1479)
Epoch (train): [2][5020/74490]	Time 0.089 (0.125)	Data 0.000 (0.049)	Loss 2.5164 (8.0679)
Epoch (train): [2][6020/74490]	Time 0.086 (0.125)	Data 0.000 (0.048)	Loss 6.0430 (8.0270)
Epoch (train): [2][7020/74490]	Time 0.081 (0.125)	Data 0.000 (0.048)	Loss 18.0337 (8.0041)
Epoch (train): [2][8020/74490]	Time 0.086 (0.124)	Data 0.000 (0.048)	Loss 9.3425 (7.9928)
Epoch (train): [2][9020/74490]	Time 0.084 (0.124)	Data 0.000 (0.047)	Loss 5.0453 (7.9499)
Epoch (train): [2][10020/74490]	Time 0.087 (0.124)	Data 0.000 (0.048)	Loss 5.7769 (7.9245)
Epoch (train): [2][11020/74490]	Time 0.081 (0.124)	Data 0.000 (0.048)	Loss 8.4927 (7.9007)
Epoch (train): [2][12020/74490]	Time 0.087 (0.124)	Data 0.000 (0.048)	Loss 7.7962 (7.8668)
Epoch (train): [2][13020/74490]	Time 0.082 (0.124)	Data 0.001 (0.048)	Loss 7.3560 (7.8583)
Epoch (train): [2][14020/74490]	Time 0.071 (0.124)	Data 0.000 (0.048)	Loss 7.0146 (7.8357)
Epoch (train): [2][15020/74490]	Time 0.090 (0.127)	Data 0.000 (0.051)	Loss 10.3050 (7.8410)
Epoch (train): [2][16020/74490]	Time 0.081 (0.132)	Data 0.002 (0.056)	Loss 9.6316 (7.8306)
Epoch (train): [2][17020/74490]	Time 0.419 (0.136)	Data 0.382 (0.060)	Loss 6.7792 (7.8071)
Epoch (train): [2][18020/74490]	Time 0.083 (0.135)	Data 0.000 (0.060)	Loss 14.7467 (7.7872)
Epoch (train): [2][19020/74490]	Time 0.083 (0.135)	Data 0.000 (0.059)	Loss 6.3844 (7.7677)
Epoch (train): [2][20020/74490]	Time 0.085 (0.134)	Data 0.002 (0.059)	Loss 7.2179 (7.7461)
Epoch (train): [2][21020/74490]	Time 0.085 (0.134)	Data 0.000 (0.058)	Loss 5.4201 (7.7383)
Epoch (train): [2][22020/74490]	Time 0.089 (0.134)	Data 0.000 (0.058)	Loss 7.2127 (7.7167)
Epoch (train): [2][23020/74490]	Time 0.081 (0.133)	Data 0.000 (0.057)	Loss 6.6621 (7.7053)
Epoch (train): [2][24020/74490]	Time 0.091 (0.133)	Data 0.000 (0.057)	Loss 6.1351 (7.6791)
Epoch (train): [2][25020/74490]	Time 0.087 (0.133)	Data 0.000 (0.057)	Loss 3.8080 (7.6630)
Epoch (train): [2][26020/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 5.4890 (7.6446)
Epoch (train): [2][27020/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 6.9364 (7.6262)
Epoch (train): [2][28020/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 7.0464 (7.6138)
Epoch (train): [2][29020/74490]	Time 0.095 (0.132)	Data 0.000 (0.056)	Loss 5.0963 (7.5984)
Epoch (train): [2][30020/74490]	Time 0.094 (0.131)	Data 0.000 (0.056)	Loss 9.0306 (7.5801)
Epoch (train): [2][31020/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 8.8352 (7.5631)
Epoch (train): [2][32020/74490]	Time 0.091 (0.131)	Data 0.000 (0.055)	Loss 5.3754 (7.5475)
Epoch (train): [2][33020/74490]	Time 0.092 (0.131)	Data 0.000 (0.055)	Loss 7.7227 (7.5315)
Epoch (train): [2][34020/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 6.9746 (7.5113)
Epoch (train): [2][35020/74490]	Time 0.081 (0.130)	Data 0.000 (0.055)	Loss 8.6030 (7.4918)
Epoch (train): [2][36020/74490]	Time 0.085 (0.130)	Data 0.000 (0.055)	Loss 5.3164 (7.4722)
Epoch (train): [2][37020/74490]	Time 0.080 (0.130)	Data 0.000 (0.055)	Loss 5.8172 (7.4556)
Epoch (train): [2][38020/74490]	Time 0.080 (0.130)	Data 0.000 (0.054)	Loss 7.7395 (7.4461)
Epoch (train): [2][39020/74490]	Time 0.087 (0.130)	Data 0.000 (0.054)	Loss 6.2895 (7.4304)
Epoch (train): [2][40020/74490]	Time 0.086 (0.130)	Data 0.001 (0.054)	Loss 3.9941 (7.4181)
Epoch (train): [2][41020/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 7.2777 (7.4031)
Epoch (train): [2][42020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.6666 (7.3917)
Epoch (train): [2][43020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 8.6003 (7.3724)
Epoch (train): [2][44020/74490]	Time 0.090 (0.130)	Data 0.001 (0.054)	Loss 10.3311 (7.3612)
Epoch (train): [2][45020/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 4.7739 (7.3441)
Epoch (train): [2][46020/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 13.6195 (7.3290)
Epoch (train): [2][47020/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 10.5647 (7.3148)
Epoch (train): [2][48020/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 5.7526 (7.2994)
Epoch (train): [2][49020/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 10.8026 (7.2862)
Epoch (train): [2][50020/74490]	Time 0.082 (0.129)	Data 0.000 (0.054)	Loss 5.1514 (7.2725)
Epoch (train): [2][51020/74490]	Time 0.088 (0.129)	Data 0.000 (0.054)	Loss 4.8362 (7.2582)
Epoch (train): [2][52020/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 4.8728 (7.2444)
Epoch (train): [2][53020/74490]	Time 0.076 (0.130)	Data 0.000 (0.054)	Loss 9.3993 (7.2301)
Epoch (train): [2][54020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 7.0362 (7.2160)
Epoch (train): [2][55020/74490]	Time 0.086 (0.130)	Data 0.003 (0.054)	Loss 4.5707 (7.2005)
Epoch (train): [2][56020/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 7.6540 (7.1869)
Epoch (train): [2][57020/74490]	Time 0.092 (0.130)	Data 0.000 (0.054)	Loss 4.3395 (7.1737)
Epoch (train): [2][58020/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 5.5191 (7.1604)
Epoch (train): [2][59020/74490]	Time 0.079 (0.130)	Data 0.003 (0.054)	Loss 7.2292 (7.1443)
Epoch (train): [2][60020/74490]	Time 0.091 (0.130)	Data 0.000 (0.054)	Loss 6.5371 (7.1320)
Epoch (train): [2][61020/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 6.3485 (7.1189)
Epoch (train): [2][62020/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 6.0489 (7.1031)
Epoch (train): [2][63020/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 2.8998 (7.0879)
Epoch (train): [2][64020/74490]	Time 0.085 (0.129)	Data 0.001 (0.054)	Loss 5.3657 (7.0722)
Epoch (train): [2][65020/74490]	Time 0.084 (0.129)	Data 0.001 (0.054)	Loss 5.4687 (7.0590)
Epoch (train): [2][66020/74490]	Time 0.083 (0.129)	Data 0.001 (0.054)	Loss 5.3691 (7.0456)
Epoch (train): [2][67020/74490]	Time 0.093 (0.129)	Data 0.000 (0.054)	Loss 6.8724 (7.0283)
Epoch (train): [2][68020/74490]	Time 0.078 (0.129)	Data 0.001 (0.054)	Loss 2.9507 (7.0141)
Epoch (train): [2][69020/74490]	Time 0.089 (0.129)	Data 0.001 (0.053)	Loss 7.1489 (7.0025)
Epoch (train): [2][70020/74490]	Time 0.089 (0.129)	Data 0.000 (0.053)	Loss 5.1067 (6.9888)
Epoch (train): [2][71020/74490]	Time 0.082 (0.129)	Data 0.000 (0.053)	Loss 6.4565 (6.9748)
Epoch (train): [2][72020/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 4.2964 (6.9617)
Epoch (train): [2][73020/74490]	Time 0.083 (0.129)	Data 0.000 (0.053)	Loss 5.2122 (6.9481)
Epoch (train): [2][74020/74490]	Time 0.084 (0.129)	Data 0.000 (0.053)	Loss 4.0279 (6.9347)
Epoch (train): [3][530/74490]	Time 0.262 (0.131)	Data 0.229 (0.054)	Loss 10.6803 (6.0595)
Epoch (train): [3][1530/74490]	Time 0.077 (0.129)	Data 0.000 (0.054)	Loss 2.4045 (5.9451)
Epoch (train): [3][2530/74490]	Time 0.088 (0.129)	Data 0.000 (0.052)	Loss 5.6482 (5.9078)
Epoch (train): [3][3530/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 6.5583 (5.8882)
Epoch (train): [3][4530/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 4.2878 (5.8732)
Epoch (train): [3][5530/74490]	Time 0.081 (0.127)	Data 0.001 (0.052)	Loss 5.1867 (5.8529)
Epoch (train): [3][6530/74490]	Time 0.079 (0.127)	Data 0.000 (0.052)	Loss 6.7792 (5.8409)
Epoch (train): [3][7530/74490]	Time 0.411 (0.128)	Data 0.376 (0.052)	Loss 10.8289 (5.8413)
Epoch (train): [3][8530/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 4.7497 (5.8387)
Epoch (train): [3][9530/74490]	Time 0.080 (0.127)	Data 0.000 (0.052)	Loss 4.3123 (5.8086)
Epoch (train): [3][10530/74490]	Time 0.373 (0.127)	Data 0.336 (0.052)	Loss 5.6018 (5.8008)
Epoch (train): [3][11530/74490]	Time 0.082 (0.127)	Data 0.000 (0.052)	Loss 6.4028 (5.7925)
Epoch (train): [3][12530/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 3.9468 (5.7785)
Epoch (train): [3][13530/74490]	Time 0.096 (0.127)	Data 0.000 (0.052)	Loss 4.4660 (5.7793)
Epoch (train): [3][14530/74490]	Time 0.080 (0.127)	Data 0.001 (0.052)	Loss 4.1564 (5.7713)
Epoch (train): [3][15530/74490]	Time 0.083 (0.127)	Data 0.000 (0.052)	Loss 3.6263 (5.7607)
Epoch (train): [3][16530/74490]	Time 0.088 (0.127)	Data 0.000 (0.052)	Loss 1.6759 (5.7580)
Epoch (train): [3][17530/74490]	Time 0.080 (0.127)	Data 0.000 (0.052)	Loss 4.9537 (5.7482)
Epoch (train): [3][18530/74490]	Time 0.085 (0.127)	Data 0.000 (0.052)	Loss 4.6749 (5.7435)
Epoch (train): [3][19530/74490]	Time 0.084 (0.127)	Data 0.000 (0.051)	Loss 5.2989 (5.7313)
Epoch (train): [3][20530/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 4.5728 (5.7203)
Epoch (train): [3][21530/74490]	Time 0.077 (0.127)	Data 0.000 (0.051)	Loss 4.3270 (5.7144)
Epoch (train): [3][22530/74490]	Time 0.080 (0.127)	Data 0.000 (0.051)	Loss 6.3692 (5.7002)
Epoch (train): [3][23530/74490]	Time 0.084 (0.127)	Data 0.000 (0.051)	Loss 9.2563 (5.6894)
Epoch (train): [3][24530/74490]	Time 0.083 (0.127)	Data 0.000 (0.051)	Loss 8.9189 (5.6821)
Epoch (train): [3][25530/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 9.8825 (5.6829)
Epoch (train): [3][26530/74490]	Time 0.083 (0.127)	Data 0.000 (0.051)	Loss 4.1039 (5.6748)
Epoch (train): [3][27530/74490]	Time 0.092 (0.127)	Data 0.000 (0.051)	Loss 3.8730 (5.6673)
Epoch (train): [3][28530/74490]	Time 0.087 (0.127)	Data 0.000 (0.051)	Loss 5.3121 (5.6550)
Epoch (train): [3][29530/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 2.5788 (5.6510)
Epoch (train): [3][30530/74490]	Time 0.296 (0.128)	Data 0.258 (0.052)	Loss 21.9254 (5.6419)
Epoch (train): [3][31530/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 5.5495 (5.6373)
Epoch (train): [3][32530/74490]	Time 0.082 (0.128)	Data 0.000 (0.052)	Loss 6.1364 (5.6325)
Epoch (train): [3][33530/74490]	Time 0.080 (0.128)	Data 0.000 (0.052)	Loss 3.1818 (5.6253)
Epoch (train): [3][34530/74490]	Time 0.084 (0.128)	Data 0.001 (0.052)	Loss 7.5241 (5.6160)
Epoch (train): [3][35530/74490]	Time 0.088 (0.128)	Data 0.003 (0.052)	Loss 5.0286 (5.6068)
Epoch (train): [3][36530/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 7.8327 (5.5984)
Epoch (train): [3][37530/74490]	Time 0.091 (0.128)	Data 0.000 (0.052)	Loss 4.8105 (5.5926)
Epoch (train): [3][38530/74490]	Time 0.085 (0.128)	Data 0.000 (0.052)	Loss 5.1816 (5.5861)
Epoch (train): [3][39530/74490]	Time 0.081 (0.128)	Data 0.000 (0.052)	Loss 3.5773 (5.5783)
Epoch (train): [3][40530/74490]	Time 0.087 (0.128)	Data 0.000 (0.052)	Loss 10.9744 (5.5765)
Epoch (train): [3][41530/74490]	Time 0.089 (0.128)	Data 0.000 (0.052)	Loss 4.2884 (5.5668)
Epoch (train): [3][42530/74490]	Time 0.085 (0.128)	Data 0.003 (0.052)	Loss 7.5212 (5.5613)
Epoch (train): [3][43530/74490]	Time 0.083 (0.128)	Data 0.000 (0.052)	Loss 5.9105 (5.5551)
Epoch (train): [3][44530/74490]	Time 0.072 (0.128)	Data 0.000 (0.053)	Loss 3.1007 (5.5462)
Epoch (train): [3][45530/74490]	Time 0.073 (0.128)	Data 0.000 (0.053)	Loss 5.8406 (5.5392)
Epoch (train): [3][46530/74490]	Time 0.089 (0.128)	Data 0.000 (0.053)	Loss 4.2940 (5.5324)
Epoch (train): [3][47530/74490]	Time 0.094 (0.128)	Data 0.000 (0.053)	Loss 2.2916 (5.5260)
Epoch (train): [3][48530/74490]	Time 0.611 (0.129)	Data 0.571 (0.053)	Loss 3.9921 (5.5192)
Epoch (train): [3][49530/74490]	Time 0.099 (0.129)	Data 0.000 (0.053)	Loss 3.7400 (5.5101)
Epoch (train): [3][50530/74490]	Time 0.082 (0.129)	Data 0.000 (0.053)	Loss 6.9451 (5.5020)
Epoch (train): [3][51530/74490]	Time 0.086 (0.129)	Data 0.000 (0.053)	Loss 6.4033 (5.4930)
Epoch (train): [3][52530/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 6.6400 (5.4875)
Epoch (train): [3][53530/74490]	Time 0.086 (0.129)	Data 0.000 (0.053)	Loss 3.0107 (5.4784)
Epoch (train): [3][54530/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 4.6729 (5.4728)
Epoch (train): [3][55530/74490]	Time 0.080 (0.129)	Data 0.000 (0.054)	Loss 3.0001 (5.4664)
Epoch (train): [3][56530/74490]	Time 0.078 (0.129)	Data 0.005 (0.054)	Loss 4.5674 (5.4630)
Epoch (train): [3][57530/74490]	Time 0.084 (0.129)	Data 0.001 (0.054)	Loss 3.8454 (5.4570)
Epoch (train): [3][58530/74490]	Time 0.477 (0.129)	Data 0.432 (0.054)	Loss 2.8659 (5.4508)
Epoch (train): [3][59530/74490]	Time 0.441 (0.129)	Data 0.401 (0.054)	Loss 5.1039 (5.4438)
Epoch (train): [3][60530/74490]	Time 0.086 (0.129)	Data 0.000 (0.054)	Loss 4.9260 (5.4359)
Epoch (train): [3][61530/74490]	Time 0.083 (0.129)	Data 0.000 (0.054)	Loss 9.0972 (5.4286)
Epoch (train): [3][62530/74490]	Time 0.089 (0.129)	Data 0.000 (0.054)	Loss 16.1793 (5.4207)
Epoch (train): [3][63530/74490]	Time 0.076 (0.129)	Data 0.002 (0.054)	Loss 7.9359 (5.4146)
Epoch (train): [3][64530/74490]	Time 0.093 (0.129)	Data 0.000 (0.054)	Loss 2.4817 (5.4094)
Epoch (train): [3][65530/74490]	Time 0.087 (0.129)	Data 0.000 (0.054)	Loss 10.1185 (5.4030)
Epoch (train): [3][66530/74490]	Time 0.086 (0.129)	Data 0.000 (0.054)	Loss 2.8668 (5.3975)
Epoch (train): [3][67530/74490]	Time 0.089 (0.129)	Data 0.001 (0.054)	Loss 5.5158 (5.3905)
Epoch (train): [3][68530/74490]	Time 0.086 (0.130)	Data 0.002 (0.055)	Loss 2.2657 (5.3835)
Epoch (train): [3][69530/74490]	Time 0.117 (0.130)	Data 0.080 (0.055)	Loss 16.3956 (5.3781)
Epoch (train): [3][70530/74490]	Time 0.395 (0.130)	Data 0.355 (0.055)	Loss 3.9275 (5.3735)
Epoch (train): [3][71530/74490]	Time 0.081 (0.130)	Data 0.000 (0.055)	Loss 11.6013 (5.3655)
Epoch (train): [3][72530/74490]	Time 0.085 (0.130)	Data 0.000 (0.055)	Loss 6.1567 (5.3577)
Epoch (train): [3][73530/74490]	Time 0.086 (0.130)	Data 0.000 (0.055)	Loss 7.0533 (5.3528)
Epoch (train): [4][40/74490]	Time 0.084 (0.337)	Data 0.000 (0.261)	Loss 3.9442 (5.2248)
Epoch (train): [4][1040/74490]	Time 0.082 (0.161)	Data 0.000 (0.084)	Loss 3.4626 (4.7274)
Epoch (train): [4][2040/74490]	Time 0.190 (0.150)	Data 0.151 (0.073)	Loss 4.4079 (4.7243)
Epoch (train): [4][3040/74490]	Time 0.419 (0.146)	Data 0.379 (0.070)	Loss 4.0696 (4.8051)
Epoch (train): [4][4040/74490]	Time 0.089 (0.145)	Data 0.002 (0.069)	Loss 2.4441 (4.7745)
Epoch (train): [4][5040/74490]	Time 0.160 (0.145)	Data 0.121 (0.069)	Loss 3.3441 (4.7731)
Epoch (train): [4][6040/74490]	Time 0.082 (0.144)	Data 0.000 (0.068)	Loss 3.0880 (4.7732)
Epoch (train): [4][7040/74490]	Time 0.082 (0.144)	Data 0.000 (0.068)	Loss 4.4355 (4.7876)
Epoch (train): [4][8040/74490]	Time 0.086 (0.144)	Data 0.000 (0.067)	Loss 6.9857 (4.7835)
Epoch (train): [4][9040/74490]	Time 0.073 (0.142)	Data 0.000 (0.066)	Loss 2.1385 (4.7802)
Epoch (train): [4][10040/74490]	Time 0.081 (0.141)	Data 0.000 (0.065)	Loss 2.4997 (4.7747)
Epoch (train): [4][11040/74490]	Time 0.492 (0.141)	Data 0.456 (0.064)	Loss 4.3750 (4.7671)
Epoch (train): [4][12040/74490]	Time 0.437 (0.140)	Data 0.395 (0.063)	Loss 2.6518 (4.7583)
Epoch (train): [4][13040/74490]	Time 0.086 (0.139)	Data 0.000 (0.062)	Loss 3.8721 (4.7512)
Epoch (train): [4][14040/74490]	Time 0.417 (0.138)	Data 0.377 (0.062)	Loss 5.6578 (4.7541)
Epoch (train): [4][15040/74490]	Time 0.084 (0.138)	Data 0.000 (0.061)	Loss 6.0479 (4.7425)
Epoch (train): [4][16040/74490]	Time 0.086 (0.137)	Data 0.000 (0.061)	Loss 2.6163 (4.7389)
Epoch (train): [4][17040/74490]	Time 0.084 (0.137)	Data 0.000 (0.061)	Loss 2.7835 (4.7341)
Epoch (train): [4][18040/74490]	Time 0.072 (0.137)	Data 0.000 (0.061)	Loss 2.5234 (4.7293)
Epoch (train): [4][19040/74490]	Time 0.085 (0.137)	Data 0.000 (0.060)	Loss 8.5383 (4.7202)
Epoch (train): [4][20040/74490]	Time 0.086 (0.136)	Data 0.000 (0.060)	Loss 7.2288 (4.7164)
Epoch (train): [4][21040/74490]	Time 0.077 (0.136)	Data 0.001 (0.060)	Loss 4.3447 (4.7048)
Epoch (train): [4][22040/74490]	Time 0.083 (0.136)	Data 0.000 (0.060)	Loss 4.9557 (4.7028)
Epoch (train): [4][23040/74490]	Time 0.084 (0.136)	Data 0.000 (0.060)	Loss 3.7015 (4.6974)
Epoch (train): [4][24040/74490]	Time 0.082 (0.136)	Data 0.000 (0.060)	Loss 4.7825 (4.6951)
Epoch (train): [4][25040/74490]	Time 0.515 (0.137)	Data 0.475 (0.060)	Loss 3.8225 (4.6932)
Epoch (train): [4][26040/74490]	Time 0.083 (0.137)	Data 0.000 (0.060)	Loss 5.1046 (4.6900)
Epoch (train): [4][27040/74490]	Time 0.083 (0.136)	Data 0.000 (0.060)	Loss 1.7065 (4.6856)
Epoch (train): [4][28040/74490]	Time 0.095 (0.136)	Data 0.000 (0.060)	Loss 3.1667 (4.6851)
Epoch (train): [4][29040/74490]	Time 0.089 (0.136)	Data 0.000 (0.060)	Loss 10.6164 (4.6791)
Epoch (train): [4][30040/74490]	Time 0.082 (0.136)	Data 0.000 (0.060)	Loss 3.7458 (4.6747)
Epoch (train): [4][31040/74490]	Time 0.098 (0.136)	Data 0.000 (0.060)	Loss 7.8777 (4.6687)
Epoch (train): [4][32040/74490]	Time 0.314 (0.136)	Data 0.274 (0.060)	Loss 2.8893 (4.6627)
Epoch (train): [4][33040/74490]	Time 0.081 (0.136)	Data 0.000 (0.060)	Loss 2.8689 (4.6588)
Epoch (train): [4][34040/74490]	Time 0.067 (0.136)	Data 0.029 (0.060)	Loss 3.4605 (4.6602)
Epoch (train): [4][35040/74490]	Time 0.081 (0.135)	Data 0.000 (0.059)	Loss 4.0967 (4.6581)
Epoch (train): [4][36040/74490]	Time 0.140 (0.135)	Data 0.101 (0.059)	Loss 1.6143 (4.6563)
Epoch (train): [4][37040/74490]	Time 0.302 (0.135)	Data 0.265 (0.059)	Loss 2.2338 (4.6540)
Epoch (train): [4][38040/74490]	Time 0.391 (0.135)	Data 0.354 (0.059)	Loss 4.9841 (4.6514)
Epoch (train): [4][39040/74490]	Time 0.463 (0.135)	Data 0.420 (0.059)	Loss 5.4427 (4.6463)
Epoch (train): [4][40040/74490]	Time 0.455 (0.135)	Data 0.419 (0.059)	Loss 5.4375 (4.6406)
Epoch (train): [4][41040/74490]	Time 0.081 (0.135)	Data 0.000 (0.058)	Loss 4.6196 (4.6343)
Epoch (train): [4][42040/74490]	Time 0.078 (0.134)	Data 0.000 (0.058)	Loss 5.4622 (4.6297)
Epoch (train): [4][43040/74490]	Time 0.083 (0.134)	Data 0.002 (0.058)	Loss 2.9102 (4.6272)
Epoch (train): [4][44040/74490]	Time 0.139 (0.135)	Data 0.102 (0.058)	Loss 2.7316 (4.6201)
Epoch (train): [4][45040/74490]	Time 0.083 (0.135)	Data 0.000 (0.059)	Loss 3.4291 (4.6178)
Epoch (train): [4][46040/74490]	Time 0.086 (0.135)	Data 0.000 (0.059)	Loss 4.8988 (4.6150)
Epoch (train): [4][47040/74490]	Time 0.090 (0.135)	Data 0.000 (0.059)	Loss 4.1332 (4.6086)
Epoch (train): [4][48040/74490]	Time 0.070 (0.135)	Data 0.000 (0.059)	Loss 3.6410 (4.6035)
Epoch (train): [4][49040/74490]	Time 0.483 (0.135)	Data 0.438 (0.059)	Loss 2.8847 (4.5997)
Epoch (train): [4][50040/74490]	Time 0.089 (0.135)	Data 0.000 (0.059)	Loss 11.1514 (4.5943)
Epoch (train): [4][51040/74490]	Time 0.084 (0.135)	Data 0.000 (0.059)	Loss 4.5701 (4.5900)
Epoch (train): [4][52040/74490]	Time 0.083 (0.135)	Data 0.000 (0.058)	Loss 5.6300 (4.5885)
Epoch (train): [4][53040/74490]	Time 0.088 (0.135)	Data 0.015 (0.058)	Loss 5.8915 (4.5838)
Epoch (train): [4][54040/74490]	Time 0.195 (0.134)	Data 0.156 (0.058)	Loss 2.6421 (4.5787)
Epoch (train): [4][55040/74490]	Time 0.398 (0.134)	Data 0.362 (0.058)	Loss 4.9313 (4.5760)
Epoch (train): [4][56040/74490]	Time 0.208 (0.134)	Data 0.170 (0.058)	Loss 6.9727 (4.5716)
Epoch (train): [4][57040/74490]	Time 0.081 (0.134)	Data 0.000 (0.058)	Loss 3.7720 (4.5667)
Epoch (train): [4][58040/74490]	Time 0.088 (0.134)	Data 0.000 (0.058)	Loss 3.6365 (4.5638)
Epoch (train): [4][59040/74490]	Time 0.080 (0.134)	Data 0.000 (0.058)	Loss 6.8736 (4.5605)
Epoch (train): [4][60040/74490]	Time 0.084 (0.134)	Data 0.000 (0.058)	Loss 3.8285 (4.5564)
Epoch (train): [4][61040/74490]	Time 0.085 (0.134)	Data 0.000 (0.058)	Loss 2.0571 (4.5522)
Epoch (train): [4][62040/74490]	Time 0.085 (0.134)	Data 0.000 (0.058)	Loss 5.6763 (4.5493)
Epoch (train): [4][63040/74490]	Time 0.084 (0.134)	Data 0.000 (0.058)	Loss 3.8694 (4.5456)
Epoch (train): [4][64040/74490]	Time 0.528 (0.135)	Data 0.484 (0.058)	Loss 3.8198 (4.5440)
Epoch (train): [4][65040/74490]	Time 0.078 (0.135)	Data 0.000 (0.058)	Loss 7.1671 (4.5398)
Epoch (train): [4][66040/74490]	Time 0.087 (0.134)	Data 0.000 (0.058)	Loss 3.9306 (4.5371)
Epoch (train): [4][67040/74490]	Time 0.084 (0.134)	Data 0.000 (0.058)	Loss 4.4927 (4.5356)
Epoch (train): [4][68040/74490]	Time 0.081 (0.134)	Data 0.000 (0.058)	Loss 3.6397 (4.5308)
Epoch (train): [4][69040/74490]	Time 0.085 (0.134)	Data 0.023 (0.058)	Loss 2.7149 (4.5287)
Epoch (train): [4][70040/74490]	Time 0.455 (0.134)	Data 0.419 (0.058)	Loss 4.9890 (4.5271)
Epoch (train): [4][71040/74490]	Time 0.395 (0.134)	Data 0.361 (0.058)	Loss 9.1806 (4.5226)
Epoch (train): [4][72040/74490]	Time 0.078 (0.134)	Data 0.000 (0.058)	Loss 3.3205 (4.5192)
Epoch (train): [4][73040/74490]	Time 0.427 (0.134)	Data 0.386 (0.058)	Loss 2.5674 (4.5156)
Epoch (train): [4][74040/74490]	Time 0.360 (0.134)	Data 0.325 (0.058)	Loss 13.3356 (4.5105)
Epoch (train): [5][550/74490]	Time 0.084 (0.132)	Data 0.000 (0.055)	Loss 3.7693 (4.2173)
Epoch (train): [5][1550/74490]	Time 0.070 (0.130)	Data 0.000 (0.055)	Loss 7.0277 (4.1724)
Epoch (train): [5][2550/74490]	Time 0.083 (0.130)	Data 0.000 (0.054)	Loss 8.8805 (4.1729)
Epoch (train): [5][3550/74490]	Time 0.081 (0.130)	Data 0.001 (0.054)	Loss 4.1020 (4.1825)
Epoch (train): [5][4550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 5.5451 (4.1677)
Epoch (train): [5][5550/74490]	Time 0.081 (0.129)	Data 0.000 (0.053)	Loss 1.6292 (4.1337)
Epoch (train): [5][6550/74490]	Time 0.083 (0.130)	Data 0.000 (0.054)	Loss 2.5180 (4.1324)
Epoch (train): [5][7550/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 4.2054 (4.1402)
Epoch (train): [5][8550/74490]	Time 0.087 (0.130)	Data 0.003 (0.054)	Loss 2.2969 (4.1253)
Epoch (train): [5][9550/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 4.9299 (4.1254)
Epoch (train): [5][10550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 1.8682 (4.1232)
Epoch (train): [5][11550/74490]	Time 0.529 (0.131)	Data 0.494 (0.055)	Loss 3.4974 (4.1247)
Epoch (train): [5][12550/74490]	Time 0.081 (0.131)	Data 0.000 (0.055)	Loss 1.7900 (4.1156)
Epoch (train): [5][13550/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 9.2897 (4.1056)
Epoch (train): [5][14550/74490]	Time 0.078 (0.131)	Data 0.000 (0.055)	Loss 2.0813 (4.0953)
Epoch (train): [5][15550/74490]	Time 0.078 (0.131)	Data 0.000 (0.055)	Loss 4.2877 (4.0926)
Epoch (train): [5][16550/74490]	Time 0.070 (0.131)	Data 0.000 (0.055)	Loss 4.4379 (4.0950)
Epoch (train): [5][17550/74490]	Time 0.072 (0.132)	Data 0.000 (0.056)	Loss 3.7553 (4.0901)
Epoch (train): [5][18550/74490]	Time 0.160 (0.132)	Data 0.127 (0.056)	Loss 4.8030 (4.0852)
Epoch (train): [5][19550/74490]	Time 0.080 (0.132)	Data 0.000 (0.057)	Loss 3.5723 (4.0861)
Epoch (train): [5][20550/74490]	Time 0.084 (0.132)	Data 0.000 (0.056)	Loss 8.1885 (4.0888)
Epoch (train): [5][21550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 3.7550 (4.0847)
Epoch (train): [5][22550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.4708 (4.0789)
Epoch (train): [5][23550/74490]	Time 0.090 (0.132)	Data 0.000 (0.056)	Loss 7.4564 (4.0812)
Epoch (train): [5][24550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.9842 (4.0789)
Epoch (train): [5][25550/74490]	Time 0.080 (0.132)	Data 0.000 (0.056)	Loss 2.4458 (4.0796)
Epoch (train): [5][26550/74490]	Time 0.082 (0.132)	Data 0.000 (0.056)	Loss 3.7404 (4.0766)
Epoch (train): [5][27550/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 3.0340 (4.0758)
Epoch (train): [5][28550/74490]	Time 0.086 (0.132)	Data 0.000 (0.056)	Loss 1.2398 (4.0744)
Epoch (train): [5][29550/74490]	Time 0.084 (0.132)	Data 0.000 (0.056)	Loss 6.9661 (4.0732)
Epoch (train): [5][30550/74490]	Time 0.081 (0.132)	Data 0.000 (0.056)	Loss 2.4985 (4.0737)
Epoch (train): [5][31550/74490]	Time 0.085 (0.132)	Data 0.000 (0.056)	Loss 4.4467 (4.0707)
Epoch (train): [5][32550/74490]	Time 0.086 (0.132)	Data 0.000 (0.056)	Loss 2.1401 (4.0685)
Epoch (train): [5][33550/74490]	Time 0.094 (0.132)	Data 0.000 (0.056)	Loss 3.6160 (4.0667)
Epoch (train): [5][34550/74490]	Time 0.084 (0.132)	Data 0.000 (0.056)	Loss 2.1293 (4.0656)
Epoch (train): [5][35550/74490]	Time 0.087 (0.131)	Data 0.000 (0.055)	Loss 2.5546 (4.0644)
Epoch (train): [5][36550/74490]	Time 0.084 (0.131)	Data 0.000 (0.055)	Loss 5.9266 (4.0629)
Epoch (train): [5][37550/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 3.3369 (4.0599)
Epoch (train): [5][38550/74490]	Time 0.080 (0.131)	Data 0.000 (0.055)	Loss 10.5456 (4.0561)
Epoch (train): [5][39550/74490]	Time 0.083 (0.131)	Data 0.000 (0.055)	Loss 5.7791 (4.0533)
Epoch (train): [5][40550/74490]	Time 0.090 (0.131)	Data 0.000 (0.055)	Loss 6.0771 (4.0495)
Epoch (train): [5][41550/74490]	Time 0.089 (0.131)	Data 0.000 (0.055)	Loss 3.8653 (4.0489)
Epoch (train): [5][42550/74490]	Time 0.082 (0.131)	Data 0.000 (0.054)	Loss 4.7074 (4.0466)
Epoch (train): [5][43550/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.4432 (4.0465)
Epoch (train): [5][44550/74490]	Time 0.081 (0.130)	Data 0.000 (0.054)	Loss 1.9130 (4.0438)
Epoch (train): [5][45550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 9.6105 (4.0396)
Epoch (train): [5][46550/74490]	Time 0.096 (0.130)	Data 0.000 (0.054)	Loss 2.9097 (4.0409)
Epoch (train): [5][47550/74490]	Time 0.077 (0.130)	Data 0.028 (0.054)	Loss 3.8083 (4.0363)
Epoch (train): [5][48550/74490]	Time 0.086 (0.130)	Data 0.002 (0.054)	Loss 4.7143 (4.0358)
Epoch (train): [5][49550/74490]	Time 0.122 (0.130)	Data 0.088 (0.054)	Loss 2.5541 (4.0321)
Epoch (train): [5][50550/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 5.9153 (4.0296)
Epoch (train): [5][51550/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 1.2818 (4.0292)
Epoch (train): [5][52550/74490]	Time 0.158 (0.130)	Data 0.120 (0.054)	Loss 3.8815 (4.0275)
Epoch (train): [5][53550/74490]	Time 0.084 (0.130)	Data 0.000 (0.054)	Loss 2.7629 (4.0263)
Epoch (train): [5][54550/74490]	Time 0.099 (0.130)	Data 0.000 (0.054)	Loss 5.8861 (4.0240)
Epoch (train): [5][55550/74490]	Time 0.075 (0.130)	Data 0.000 (0.054)	Loss 3.8427 (4.0197)
Epoch (train): [5][56550/74490]	Time 0.086 (0.130)	Data 0.000 (0.054)	Loss 6.2459 (4.0179)
Epoch (train): [5][57550/74490]	Time 0.092 (0.130)	Data 0.000 (0.054)	Loss 1.4713 (4.0152)
Epoch (train): [5][58550/74490]	Time 0.181 (0.130)	Data 0.141 (0.054)	Loss 2.8685 (4.0123)
Epoch (train): [5][59550/74490]	Time 0.085 (0.130)	Data 0.000 (0.054)	Loss 2.5928 (4.0107)
Epoch (train): [5][60550/74490]	Time 0.140 (0.130)	Data 0.103 (0.054)	Loss 4.8140 (4.0070)
Epoch (train): [5][61550/74490]	Time 0.087 (0.130)	Data 0.000 (0.054)	Loss 2.7314 (4.0076)
Epoch (train): [5][62550/74490]	Time 0.082 (0.130)	Data 0.000 (0.054)	Loss 2.2216 (4.0048)
Epoch (train): [5][63550/74490]	Time 0.089 (0.130)	Data 0.000 (0.054)	Loss 3.5194 (4.0031)
Epoch (train): [5][64550/74490]	Time 0.351 (0.130)	Data 0.315 (0.054)	Loss 2.2041 (4.0021)
Epoch (train): [5][65550/74490]	Time 0.450 (0.130)	Data 0.411 (0.054)	Loss 15.9300 (4.0011)
Epoch (train): [5][66550/74490]	Time 0.176 (0.131)	Data 0.135 (0.054)	Loss 3.5363 (3.9990)
Epoch (train): [5][67550/74490]	Time 0.085 (0.131)	Data 0.000 (0.055)	Loss 2.4967 (3.9977)
Epoch (train): [5][68550/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 2.9045 (3.9956)
Epoch (train): [5][69550/74490]	Time 0.079 (0.131)	Data 0.001 (0.055)	Loss 3.3790 (3.9932)
Epoch (train): [5][70550/74490]	Time 0.092 (0.131)	Data 0.000 (0.055)	Loss 5.7808 (3.9919)
Epoch (train): [5][71550/74490]	Time 0.089 (0.131)	Data 0.000 (0.055)	Loss 3.0162 (3.9895)
Epoch (train): [5][72550/74490]	Time 0.677 (0.131)	Data 0.639 (0.055)	Loss 3.3252 (3.9867)
Epoch (train): [5][73550/74490]	Time 0.082 (0.131)	Data 0.000 (0.055)	Loss 4.3319 (3.9853)
Epoch (train): [6][60/74490]	Time 0.080 (0.146)	Data 0.000 (0.069)	Loss 2.9914 (3.1934)
Epoch (train): [6][1060/74490]	Time 0.085 (0.125)	Data 0.000 (0.050)	Loss 2.9254 (3.6531)
Epoch (train): [6][2060/74490]	Time 0.082 (0.125)	Data 0.000 (0.051)	Loss 5.7368 (3.6816)
Epoch (train): [6][3060/74490]	Time 0.086 (0.125)	Data 0.000 (0.050)	Loss 2.9208 (3.6911)
Epoch (train): [6][4060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 3.6727 (3.6833)
Epoch (train): [6][5060/74490]	Time 0.096 (0.125)	Data 0.000 (0.049)	Loss 2.4257 (3.7021)
Epoch (train): [6][6060/74490]	Time 0.082 (0.125)	Data 0.000 (0.050)	Loss 4.7792 (3.6956)
Epoch (train): [6][7060/74490]	Time 0.082 (0.125)	Data 0.000 (0.049)	Loss 3.8928 (3.6870)
Epoch (train): [6][8060/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 2.2871 (3.6891)
Epoch (train): [6][9060/74490]	Time 0.089 (0.126)	Data 0.000 (0.050)	Loss 3.7318 (3.6815)
Epoch (train): [6][10060/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 2.3558 (3.6906)
Epoch (train): [6][11060/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 3.1304 (3.6913)
Epoch (train): [6][12060/74490]	Time 0.094 (0.126)	Data 0.000 (0.050)	Loss 2.7280 (3.6877)
Epoch (train): [6][13060/74490]	Time 0.084 (0.126)	Data 0.000 (0.050)	Loss 2.3805 (3.6814)
Epoch (train): [6][14060/74490]	Time 0.087 (0.126)	Data 0.002 (0.050)	Loss 4.7527 (3.6834)
Epoch (train): [6][15060/74490]	Time 0.079 (0.126)	Data 0.000 (0.050)	Loss 3.2174 (3.6832)
Epoch (train): [6][16060/74490]	Time 0.089 (0.126)	Data 0.001 (0.050)	Loss 2.5881 (3.6853)
Epoch (train): [6][17060/74490]	Time 0.079 (0.126)	Data 0.000 (0.050)	Loss 4.7498 (3.6859)
Epoch (train): [6][18060/74490]	Time 0.099 (0.126)	Data 0.000 (0.050)	Loss 3.7847 (3.6854)
Epoch (train): [6][19060/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 3.1952 (3.6885)
Epoch (train): [6][20060/74490]	Time 0.082 (0.126)	Data 0.000 (0.050)	Loss 3.5194 (3.6867)
Epoch (train): [6][21060/74490]	Time 0.090 (0.126)	Data 0.000 (0.050)	Loss 2.1210 (3.6841)
Epoch (train): [6][22060/74490]	Time 0.087 (0.126)	Data 0.000 (0.050)	Loss 3.2779 (3.6803)
Epoch (train): [6][23060/74490]	Time 0.086 (0.126)	Data 0.002 (0.050)	Loss 3.4046 (3.6765)
Epoch (train): [6][24060/74490]	Time 0.081 (0.126)	Data 0.000 (0.050)	Loss 3.3655 (3.6781)
Epoch (train): [6][25060/74490]	Time 0.089 (0.126)	Data 0.000 (0.050)	Loss 5.9292 (3.6800)
Epoch (train): [6][26060/74490]	Time 0.082 (0.126)	Data 0.000 (0.050)	Loss 5.9465 (3.6710)
Epoch (train): [6][27060/74490]	Time 0.094 (0.125)	Data 0.000 (0.050)	Loss 2.9150 (3.6706)
Epoch (train): [6][28060/74490]	Time 0.096 (0.125)	Data 0.000 (0.050)	Loss 2.2489 (3.6709)
Epoch (train): [6][29060/74490]	Time 0.091 (0.125)	Data 0.000 (0.050)	Loss 3.7287 (3.6717)
Epoch (train): [6][30060/74490]	Time 0.090 (0.125)	Data 0.000 (0.049)	Loss 2.5575 (3.6714)
Epoch (train): [6][31060/74490]	Time 0.099 (0.125)	Data 0.000 (0.049)	Loss 2.5016 (3.6710)
Epoch (train): [6][32060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 3.5870 (3.6686)
Epoch (train): [6][33060/74490]	Time 0.088 (0.125)	Data 0.000 (0.049)	Loss 4.0276 (3.6687)
Epoch (train): [6][34060/74490]	Time 0.079 (0.125)	Data 0.000 (0.049)	Loss 8.9554 (3.6666)
Epoch (train): [6][35060/74490]	Time 0.094 (0.125)	Data 0.000 (0.049)	Loss 1.2979 (3.6645)
Epoch (train): [6][36060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 1.8760 (3.6623)
Epoch (train): [6][37060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 2.0693 (3.6590)
Epoch (train): [6][38060/74490]	Time 0.082 (0.125)	Data 0.000 (0.049)	Loss 3.1629 (3.6576)
Epoch (train): [6][39060/74490]	Time 0.077 (0.125)	Data 0.000 (0.049)	Loss 2.4357 (3.6574)
Epoch (train): [6][40060/74490]	Time 0.080 (0.125)	Data 0.000 (0.049)	Loss 3.9798 (3.6565)
Epoch (train): [6][41060/74490]	Time 0.067 (0.125)	Data 0.001 (0.049)	Loss 2.5002 (3.6551)
Epoch (train): [6][42060/74490]	Time 0.085 (0.125)	Data 0.000 (0.049)	Loss 3.8763 (3.6512)
Epoch (train): [6][43060/74490]	Time 0.092 (0.125)	Data 0.000 (0.049)	Loss 14.5349 (3.6501)
Epoch (train): [6][44060/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 3.5407 (3.6504)
Epoch (train): [6][45060/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 3.7447 (3.6493)
Epoch (train): [6][46060/74490]	Time 0.092 (0.125)	Data 0.000 (0.049)	Loss 3.4079 (3.6471)
Epoch (train): [6][47060/74490]	Time 0.081 (0.125)	Data 0.000 (0.049)	Loss 5.5281 (3.6480)
Epoch (train): [6][48060/74490]	Time 0.084 (0.125)	Data 0.000 (0.049)	Loss 5.7246 (3.6436)
Epoch (train): [6][49060/74490]	Time 0.085 (0.125)	Data 0.001 (0.049)	Loss 4.1070 (3.6420)
Epoch (train): [6][50060/74490]	Time 0.085 (0.125)	Data 0.001 (0.049)	Loss 8.9947 (3.6402)
Epoch (train): [6][51060/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 2.6427 (3.6364)
Epoch (train): [6][52060/74490]	Time 0.086 (0.125)	Data 0.000 (0.050)	Loss 5.5915 (3.6343)
Epoch (train): [6][53060/74490]	Time 0.086 (0.125)	Data 0.000 (0.049)	Loss 1.3666 (3.6346)
Epoch (train): [6][54060/74490]	Time 0.087 (0.125)	Data 0.000 (0.049)	Loss 2.3634 (3.6333)
Epoch (train): [6][55060/74490]	Time 0.086 (0.125)	Data 0.001 (0.049)	Loss 3.1398 (3.6325)
Epoch (train): [6][56060/74490]	Time 0.098 (0.125)	Data 0.001 (0.049)	Loss 5.7761 (3.6304)
Epoch (train): [6][57060/74490]	Time 0.071 (0.125)	Data 0.000 (0.049)	Loss 1.8979 (3.6287)
Epoch (train): [6][58060/74490]	Time 0.083 (0.125)	Data 0.000 (0.049)	Loss 2.5851 (3.6268)
Epoch (train): [6][59060/74490]	Time 0.086 (0.125)	Data 0.000 (0.050)	Loss 2.1266 (3.6257)
Epoch (train): [6][60060/74490]	Time 0.070 (0.125)	Data 0.000 (0.049)	Loss 3.2833 (3.6245)
Epoch (train): [6][61060/74490]	Time 0.088 (0.125)	Data 0.000 (0.050)	Loss 4.9813 (3.6246)
Epoch (train): [6][62060/74490]	Time 0.084 (0.125)	Data 0.000 (0.050)	Loss 4.2069 (3.6236)
Epoch (train): [6][63060/74490]	Time 0.102 (0.125)	Data 0.000 (0.050)	Loss 2.6477 (3.6217)
Epoch (train): [6][64060/74490]	Time 0.084 (0.125)	Data 0.001 (0.050)	Loss 2.6125 (3.6187)
Epoch (train): [6][65060/74490]	Time 0.082 (0.125)	Data 0.000 (0.050)	Loss 3.3908 (3.6201)
Epoch (train): [6][66060/74490]	Time 0.080 (0.125)	Data 0.000 (0.050)	Loss 4.5107 (3.6191)
Epoch (train): [6][67060/74490]	Time 0.084 (0.125)	Data 0.000 (0.050)	Loss 2.2480 (3.6177)
Epoch (train): [6][68060/74490]	Time 0.089 (0.126)	Data 0.002 (0.050)	Loss 1.9811 (3.6166)
Epoch (train): [6][69060/74490]	Time 0.086 (0.126)	Data 0.001 (0.050)	Loss 2.6853 (3.6158)
Epoch (train): [6][70060/74490]	Time 0.085 (0.126)	Data 0.001 (0.050)	Loss 2.6212 (3.6163)
Epoch (train): [6][71060/74490]	Time 0.083 (0.126)	Data 0.000 (0.050)	Loss 2.7254 (3.6147)
Epoch (train): [6][72060/74490]	Time 0.086 (0.126)	Data 0.000 (0.050)	Loss 3.4186 (3.6137)
Epoch (train): [6][73060/74490]	Time 0.085 (0.126)	Data 0.000 (0.050)	Loss 3.9275 (3.6133)
Epoch (train): [6][74060/74490]	Time 0.084 (0.126)	Data 0.000 (0.050)	Loss 4.5275 (3.6120)
Epoch (train): [7][570/74490]	Time 0.075 (0.127)	Data 0.000 (0.053)	Loss 3.3109 (3.3693)
Epoch (train): [7][1570/74490]	Time 0.083 (0.123)	Data 0.000 (0.049)	Loss 2.5126 (3.4021)
Epoch (train): [7][2570/74490]	Time 0.083 (0.123)	Data 0.000 (0.048)	Loss 4.9098 (3.4356)
Epoch (train): [7][3570/74490]	Time 0.094 (0.122)	Data 0.000 (0.047)	Loss 4.7479 (3.3960)
Epoch (train): [7][4570/74490]	Time 0.086 (0.122)	Data 0.000 (0.046)	Loss 6.6466 (3.3767)
Epoch (train): [7][5570/74490]	Time 0.086 (0.122)	Data 0.000 (0.046)	Loss 3.4986 (3.3827)
Epoch (train): [7][6570/74490]	Time 0.095 (0.123)	Data 0.000 (0.046)	Loss 2.6632 (3.3813)
Epoch (train): [7][7570/74490]	Time 0.086 (0.123)	Data 0.000 (0.047)	Loss 1.9628 (3.3884)
Epoch (train): [7][8570/74490]	Time 0.085 (0.123)	Data 0.001 (0.046)	Loss 3.4633 (3.3874)
Epoch (train): [7][9570/74490]	Time 0.095 (0.123)	Data 0.000 (0.046)	Loss 3.2766 (3.3937)
Epoch (train): [7][10570/74490]	Time 0.088 (0.122)	Data 0.000 (0.046)	Loss 3.4083 (3.3950)
Epoch (train): [7][11570/74490]	Time 0.098 (0.122)	Data 0.000 (0.045)	Loss 1.1297 (3.3860)
Epoch (train): [7][12570/74490]	Time 0.093 (0.122)	Data 0.011 (0.046)	Loss 2.3429 (3.3821)
Epoch (train): [7][13570/74490]	Time 0.090 (0.123)	Data 0.000 (0.046)	Loss 7.4679 (3.3831)
Epoch (train): [7][14570/74490]	Time 0.084 (0.123)	Data 0.000 (0.046)	Loss 1.6354 (3.3875)
Epoch (train): [7][15570/74490]	Time 0.087 (0.123)	Data 0.000 (0.046)	Loss 8.9151 (3.3912)
Epoch (train): [7][16570/74490]	Time 0.083 (0.123)	Data 0.000 (0.046)	Loss 5.8616 (3.3858)
Epoch (train): [7][17570/74490]	Time 0.081 (0.123)	Data 0.000 (0.047)	Loss 2.9238 (3.3865)
Epoch (train): [7][18570/74490]	Time 0.088 (0.123)	Data 0.000 (0.047)	Loss 5.7383 (3.3830)
